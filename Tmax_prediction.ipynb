{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>E</th>\n",
       "      <th>N</th>\n",
       "      <th>Tmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>67.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>126.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>72.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>162.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>94.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>61.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>63.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>77.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>63.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>76.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>98.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>94.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A  E   N    Tmax\n",
       "0   25  1  11   67.67\n",
       "1   25  1   5  126.85\n",
       "2   25  2   8   72.71\n",
       "3   25  3  11  162.85\n",
       "4   25  3   5   94.85\n",
       "5   35  1   8   61.15\n",
       "6   35  2  11   63.03\n",
       "7   35  2   5   77.35\n",
       "8   35  3   8   63.25\n",
       "9   25  1   8   76.30\n",
       "10  25  2   5   98.76\n",
       "11  35  3  11   94.70"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "database = pd.read_excel('database_TCC.xlsx')\n",
    "database = database[['A','E','N','Tmax']]\n",
    "database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standardscaler = StandardScaler()\n",
    "standardscaler.fit(database)\n",
    "data = standardscaler.transform(database)\n",
    "database = pd.DataFrame(data,columns=database.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(standardscaler, open('standard_scaler_Tmax.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error,max_error\n",
    "\n",
    "def split_x_and_y(database,x,y):\n",
    "  dataset_x = database[x]\n",
    "  dataset_y = database[y]\n",
    "  return dataset_x,dataset_y\n",
    "\n",
    "\n",
    "def scores(Y_true, Y_predicted):\n",
    "  r2 = r2_score(Y_true, Y_predicted)\n",
    "  meansquarederror = mean_squared_error(Y_true, Y_predicted)\n",
    "  meanabsoluteerror = mean_absolute_error(Y_true, Y_predicted)\n",
    "  maxerror = max_error(Y_true, Y_predicted)\n",
    "\n",
    "  print('r2:',r2,'meansquarederror:',meansquarederror,'meanabsoluteerror:',meanabsoluteerror,'maxerror:',maxerror)\n",
    "  return r2,meansquarederror,meanabsoluteerror,maxerror\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_x,dataset_y = split_x_and_y(database,['A','E','N'],'Tmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8447830391182938"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RFR = RandomForestRegressor(n_estimators=1000)\n",
    "RFR.fit(dataset_x,dataset_y)\n",
    "RFR.score(dataset_x,dataset_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7053810307734065"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_x,dataset_y = split_x_and_y(database.iloc[[0,1,2,3,4,5,6,7,8]],['A','E','N'],'Tmax')\n",
    "\n",
    "test_x,test_y = split_x_and_y(database.iloc[[9,10,11]],['A','E','N'],'Tmax')\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RFR = RandomForestRegressor(n_estimators=3000,criterion='absolute_error',random_state=100)\n",
    "RFR.fit(dataset_x,dataset_y)\n",
    "RFR.score(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21169354, 0.38198803, 0.40631843])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFR.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(RFR, open('Random_Forest_Regressor_Tmax.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6006148480401164"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_x,dataset_y = split_x_and_y(database.iloc[[0,1,2,3,4,5,6,7,8]],['A','E','N'],'Tmax')\n",
    "\n",
    "test_x,test_y = split_x_and_y(database.iloc[[9,10,11]],['A','E','N'],'Tmax')\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svr = svm.SVR(C=4,kernel ='rbf',gamma='scale')\n",
    "\n",
    "svr.fit(dataset_x,dataset_y)\n",
    "svr.score(test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.830254490027388"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_x,dataset_y = split_x_and_y(database.iloc[[0,1,2,3,4,5,6,7,8]],['A','E','N'],'Tmax')\n",
    "\n",
    "test_x,test_y = split_x_and_y(database.iloc[[9,10,11]],['A','E','N'],'Tmax')\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "MLP = MLPRegressor(max_iter=1000,hidden_layer_sizes=(64,32),activation='relu',solver='adam',learning_rate='constant',momentum=0.9,beta_1=0.6,beta_2=0.959,random_state = 100)\n",
    "MLP.fit(dataset_x,dataset_y)\n",
    "MLP.score(test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial with Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2550390584768786"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_x,dataset_y = split_x_and_y(database.iloc[[0,1,2,3,4,5,6,7,8]],['A','E','N'],'Tmax')\n",
    "\n",
    "test_x,test_y = split_x_and_y(database.iloc[[9,10,11]],['A','E','N'],'Tmax')\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "poly = PolynomialFeatures(4)\n",
    "LR = LinearRegression()\n",
    "\n",
    "dataset_x_transformed = poly.fit_transform(dataset_x)\n",
    "test_x_transformed = poly.fit_transform(test_x)\n",
    "\n",
    "LR.fit(dataset_x_transformed,dataset_y)\n",
    "LR.score(test_x_transformed,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/450\n",
      "1/1 [==============================] - 1s 538ms/step - loss: 1.5233 - mse: 1.5233 - val_loss: 0.9323 - val_mse: 0.9323\n",
      "Epoch 2/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4057 - mse: 4.4057 - val_loss: 0.1655 - val_mse: 0.1655\n",
      "Epoch 3/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.6880 - mse: 1.6880 - val_loss: 2.5342 - val_mse: 2.5342\n",
      "Epoch 4/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.1432 - mse: 2.1432 - val_loss: 4.2233 - val_mse: 4.2233\n",
      "Epoch 5/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.1158 - mse: 3.1158 - val_loss: 3.3451 - val_mse: 3.3451\n",
      "Epoch 6/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.5796 - mse: 2.5796 - val_loss: 1.5953 - val_mse: 1.5953\n",
      "Epoch 7/450\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.6985 - mse: 1.6985 - val_loss: 0.3963 - val_mse: 0.3963\n",
      "Epoch 8/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.5016 - mse: 1.5016 - val_loss: 0.0663 - val_mse: 0.0663\n",
      "Epoch 9/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.9484 - mse: 1.9484 - val_loss: 0.0821 - val_mse: 0.0821\n",
      "Epoch 10/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.2749 - mse: 2.2749 - val_loss: 0.0642 - val_mse: 0.0642\n",
      "Epoch 11/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.0934 - mse: 2.0934 - val_loss: 0.1438 - val_mse: 0.1438\n",
      "Epoch 12/450\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.6734 - mse: 1.6734 - val_loss: 0.5637 - val_mse: 0.5637\n",
      "Epoch 13/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.4422 - mse: 1.4422 - val_loss: 1.2798 - val_mse: 1.2798\n",
      "Epoch 14/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.5519 - mse: 1.5519 - val_loss: 1.9075 - val_mse: 1.9075\n",
      "Epoch 15/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.7878 - mse: 1.7878 - val_loss: 2.0645 - val_mse: 2.0645\n",
      "Epoch 16/450\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.8539 - mse: 1.8539 - val_loss: 1.7096 - val_mse: 1.7096\n",
      "Epoch 17/450\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.6926 - mse: 1.6926 - val_loss: 1.1076 - val_mse: 1.1076\n",
      "Epoch 18/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4802 - mse: 1.4802 - val_loss: 0.5734 - val_mse: 0.5734\n",
      "Epoch 19/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4063 - mse: 1.4063 - val_loss: 0.2648 - val_mse: 0.2648\n",
      "Epoch 20/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4951 - mse: 1.4951 - val_loss: 0.1513 - val_mse: 0.1513\n",
      "Epoch 21/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.6092 - mse: 1.6092 - val_loss: 0.1456 - val_mse: 0.1456\n",
      "Epoch 22/450\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.6127 - mse: 1.6127 - val_loss: 0.2281 - val_mse: 0.2281\n",
      "Epoch 23/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.5052 - mse: 1.5052 - val_loss: 0.4370 - val_mse: 0.4370\n",
      "Epoch 24/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3947 - mse: 1.3947 - val_loss: 0.7672 - val_mse: 0.7672\n",
      "Epoch 25/450\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.3742 - mse: 1.3742 - val_loss: 1.1089 - val_mse: 1.1089\n",
      "Epoch 26/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4333 - mse: 1.4333 - val_loss: 1.3011 - val_mse: 1.3011\n",
      "Epoch 27/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.4843 - mse: 1.4843 - val_loss: 1.2541 - val_mse: 1.2541\n",
      "Epoch 28/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.4631 - mse: 1.4631 - val_loss: 1.0133 - val_mse: 1.0133\n",
      "Epoch 29/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.3907 - mse: 1.3907 - val_loss: 0.7109 - val_mse: 0.7109\n",
      "Epoch 30/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.3368 - mse: 1.3368 - val_loss: 0.4672 - val_mse: 0.4672\n",
      "Epoch 31/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.3411 - mse: 1.3411 - val_loss: 0.3306 - val_mse: 0.3306\n",
      "Epoch 32/450\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.3770 - mse: 1.3770 - val_loss: 0.2934 - val_mse: 0.2934\n",
      "Epoch 33/450\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3895 - mse: 1.3895 - val_loss: 0.3408 - val_mse: 0.3408\n",
      "Epoch 34/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3578 - mse: 1.3578 - val_loss: 0.4695 - val_mse: 0.4695\n",
      "Epoch 35/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.3119 - mse: 1.3119 - val_loss: 0.6606 - val_mse: 0.6606\n",
      "Epoch 36/450\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.2922 - mse: 1.2922 - val_loss: 0.8535 - val_mse: 0.8535\n",
      "Epoch 37/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.3045 - mse: 1.3045 - val_loss: 0.9662 - val_mse: 0.9662\n",
      "Epoch 38/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3189 - mse: 1.3189 - val_loss: 0.9494 - val_mse: 0.9494\n",
      "Epoch 39/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.3081 - mse: 1.3081 - val_loss: 0.8215 - val_mse: 0.8215\n",
      "Epoch 40/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2776 - mse: 1.2776 - val_loss: 0.6506 - val_mse: 0.6506\n",
      "Epoch 41/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2543 - mse: 1.2543 - val_loss: 0.5053 - val_mse: 0.5053\n",
      "Epoch 42/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2527 - mse: 1.2527 - val_loss: 0.4225 - val_mse: 0.4225\n",
      "Epoch 43/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2601 - mse: 1.2601 - val_loss: 0.4089 - val_mse: 0.4089\n",
      "Epoch 44/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2556 - mse: 1.2556 - val_loss: 0.4594 - val_mse: 0.4594\n",
      "Epoch 45/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2356 - mse: 1.2356 - val_loss: 0.5608 - val_mse: 0.5608\n",
      "Epoch 46/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.2156 - mse: 1.2156 - val_loss: 0.6824 - val_mse: 0.6824\n",
      "Epoch 47/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2086 - mse: 1.2086 - val_loss: 0.7766 - val_mse: 0.7766\n",
      "Epoch 48/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2098 - mse: 1.2098 - val_loss: 0.8021 - val_mse: 0.8021\n",
      "Epoch 49/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2055 - mse: 1.2055 - val_loss: 0.7513 - val_mse: 0.7513\n",
      "Epoch 50/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1909 - mse: 1.1909 - val_loss: 0.6542 - val_mse: 0.6542\n",
      "Epoch 51/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1748 - mse: 1.1748 - val_loss: 0.5555 - val_mse: 0.5555\n",
      "Epoch 52/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1666 - mse: 1.1666 - val_loss: 0.4894 - val_mse: 0.4894\n",
      "Epoch 53/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1642 - mse: 1.1642 - val_loss: 0.4704 - val_mse: 0.4704\n",
      "Epoch 54/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1586 - mse: 1.1586 - val_loss: 0.4981 - val_mse: 0.4981\n",
      "Epoch 55/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1464 - mse: 1.1464 - val_loss: 0.5609 - val_mse: 0.5609\n",
      "Epoch 56/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.1335 - mse: 1.1335 - val_loss: 0.6347 - val_mse: 0.6347\n",
      "Epoch 57/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1257 - mse: 1.1257 - val_loss: 0.6882 - val_mse: 0.6882\n",
      "Epoch 58/450\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.1214 - mse: 1.1214 - val_loss: 0.6973 - val_mse: 0.6973\n",
      "Epoch 59/450\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1146 - mse: 1.1146 - val_loss: 0.6601 - val_mse: 0.6601\n",
      "Epoch 60/450\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1038 - mse: 1.1038 - val_loss: 0.5973 - val_mse: 0.5973\n",
      "Epoch 61/450\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0933 - mse: 1.0933 - val_loss: 0.5374 - val_mse: 0.5374\n",
      "Epoch 62/450\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.0865 - mse: 1.0865 - val_loss: 0.5019 - val_mse: 0.5019\n",
      "Epoch 63/450\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.0811 - mse: 1.0811 - val_loss: 0.4992 - val_mse: 0.4992\n",
      "Epoch 64/450\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0737 - mse: 1.0737 - val_loss: 0.5259 - val_mse: 0.5259\n",
      "Epoch 65/450\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0642 - mse: 1.0642 - val_loss: 0.5690 - val_mse: 0.5690\n",
      "Epoch 66/450\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0559 - mse: 1.0559 - val_loss: 0.6082 - val_mse: 0.6082\n",
      "Epoch 67/450\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0499 - mse: 1.0499 - val_loss: 0.6243 - val_mse: 0.6243\n",
      "Epoch 68/450\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0441 - mse: 1.0441 - val_loss: 0.6099 - val_mse: 0.6099\n",
      "Epoch 69/450\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0367 - mse: 1.0367 - val_loss: 0.5731 - val_mse: 0.5731\n",
      "Epoch 70/450\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0288 - mse: 1.0288 - val_loss: 0.5318 - val_mse: 0.5318\n",
      "Epoch 71/450\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0223 - mse: 1.0223 - val_loss: 0.5029 - val_mse: 0.5029\n",
      "Epoch 72/450\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0171 - mse: 1.0171 - val_loss: 0.4949 - val_mse: 0.4949\n",
      "Epoch 73/450\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0113 - mse: 1.0113 - val_loss: 0.5073 - val_mse: 0.5073\n",
      "Epoch 74/450\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.0047 - mse: 1.0047 - val_loss: 0.5314 - val_mse: 0.5314\n",
      "Epoch 75/450\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9985 - mse: 0.9985 - val_loss: 0.5538 - val_mse: 0.5538\n",
      "Epoch 76/450\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9936 - mse: 0.9936 - val_loss: 0.5618 - val_mse: 0.5618\n",
      "Epoch 77/450\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.9889 - mse: 0.9889 - val_loss: 0.5509 - val_mse: 0.5509\n",
      "Epoch 78/450\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.9837 - mse: 0.9837 - val_loss: 0.5263 - val_mse: 0.5263\n",
      "Epoch 79/450\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.9785 - mse: 0.9785 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 80/450\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9740 - mse: 0.9740 - val_loss: 0.4820 - val_mse: 0.4820\n",
      "Epoch 81/450\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9702 - mse: 0.9702 - val_loss: 0.4780 - val_mse: 0.4780\n",
      "Epoch 82/450\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9663 - mse: 0.9663 - val_loss: 0.4863 - val_mse: 0.4863\n",
      "Epoch 83/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9621 - mse: 0.9621 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 84/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9585 - mse: 0.9585 - val_loss: 0.5099 - val_mse: 0.5099\n",
      "Epoch 85/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9555 - mse: 0.9555 - val_loss: 0.5094 - val_mse: 0.5094\n",
      "Epoch 86/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9525 - mse: 0.9525 - val_loss: 0.4978 - val_mse: 0.4978\n",
      "Epoch 87/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9495 - mse: 0.9495 - val_loss: 0.4805 - val_mse: 0.4805\n",
      "Epoch 88/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9467 - mse: 0.9467 - val_loss: 0.4651 - val_mse: 0.4651\n",
      "Epoch 89/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9444 - mse: 0.9444 - val_loss: 0.4572 - val_mse: 0.4572\n",
      "Epoch 90/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9424 - mse: 0.9424 - val_loss: 0.4579 - val_mse: 0.4579\n",
      "Epoch 91/450\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9403 - mse: 0.9403 - val_loss: 0.4643 - val_mse: 0.4643\n",
      "Epoch 92/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9383 - mse: 0.9383 - val_loss: 0.4707 - val_mse: 0.4707\n",
      "Epoch 93/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9367 - mse: 0.9367 - val_loss: 0.4720 - val_mse: 0.4720\n",
      "Epoch 94/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9354 - mse: 0.9354 - val_loss: 0.4662 - val_mse: 0.4662\n",
      "Epoch 95/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9340 - mse: 0.9340 - val_loss: 0.4556 - val_mse: 0.4556\n",
      "Epoch 96/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9327 - mse: 0.9327 - val_loss: 0.4447 - val_mse: 0.4447\n",
      "Epoch 97/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9317 - mse: 0.9317 - val_loss: 0.4378 - val_mse: 0.4378\n",
      "Epoch 98/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9308 - mse: 0.9308 - val_loss: 0.4362 - val_mse: 0.4362\n",
      "Epoch 99/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9300 - mse: 0.9300 - val_loss: 0.4386 - val_mse: 0.4386\n",
      "Epoch 100/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9292 - mse: 0.9292 - val_loss: 0.4417 - val_mse: 0.4417\n",
      "Epoch 101/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9285 - mse: 0.9285 - val_loss: 0.4420 - val_mse: 0.4420\n",
      "Epoch 102/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9280 - mse: 0.9280 - val_loss: 0.4380 - val_mse: 0.4380\n",
      "Epoch 103/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9275 - mse: 0.9275 - val_loss: 0.4307 - val_mse: 0.4307\n",
      "Epoch 104/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9270 - mse: 0.9270 - val_loss: 0.4231 - val_mse: 0.4231\n",
      "Epoch 105/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9266 - mse: 0.9266 - val_loss: 0.4178 - val_mse: 0.4178\n",
      "Epoch 106/450\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9262 - mse: 0.9262 - val_loss: 0.4157 - val_mse: 0.4157\n",
      "Epoch 107/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9259 - mse: 0.9259 - val_loss: 0.4161 - val_mse: 0.4161\n",
      "Epoch 108/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9255 - mse: 0.9255 - val_loss: 0.4167 - val_mse: 0.4167\n",
      "Epoch 109/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9252 - mse: 0.9252 - val_loss: 0.4156 - val_mse: 0.4156\n",
      "Epoch 110/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9250 - mse: 0.9250 - val_loss: 0.4117 - val_mse: 0.4117\n",
      "Epoch 111/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9247 - mse: 0.9247 - val_loss: 0.4060 - val_mse: 0.4060\n",
      "Epoch 112/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9244 - mse: 0.9244 - val_loss: 0.4002 - val_mse: 0.4002\n",
      "Epoch 113/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9242 - mse: 0.9242 - val_loss: 0.3961 - val_mse: 0.3961\n",
      "Epoch 114/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9239 - mse: 0.9239 - val_loss: 0.3940 - val_mse: 0.3940\n",
      "Epoch 115/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9237 - mse: 0.9237 - val_loss: 0.3932 - val_mse: 0.3932\n",
      "Epoch 116/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9234 - mse: 0.9234 - val_loss: 0.3922 - val_mse: 0.3922\n",
      "Epoch 117/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9232 - mse: 0.9232 - val_loss: 0.3899 - val_mse: 0.3899\n",
      "Epoch 118/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9229 - mse: 0.9229 - val_loss: 0.3860 - val_mse: 0.3860\n",
      "Epoch 119/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9227 - mse: 0.9227 - val_loss: 0.3812 - val_mse: 0.3812\n",
      "Epoch 120/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9224 - mse: 0.9224 - val_loss: 0.3768 - val_mse: 0.3768\n",
      "Epoch 121/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9222 - mse: 0.9222 - val_loss: 0.3735 - val_mse: 0.3735\n",
      "Epoch 122/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9220 - mse: 0.9220 - val_loss: 0.3716 - val_mse: 0.3716\n",
      "Epoch 123/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9217 - mse: 0.9217 - val_loss: 0.3702 - val_mse: 0.3702\n",
      "Epoch 124/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9215 - mse: 0.9215 - val_loss: 0.3684 - val_mse: 0.3684\n",
      "Epoch 125/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9213 - mse: 0.9213 - val_loss: 0.3656 - val_mse: 0.3656\n",
      "Epoch 126/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9211 - mse: 0.9211 - val_loss: 0.3619 - val_mse: 0.3619\n",
      "Epoch 127/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9209 - mse: 0.9209 - val_loss: 0.3581 - val_mse: 0.3581\n",
      "Epoch 128/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9206 - mse: 0.9206 - val_loss: 0.3548 - val_mse: 0.3548\n",
      "Epoch 129/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9204 - mse: 0.9204 - val_loss: 0.3524 - val_mse: 0.3524\n",
      "Epoch 130/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9203 - mse: 0.9203 - val_loss: 0.3507 - val_mse: 0.3507\n",
      "Epoch 131/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9201 - mse: 0.9201 - val_loss: 0.3491 - val_mse: 0.3491\n",
      "Epoch 132/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9199 - mse: 0.9199 - val_loss: 0.3470 - val_mse: 0.3470\n",
      "Epoch 133/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9197 - mse: 0.9197 - val_loss: 0.3443 - val_mse: 0.3443\n",
      "Epoch 134/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9195 - mse: 0.9195 - val_loss: 0.3412 - val_mse: 0.3412\n",
      "Epoch 135/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9194 - mse: 0.9194 - val_loss: 0.3384 - val_mse: 0.3384\n",
      "Epoch 136/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9192 - mse: 0.9192 - val_loss: 0.3361 - val_mse: 0.3361\n",
      "Epoch 137/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9191 - mse: 0.9191 - val_loss: 0.3344 - val_mse: 0.3344\n",
      "Epoch 138/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9189 - mse: 0.9189 - val_loss: 0.3330 - val_mse: 0.3330\n",
      "Epoch 139/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9188 - mse: 0.9188 - val_loss: 0.3314 - val_mse: 0.3314\n",
      "Epoch 140/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9187 - mse: 0.9187 - val_loss: 0.3294 - val_mse: 0.3294\n",
      "Epoch 141/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9186 - mse: 0.9186 - val_loss: 0.3271 - val_mse: 0.3271\n",
      "Epoch 142/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9184 - mse: 0.9184 - val_loss: 0.3248 - val_mse: 0.3248\n",
      "Epoch 143/450\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9183 - mse: 0.9183 - val_loss: 0.3229 - val_mse: 0.3229\n",
      "Epoch 144/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9182 - mse: 0.9182 - val_loss: 0.3214 - val_mse: 0.3214\n",
      "Epoch 145/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9181 - mse: 0.9181 - val_loss: 0.3202 - val_mse: 0.3202\n",
      "Epoch 146/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9180 - mse: 0.9180 - val_loss: 0.3189 - val_mse: 0.3189\n",
      "Epoch 147/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9179 - mse: 0.9179 - val_loss: 0.3174 - val_mse: 0.3174\n",
      "Epoch 148/450\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9178 - mse: 0.9178 - val_loss: 0.3157 - val_mse: 0.3157\n",
      "Epoch 149/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9177 - mse: 0.9177 - val_loss: 0.3140 - val_mse: 0.3140\n",
      "Epoch 150/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9177 - mse: 0.9177 - val_loss: 0.3124 - val_mse: 0.3124\n",
      "Epoch 151/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9176 - mse: 0.9176 - val_loss: 0.3112 - val_mse: 0.3112\n",
      "Epoch 152/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9175 - mse: 0.9175 - val_loss: 0.3102 - val_mse: 0.3102\n",
      "Epoch 153/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9174 - mse: 0.9174 - val_loss: 0.3092 - val_mse: 0.3092\n",
      "Epoch 154/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9173 - mse: 0.9173 - val_loss: 0.3081 - val_mse: 0.3081\n",
      "Epoch 155/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9173 - mse: 0.9173 - val_loss: 0.3068 - val_mse: 0.3068\n",
      "Epoch 156/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9172 - mse: 0.9172 - val_loss: 0.3055 - val_mse: 0.3055\n",
      "Epoch 157/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9171 - mse: 0.9171 - val_loss: 0.3044 - val_mse: 0.3044\n",
      "Epoch 158/450\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9170 - mse: 0.9170 - val_loss: 0.3034 - val_mse: 0.3034\n",
      "Epoch 159/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9170 - mse: 0.9170 - val_loss: 0.3026 - val_mse: 0.3026\n",
      "Epoch 160/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9169 - mse: 0.9169 - val_loss: 0.3018 - val_mse: 0.3018\n",
      "Epoch 161/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9169 - mse: 0.9169 - val_loss: 0.3010 - val_mse: 0.3010\n",
      "Epoch 162/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9168 - mse: 0.9168 - val_loss: 0.3000 - val_mse: 0.3000\n",
      "Epoch 163/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9167 - mse: 0.9167 - val_loss: 0.2990 - val_mse: 0.2990\n",
      "Epoch 164/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9167 - mse: 0.9167 - val_loss: 0.2981 - val_mse: 0.2981\n",
      "Epoch 165/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9166 - mse: 0.9166 - val_loss: 0.2974 - val_mse: 0.2974\n",
      "Epoch 166/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9165 - mse: 0.9165 - val_loss: 0.2968 - val_mse: 0.2968\n",
      "Epoch 167/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9165 - mse: 0.9165 - val_loss: 0.2961 - val_mse: 0.2961\n",
      "Epoch 168/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9164 - mse: 0.9164 - val_loss: 0.2955 - val_mse: 0.2955\n",
      "Epoch 169/450\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9164 - mse: 0.9164 - val_loss: 0.2948 - val_mse: 0.2948\n",
      "Epoch 170/450\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9163 - mse: 0.9163 - val_loss: 0.2940 - val_mse: 0.2940\n",
      "Epoch 171/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9163 - mse: 0.9163 - val_loss: 0.2933 - val_mse: 0.2933\n",
      "Epoch 172/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9162 - mse: 0.9162 - val_loss: 0.2928 - val_mse: 0.2928\n",
      "Epoch 173/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9162 - mse: 0.9162 - val_loss: 0.2923 - val_mse: 0.2923\n",
      "Epoch 174/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9161 - mse: 0.9161 - val_loss: 0.2918 - val_mse: 0.2918\n",
      "Epoch 175/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9161 - mse: 0.9161 - val_loss: 0.2913 - val_mse: 0.2913\n",
      "Epoch 176/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9160 - mse: 0.9160 - val_loss: 0.2907 - val_mse: 0.2907\n",
      "Epoch 177/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9160 - mse: 0.9160 - val_loss: 0.2902 - val_mse: 0.2902\n",
      "Epoch 178/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9159 - mse: 0.9159 - val_loss: 0.2897 - val_mse: 0.2897\n",
      "Epoch 179/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9159 - mse: 0.9159 - val_loss: 0.2892 - val_mse: 0.2892\n",
      "Epoch 180/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9158 - mse: 0.9158 - val_loss: 0.2889 - val_mse: 0.2889\n",
      "Epoch 181/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9158 - mse: 0.9158 - val_loss: 0.2885 - val_mse: 0.2885\n",
      "Epoch 182/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9157 - mse: 0.9157 - val_loss: 0.2881 - val_mse: 0.2881\n",
      "Epoch 183/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9157 - mse: 0.9157 - val_loss: 0.2877 - val_mse: 0.2877\n",
      "Epoch 184/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9156 - mse: 0.9156 - val_loss: 0.2872 - val_mse: 0.2872\n",
      "Epoch 185/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9156 - mse: 0.9156 - val_loss: 0.2869 - val_mse: 0.2869\n",
      "Epoch 186/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9155 - mse: 0.9155 - val_loss: 0.2865 - val_mse: 0.2865\n",
      "Epoch 187/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9155 - mse: 0.9155 - val_loss: 0.2863 - val_mse: 0.2863\n",
      "Epoch 188/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9154 - mse: 0.9154 - val_loss: 0.2860 - val_mse: 0.2860\n",
      "Epoch 189/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9154 - mse: 0.9154 - val_loss: 0.2856 - val_mse: 0.2856\n",
      "Epoch 190/450\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9153 - mse: 0.9153 - val_loss: 0.2853 - val_mse: 0.2853\n",
      "Epoch 191/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9153 - mse: 0.9153 - val_loss: 0.2850 - val_mse: 0.2850\n",
      "Epoch 192/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9152 - mse: 0.9152 - val_loss: 0.2847 - val_mse: 0.2847\n",
      "Epoch 193/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9152 - mse: 0.9152 - val_loss: 0.2845 - val_mse: 0.2845\n",
      "Epoch 194/450\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.9151 - mse: 0.9151 - val_loss: 0.2843 - val_mse: 0.2843\n",
      "Epoch 195/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9151 - mse: 0.9151 - val_loss: 0.2841 - val_mse: 0.2841\n",
      "Epoch 196/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9150 - mse: 0.9150 - val_loss: 0.2838 - val_mse: 0.2838\n",
      "Epoch 197/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9150 - mse: 0.9150 - val_loss: 0.2836 - val_mse: 0.2836\n",
      "Epoch 198/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9149 - mse: 0.9149 - val_loss: 0.2833 - val_mse: 0.2833\n",
      "Epoch 199/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9149 - mse: 0.9149 - val_loss: 0.2831 - val_mse: 0.2831\n",
      "Epoch 200/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9148 - mse: 0.9148 - val_loss: 0.2830 - val_mse: 0.2830\n",
      "Epoch 201/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9148 - mse: 0.9148 - val_loss: 0.2828 - val_mse: 0.2828\n",
      "Epoch 202/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9147 - mse: 0.9147 - val_loss: 0.2826 - val_mse: 0.2826\n",
      "Epoch 203/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9146 - mse: 0.9146 - val_loss: 0.2824 - val_mse: 0.2824\n",
      "Epoch 204/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9146 - mse: 0.9146 - val_loss: 0.2823 - val_mse: 0.2823\n",
      "Epoch 205/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9145 - mse: 0.9145 - val_loss: 0.2821 - val_mse: 0.2821\n",
      "Epoch 206/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9145 - mse: 0.9145 - val_loss: 0.2820 - val_mse: 0.2820\n",
      "Epoch 207/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9144 - mse: 0.9144 - val_loss: 0.2818 - val_mse: 0.2818\n",
      "Epoch 208/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9144 - mse: 0.9144 - val_loss: 0.2817 - val_mse: 0.2817\n",
      "Epoch 209/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9143 - mse: 0.9143 - val_loss: 0.2816 - val_mse: 0.2816\n",
      "Epoch 210/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9143 - mse: 0.9143 - val_loss: 0.2814 - val_mse: 0.2814\n",
      "Epoch 211/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9142 - mse: 0.9142 - val_loss: 0.2813 - val_mse: 0.2813\n",
      "Epoch 212/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9142 - mse: 0.9142 - val_loss: 0.2812 - val_mse: 0.2812\n",
      "Epoch 213/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9141 - mse: 0.9141 - val_loss: 0.2811 - val_mse: 0.2811\n",
      "Epoch 214/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9140 - mse: 0.9140 - val_loss: 0.2810 - val_mse: 0.2810\n",
      "Epoch 215/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9140 - mse: 0.9140 - val_loss: 0.2809 - val_mse: 0.2809\n",
      "Epoch 216/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9139 - mse: 0.9139 - val_loss: 0.2809 - val_mse: 0.2809\n",
      "Epoch 217/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9139 - mse: 0.9139 - val_loss: 0.2808 - val_mse: 0.2808\n",
      "Epoch 218/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9138 - mse: 0.9138 - val_loss: 0.2807 - val_mse: 0.2807\n",
      "Epoch 219/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9137 - mse: 0.9137 - val_loss: 0.2806 - val_mse: 0.2806\n",
      "Epoch 220/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9137 - mse: 0.9137 - val_loss: 0.2806 - val_mse: 0.2806\n",
      "Epoch 221/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9136 - mse: 0.9136 - val_loss: 0.2805 - val_mse: 0.2805\n",
      "Epoch 222/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9135 - mse: 0.9135 - val_loss: 0.2805 - val_mse: 0.2805\n",
      "Epoch 223/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9135 - mse: 0.9135 - val_loss: 0.2804 - val_mse: 0.2804\n",
      "Epoch 224/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9134 - mse: 0.9134 - val_loss: 0.2804 - val_mse: 0.2804\n",
      "Epoch 225/450\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9134 - mse: 0.9134 - val_loss: 0.2803 - val_mse: 0.2803\n",
      "Epoch 226/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9133 - mse: 0.9133 - val_loss: 0.2803 - val_mse: 0.2803\n",
      "Epoch 227/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9132 - mse: 0.9132 - val_loss: 0.2803 - val_mse: 0.2803\n",
      "Epoch 228/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9132 - mse: 0.9132 - val_loss: 0.2802 - val_mse: 0.2802\n",
      "Epoch 229/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9131 - mse: 0.9131 - val_loss: 0.2802 - val_mse: 0.2802\n",
      "Epoch 230/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9130 - mse: 0.9130 - val_loss: 0.2802 - val_mse: 0.2802\n",
      "Epoch 231/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9130 - mse: 0.9130 - val_loss: 0.2802 - val_mse: 0.2802\n",
      "Epoch 232/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9129 - mse: 0.9129 - val_loss: 0.2801 - val_mse: 0.2801\n",
      "Epoch 233/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9128 - mse: 0.9128 - val_loss: 0.2801 - val_mse: 0.2801\n",
      "Epoch 234/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9127 - mse: 0.9127 - val_loss: 0.2801 - val_mse: 0.2801\n",
      "Epoch 235/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9127 - mse: 0.9127 - val_loss: 0.2801 - val_mse: 0.2801\n",
      "Epoch 236/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9126 - mse: 0.9126 - val_loss: 0.2801 - val_mse: 0.2801\n",
      "Epoch 237/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9125 - mse: 0.9125 - val_loss: 0.2801 - val_mse: 0.2801\n",
      "Epoch 238/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9124 - mse: 0.9124 - val_loss: 0.2801 - val_mse: 0.2801\n",
      "Epoch 239/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9124 - mse: 0.9124 - val_loss: 0.2801 - val_mse: 0.2801\n",
      "Epoch 240/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9123 - mse: 0.9123 - val_loss: 0.2801 - val_mse: 0.2801\n",
      "Epoch 241/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9122 - mse: 0.9122 - val_loss: 0.2802 - val_mse: 0.2802\n",
      "Epoch 242/450\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.9121 - mse: 0.9121 - val_loss: 0.2802 - val_mse: 0.2802\n",
      "Epoch 243/450\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.9121 - mse: 0.9121 - val_loss: 0.2802 - val_mse: 0.2802\n",
      "Epoch 244/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9120 - mse: 0.9120 - val_loss: 0.2802 - val_mse: 0.2802\n",
      "Epoch 245/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9119 - mse: 0.9119 - val_loss: 0.2802 - val_mse: 0.2802\n",
      "Epoch 246/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9118 - mse: 0.9118 - val_loss: 0.2802 - val_mse: 0.2802\n",
      "Epoch 247/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9117 - mse: 0.9117 - val_loss: 0.2803 - val_mse: 0.2803\n",
      "Epoch 248/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9116 - mse: 0.9116 - val_loss: 0.2803 - val_mse: 0.2803\n",
      "Epoch 249/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9115 - mse: 0.9115 - val_loss: 0.2803 - val_mse: 0.2803\n",
      "Epoch 250/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9115 - mse: 0.9115 - val_loss: 0.2803 - val_mse: 0.2803\n",
      "Epoch 251/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9114 - mse: 0.9114 - val_loss: 0.2804 - val_mse: 0.2804\n",
      "Epoch 252/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9113 - mse: 0.9113 - val_loss: 0.2804 - val_mse: 0.2804\n",
      "Epoch 253/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9112 - mse: 0.9112 - val_loss: 0.2804 - val_mse: 0.2804\n",
      "Epoch 254/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9111 - mse: 0.9111 - val_loss: 0.2805 - val_mse: 0.2805\n",
      "Epoch 255/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9110 - mse: 0.9110 - val_loss: 0.2805 - val_mse: 0.2805\n",
      "Epoch 256/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9109 - mse: 0.9109 - val_loss: 0.2805 - val_mse: 0.2805\n",
      "Epoch 257/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9108 - mse: 0.9108 - val_loss: 0.2806 - val_mse: 0.2806\n",
      "Epoch 258/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9107 - mse: 0.9107 - val_loss: 0.2806 - val_mse: 0.2806\n",
      "Epoch 259/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9106 - mse: 0.9106 - val_loss: 0.2807 - val_mse: 0.2807\n",
      "Epoch 260/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9105 - mse: 0.9105 - val_loss: 0.2807 - val_mse: 0.2807\n",
      "Epoch 261/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9104 - mse: 0.9104 - val_loss: 0.2807 - val_mse: 0.2807\n",
      "Epoch 262/450\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9103 - mse: 0.9103 - val_loss: 0.2808 - val_mse: 0.2808\n",
      "Epoch 263/450\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9102 - mse: 0.9102 - val_loss: 0.2808 - val_mse: 0.2808\n",
      "Epoch 264/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9101 - mse: 0.9101 - val_loss: 0.2809 - val_mse: 0.2809\n",
      "Epoch 265/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9100 - mse: 0.9100 - val_loss: 0.2809 - val_mse: 0.2809\n",
      "Epoch 266/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9099 - mse: 0.9099 - val_loss: 0.2810 - val_mse: 0.2810\n",
      "Epoch 267/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9098 - mse: 0.9098 - val_loss: 0.2810 - val_mse: 0.2810\n",
      "Epoch 268/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9097 - mse: 0.9097 - val_loss: 0.2811 - val_mse: 0.2811\n",
      "Epoch 269/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9096 - mse: 0.9096 - val_loss: 0.2811 - val_mse: 0.2811\n",
      "Epoch 270/450\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9094 - mse: 0.9094 - val_loss: 0.2812 - val_mse: 0.2812\n",
      "Epoch 271/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9093 - mse: 0.9093 - val_loss: 0.2813 - val_mse: 0.2813\n",
      "Epoch 272/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9092 - mse: 0.9092 - val_loss: 0.2813 - val_mse: 0.2813\n",
      "Epoch 273/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9091 - mse: 0.9091 - val_loss: 0.2814 - val_mse: 0.2814\n",
      "Epoch 274/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9090 - mse: 0.9090 - val_loss: 0.2814 - val_mse: 0.2814\n",
      "Epoch 275/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9088 - mse: 0.9088 - val_loss: 0.2815 - val_mse: 0.2815\n",
      "Epoch 276/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9087 - mse: 0.9087 - val_loss: 0.2816 - val_mse: 0.2816\n",
      "Epoch 277/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9086 - mse: 0.9086 - val_loss: 0.2816 - val_mse: 0.2816\n",
      "Epoch 278/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9085 - mse: 0.9085 - val_loss: 0.2817 - val_mse: 0.2817\n",
      "Epoch 279/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9083 - mse: 0.9083 - val_loss: 0.2818 - val_mse: 0.2818\n",
      "Epoch 280/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9082 - mse: 0.9082 - val_loss: 0.2818 - val_mse: 0.2818\n",
      "Epoch 281/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9081 - mse: 0.9081 - val_loss: 0.2819 - val_mse: 0.2819\n",
      "Epoch 282/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9079 - mse: 0.9079 - val_loss: 0.2820 - val_mse: 0.2820\n",
      "Epoch 283/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9078 - mse: 0.9078 - val_loss: 0.2821 - val_mse: 0.2821\n",
      "Epoch 284/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9077 - mse: 0.9077 - val_loss: 0.2821 - val_mse: 0.2821\n",
      "Epoch 285/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9075 - mse: 0.9075 - val_loss: 0.2822 - val_mse: 0.2822\n",
      "Epoch 286/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9074 - mse: 0.9074 - val_loss: 0.2823 - val_mse: 0.2823\n",
      "Epoch 287/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9072 - mse: 0.9072 - val_loss: 0.2824 - val_mse: 0.2824\n",
      "Epoch 288/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9071 - mse: 0.9071 - val_loss: 0.2824 - val_mse: 0.2824\n",
      "Epoch 289/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9069 - mse: 0.9069 - val_loss: 0.2825 - val_mse: 0.2825\n",
      "Epoch 290/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9068 - mse: 0.9068 - val_loss: 0.2826 - val_mse: 0.2826\n",
      "Epoch 291/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9066 - mse: 0.9066 - val_loss: 0.2827 - val_mse: 0.2827\n",
      "Epoch 292/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9064 - mse: 0.9064 - val_loss: 0.2828 - val_mse: 0.2828\n",
      "Epoch 293/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9063 - mse: 0.9063 - val_loss: 0.2829 - val_mse: 0.2829\n",
      "Epoch 294/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9061 - mse: 0.9061 - val_loss: 0.2829 - val_mse: 0.2829\n",
      "Epoch 295/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9060 - mse: 0.9060 - val_loss: 0.2830 - val_mse: 0.2830\n",
      "Epoch 296/450\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9058 - mse: 0.9058 - val_loss: 0.2831 - val_mse: 0.2831\n",
      "Epoch 297/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9056 - mse: 0.9056 - val_loss: 0.2832 - val_mse: 0.2832\n",
      "Epoch 298/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9054 - mse: 0.9054 - val_loss: 0.2833 - val_mse: 0.2833\n",
      "Epoch 299/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9053 - mse: 0.9053 - val_loss: 0.2834 - val_mse: 0.2834\n",
      "Epoch 300/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9051 - mse: 0.9051 - val_loss: 0.2835 - val_mse: 0.2835\n",
      "Epoch 301/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9049 - mse: 0.9049 - val_loss: 0.2836 - val_mse: 0.2836\n",
      "Epoch 302/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9047 - mse: 0.9047 - val_loss: 0.2837 - val_mse: 0.2837\n",
      "Epoch 303/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9045 - mse: 0.9045 - val_loss: 0.2838 - val_mse: 0.2838\n",
      "Epoch 304/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9043 - mse: 0.9043 - val_loss: 0.2839 - val_mse: 0.2839\n",
      "Epoch 305/450\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.9041 - mse: 0.9041 - val_loss: 0.2840 - val_mse: 0.2840\n",
      "Epoch 306/450\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9039 - mse: 0.9039 - val_loss: 0.2841 - val_mse: 0.2841\n",
      "Epoch 307/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9037 - mse: 0.9037 - val_loss: 0.2843 - val_mse: 0.2843\n",
      "Epoch 308/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9035 - mse: 0.9035 - val_loss: 0.2844 - val_mse: 0.2844\n",
      "Epoch 309/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9033 - mse: 0.9033 - val_loss: 0.2845 - val_mse: 0.2845\n",
      "Epoch 310/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9031 - mse: 0.9031 - val_loss: 0.2846 - val_mse: 0.2846\n",
      "Epoch 311/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9029 - mse: 0.9029 - val_loss: 0.2847 - val_mse: 0.2847\n",
      "Epoch 312/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9026 - mse: 0.9026 - val_loss: 0.2848 - val_mse: 0.2848\n",
      "Epoch 313/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9024 - mse: 0.9024 - val_loss: 0.2850 - val_mse: 0.2850\n",
      "Epoch 314/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9022 - mse: 0.9022 - val_loss: 0.2851 - val_mse: 0.2851\n",
      "Epoch 315/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9020 - mse: 0.9020 - val_loss: 0.2852 - val_mse: 0.2852\n",
      "Epoch 316/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9017 - mse: 0.9017 - val_loss: 0.2853 - val_mse: 0.2853\n",
      "Epoch 317/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9015 - mse: 0.9015 - val_loss: 0.2855 - val_mse: 0.2855\n",
      "Epoch 318/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9012 - mse: 0.9012 - val_loss: 0.2856 - val_mse: 0.2856\n",
      "Epoch 319/450\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.9010 - mse: 0.9010 - val_loss: 0.2858 - val_mse: 0.2858\n",
      "Epoch 320/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9007 - mse: 0.9007 - val_loss: 0.2859 - val_mse: 0.2859\n",
      "Epoch 321/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9005 - mse: 0.9005 - val_loss: 0.2860 - val_mse: 0.2860\n",
      "Epoch 322/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9002 - mse: 0.9002 - val_loss: 0.2862 - val_mse: 0.2862\n",
      "Epoch 323/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8999 - mse: 0.8999 - val_loss: 0.2863 - val_mse: 0.2863\n",
      "Epoch 324/450\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8997 - mse: 0.8997 - val_loss: 0.2865 - val_mse: 0.2865\n",
      "Epoch 325/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8994 - mse: 0.8994 - val_loss: 0.2866 - val_mse: 0.2866\n",
      "Epoch 326/450\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8991 - mse: 0.8991 - val_loss: 0.2868 - val_mse: 0.2868\n",
      "Epoch 327/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8988 - mse: 0.8988 - val_loss: 0.2869 - val_mse: 0.2869\n",
      "Epoch 328/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8985 - mse: 0.8985 - val_loss: 0.2871 - val_mse: 0.2871\n",
      "Epoch 329/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8982 - mse: 0.8982 - val_loss: 0.2873 - val_mse: 0.2873\n",
      "Epoch 330/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8979 - mse: 0.8979 - val_loss: 0.2874 - val_mse: 0.2874\n",
      "Epoch 331/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8976 - mse: 0.8976 - val_loss: 0.2876 - val_mse: 0.2876\n",
      "Epoch 332/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8973 - mse: 0.8973 - val_loss: 0.2878 - val_mse: 0.2878\n",
      "Epoch 333/450\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8970 - mse: 0.8970 - val_loss: 0.2879 - val_mse: 0.2879\n",
      "Epoch 334/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8967 - mse: 0.8967 - val_loss: 0.2881 - val_mse: 0.2881\n",
      "Epoch 335/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8963 - mse: 0.8963 - val_loss: 0.2883 - val_mse: 0.2883\n",
      "Epoch 336/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8960 - mse: 0.8960 - val_loss: 0.2885 - val_mse: 0.2885\n",
      "Epoch 337/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8956 - mse: 0.8956 - val_loss: 0.2887 - val_mse: 0.2887\n",
      "Epoch 338/450\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8953 - mse: 0.8953 - val_loss: 0.2889 - val_mse: 0.2889\n",
      "Epoch 339/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8949 - mse: 0.8949 - val_loss: 0.2891 - val_mse: 0.2891\n",
      "Epoch 340/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8945 - mse: 0.8945 - val_loss: 0.2893 - val_mse: 0.2893\n",
      "Epoch 341/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8942 - mse: 0.8942 - val_loss: 0.2895 - val_mse: 0.2895\n",
      "Epoch 342/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8938 - mse: 0.8938 - val_loss: 0.2897 - val_mse: 0.2897\n",
      "Epoch 343/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8934 - mse: 0.8934 - val_loss: 0.2899 - val_mse: 0.2899\n",
      "Epoch 344/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8930 - mse: 0.8930 - val_loss: 0.2901 - val_mse: 0.2901\n",
      "Epoch 345/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8926 - mse: 0.8926 - val_loss: 0.2903 - val_mse: 0.2903\n",
      "Epoch 346/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8922 - mse: 0.8922 - val_loss: 0.2905 - val_mse: 0.2905\n",
      "Epoch 347/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8918 - mse: 0.8918 - val_loss: 0.2907 - val_mse: 0.2907\n",
      "Epoch 348/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8913 - mse: 0.8913 - val_loss: 0.2910 - val_mse: 0.2910\n",
      "Epoch 349/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8909 - mse: 0.8909 - val_loss: 0.2912 - val_mse: 0.2912\n",
      "Epoch 350/450\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8905 - mse: 0.8905 - val_loss: 0.2914 - val_mse: 0.2914\n",
      "Epoch 351/450\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8900 - mse: 0.8900 - val_loss: 0.2917 - val_mse: 0.2917\n",
      "Epoch 352/450\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8895 - mse: 0.8895 - val_loss: 0.2919 - val_mse: 0.2919\n",
      "Epoch 353/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8891 - mse: 0.8891 - val_loss: 0.2922 - val_mse: 0.2922\n",
      "Epoch 354/450\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8886 - mse: 0.8886 - val_loss: 0.2924 - val_mse: 0.2924\n",
      "Epoch 355/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8881 - mse: 0.8881 - val_loss: 0.2927 - val_mse: 0.2927\n",
      "Epoch 356/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8876 - mse: 0.8876 - val_loss: 0.2929 - val_mse: 0.2929\n",
      "Epoch 357/450\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8871 - mse: 0.8871 - val_loss: 0.2932 - val_mse: 0.2932\n",
      "Epoch 358/450\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8865 - mse: 0.8865 - val_loss: 0.2935 - val_mse: 0.2935\n",
      "Epoch 359/450\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8860 - mse: 0.8860 - val_loss: 0.2938 - val_mse: 0.2938\n",
      "Epoch 360/450\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8854 - mse: 0.8854 - val_loss: 0.2940 - val_mse: 0.2940\n",
      "Epoch 361/450\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8849 - mse: 0.8849 - val_loss: 0.2943 - val_mse: 0.2943\n",
      "Epoch 362/450\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8843 - mse: 0.8843 - val_loss: 0.2946 - val_mse: 0.2946\n",
      "Epoch 363/450\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8837 - mse: 0.8837 - val_loss: 0.2949 - val_mse: 0.2949\n",
      "Epoch 364/450\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8831 - mse: 0.8831 - val_loss: 0.2952 - val_mse: 0.2952\n",
      "Epoch 365/450\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8825 - mse: 0.8825 - val_loss: 0.2955 - val_mse: 0.2955\n",
      "Epoch 366/450\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8819 - mse: 0.8819 - val_loss: 0.2958 - val_mse: 0.2958\n",
      "Epoch 367/450\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8812 - mse: 0.8812 - val_loss: 0.2961 - val_mse: 0.2961\n",
      "Epoch 368/450\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8806 - mse: 0.8806 - val_loss: 0.2965 - val_mse: 0.2965\n",
      "Epoch 369/450\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8799 - mse: 0.8799 - val_loss: 0.2968 - val_mse: 0.2968\n",
      "Epoch 370/450\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8792 - mse: 0.8792 - val_loss: 0.2971 - val_mse: 0.2971\n",
      "Epoch 371/450\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8785 - mse: 0.8785 - val_loss: 0.2975 - val_mse: 0.2975\n",
      "Epoch 372/450\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8778 - mse: 0.8778 - val_loss: 0.2978 - val_mse: 0.2978\n",
      "Epoch 373/450\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8771 - mse: 0.8771 - val_loss: 0.2981 - val_mse: 0.2981\n",
      "Epoch 374/450\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8763 - mse: 0.8763 - val_loss: 0.2985 - val_mse: 0.2985\n",
      "Epoch 375/450\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.8756 - mse: 0.8756 - val_loss: 0.2989 - val_mse: 0.2989\n",
      "Epoch 376/450\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8748 - mse: 0.8748 - val_loss: 0.2992 - val_mse: 0.2992\n",
      "Epoch 377/450\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8740 - mse: 0.8740 - val_loss: 0.2996 - val_mse: 0.2996\n",
      "Epoch 378/450\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8731 - mse: 0.8731 - val_loss: 0.3000 - val_mse: 0.3000\n",
      "Epoch 379/450\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8723 - mse: 0.8723 - val_loss: 0.3003 - val_mse: 0.3003\n",
      "Epoch 380/450\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8714 - mse: 0.8714 - val_loss: 0.3007 - val_mse: 0.3007\n",
      "Epoch 381/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8705 - mse: 0.8705 - val_loss: 0.3011 - val_mse: 0.3011\n",
      "Epoch 382/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8696 - mse: 0.8696 - val_loss: 0.3015 - val_mse: 0.3015\n",
      "Epoch 383/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8687 - mse: 0.8687 - val_loss: 0.3019 - val_mse: 0.3019\n",
      "Epoch 384/450\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8677 - mse: 0.8677 - val_loss: 0.3023 - val_mse: 0.3023\n",
      "Epoch 385/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8667 - mse: 0.8667 - val_loss: 0.3027 - val_mse: 0.3027\n",
      "Epoch 386/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8657 - mse: 0.8657 - val_loss: 0.3032 - val_mse: 0.3032\n",
      "Epoch 387/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8647 - mse: 0.8647 - val_loss: 0.3036 - val_mse: 0.3036\n",
      "Epoch 388/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8636 - mse: 0.8636 - val_loss: 0.3040 - val_mse: 0.3040\n",
      "Epoch 389/450\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8625 - mse: 0.8625 - val_loss: 0.3044 - val_mse: 0.3044\n",
      "Epoch 390/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8614 - mse: 0.8614 - val_loss: 0.3049 - val_mse: 0.3049\n",
      "Epoch 391/450\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8602 - mse: 0.8602 - val_loss: 0.3053 - val_mse: 0.3053\n",
      "Epoch 392/450\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8591 - mse: 0.8591 - val_loss: 0.3058 - val_mse: 0.3058\n",
      "Epoch 393/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8578 - mse: 0.8578 - val_loss: 0.3062 - val_mse: 0.3062\n",
      "Epoch 394/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8566 - mse: 0.8566 - val_loss: 0.3067 - val_mse: 0.3067\n",
      "Epoch 395/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8553 - mse: 0.8553 - val_loss: 0.3071 - val_mse: 0.3071\n",
      "Epoch 396/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8539 - mse: 0.8539 - val_loss: 0.3076 - val_mse: 0.3076\n",
      "Epoch 397/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8525 - mse: 0.8525 - val_loss: 0.3080 - val_mse: 0.3080\n",
      "Epoch 398/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8511 - mse: 0.8511 - val_loss: 0.3085 - val_mse: 0.3085\n",
      "Epoch 399/450\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8496 - mse: 0.8496 - val_loss: 0.3090 - val_mse: 0.3090\n",
      "Epoch 400/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8481 - mse: 0.8481 - val_loss: 0.3094 - val_mse: 0.3094\n",
      "Epoch 401/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8466 - mse: 0.8466 - val_loss: 0.3099 - val_mse: 0.3099\n",
      "Epoch 402/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8449 - mse: 0.8449 - val_loss: 0.3104 - val_mse: 0.3104\n",
      "Epoch 403/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8433 - mse: 0.8433 - val_loss: 0.3108 - val_mse: 0.3108\n",
      "Epoch 404/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8415 - mse: 0.8415 - val_loss: 0.3113 - val_mse: 0.3113\n",
      "Epoch 405/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8397 - mse: 0.8397 - val_loss: 0.3117 - val_mse: 0.3117\n",
      "Epoch 406/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8379 - mse: 0.8379 - val_loss: 0.3122 - val_mse: 0.3122\n",
      "Epoch 407/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8359 - mse: 0.8359 - val_loss: 0.3126 - val_mse: 0.3126\n",
      "Epoch 408/450\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8339 - mse: 0.8339 - val_loss: 0.3131 - val_mse: 0.3131\n",
      "Epoch 409/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8319 - mse: 0.8319 - val_loss: 0.3135 - val_mse: 0.3135\n",
      "Epoch 410/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8297 - mse: 0.8297 - val_loss: 0.3139 - val_mse: 0.3139\n",
      "Epoch 411/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8275 - mse: 0.8275 - val_loss: 0.3144 - val_mse: 0.3144\n",
      "Epoch 412/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8252 - mse: 0.8252 - val_loss: 0.3148 - val_mse: 0.3148\n",
      "Epoch 413/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8228 - mse: 0.8228 - val_loss: 0.3152 - val_mse: 0.3152\n",
      "Epoch 414/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8203 - mse: 0.8203 - val_loss: 0.3155 - val_mse: 0.3155\n",
      "Epoch 415/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8177 - mse: 0.8177 - val_loss: 0.3159 - val_mse: 0.3159\n",
      "Epoch 416/450\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8151 - mse: 0.8151 - val_loss: 0.3163 - val_mse: 0.3163\n",
      "Epoch 417/450\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8123 - mse: 0.8123 - val_loss: 0.3166 - val_mse: 0.3166\n",
      "Epoch 418/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8094 - mse: 0.8094 - val_loss: 0.3169 - val_mse: 0.3169\n",
      "Epoch 419/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8065 - mse: 0.8065 - val_loss: 0.3172 - val_mse: 0.3172\n",
      "Epoch 420/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8034 - mse: 0.8034 - val_loss: 0.3175 - val_mse: 0.3175\n",
      "Epoch 421/450\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8002 - mse: 0.8002 - val_loss: 0.3178 - val_mse: 0.3178\n",
      "Epoch 422/450\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7969 - mse: 0.7969 - val_loss: 0.3180 - val_mse: 0.3180\n",
      "Epoch 423/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7935 - mse: 0.7935 - val_loss: 0.3183 - val_mse: 0.3183\n",
      "Epoch 424/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7900 - mse: 0.7900 - val_loss: 0.3185 - val_mse: 0.3185\n",
      "Epoch 425/450\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7863 - mse: 0.7863 - val_loss: 0.3186 - val_mse: 0.3186\n",
      "Epoch 426/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7826 - mse: 0.7826 - val_loss: 0.3188 - val_mse: 0.3188\n",
      "Epoch 427/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7787 - mse: 0.7787 - val_loss: 0.3189 - val_mse: 0.3189\n",
      "Epoch 428/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7747 - mse: 0.7747 - val_loss: 0.3190 - val_mse: 0.3190\n",
      "Epoch 429/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7706 - mse: 0.7706 - val_loss: 0.3191 - val_mse: 0.3191\n",
      "Epoch 430/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7664 - mse: 0.7664 - val_loss: 0.3191 - val_mse: 0.3191\n",
      "Epoch 431/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7620 - mse: 0.7620 - val_loss: 0.3191 - val_mse: 0.3191\n",
      "Epoch 432/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7575 - mse: 0.7575 - val_loss: 0.3191 - val_mse: 0.3191\n",
      "Epoch 433/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7529 - mse: 0.7529 - val_loss: 0.3190 - val_mse: 0.3190\n",
      "Epoch 434/450\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7482 - mse: 0.7482 - val_loss: 0.3189 - val_mse: 0.3189\n",
      "Epoch 435/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7433 - mse: 0.7433 - val_loss: 0.3188 - val_mse: 0.3188\n",
      "Epoch 436/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7384 - mse: 0.7384 - val_loss: 0.3186 - val_mse: 0.3186\n",
      "Epoch 437/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7333 - mse: 0.7333 - val_loss: 0.3184 - val_mse: 0.3184\n",
      "Epoch 438/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7281 - mse: 0.7281 - val_loss: 0.3182 - val_mse: 0.3182\n",
      "Epoch 439/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7227 - mse: 0.7227 - val_loss: 0.3179 - val_mse: 0.3179\n",
      "Epoch 440/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7173 - mse: 0.7173 - val_loss: 0.3175 - val_mse: 0.3175\n",
      "Epoch 441/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7117 - mse: 0.7117 - val_loss: 0.3172 - val_mse: 0.3172\n",
      "Epoch 442/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7060 - mse: 0.7060 - val_loss: 0.3167 - val_mse: 0.3167\n",
      "Epoch 443/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7003 - mse: 0.7003 - val_loss: 0.3163 - val_mse: 0.3163\n",
      "Epoch 444/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6943 - mse: 0.6943 - val_loss: 0.3157 - val_mse: 0.3157\n",
      "Epoch 445/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6883 - mse: 0.6883 - val_loss: 0.3152 - val_mse: 0.3152\n",
      "Epoch 446/450\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6822 - mse: 0.6822 - val_loss: 0.3146 - val_mse: 0.3146\n",
      "Epoch 447/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6760 - mse: 0.6760 - val_loss: 0.3139 - val_mse: 0.3139\n",
      "Epoch 448/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6696 - mse: 0.6696 - val_loss: 0.3132 - val_mse: 0.3132\n",
      "Epoch 449/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6632 - mse: 0.6632 - val_loss: 0.3124 - val_mse: 0.3124\n",
      "Epoch 450/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6567 - mse: 0.6567 - val_loss: 0.3116 - val_mse: 0.3116\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# from tensorflow.python.keras.layers import Dense\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "variables,results = split_x_and_y(database.iloc[[0,1,2,3,4,5,6,7,8]],['A','E','N'],'Tmax')\n",
    "test_x,test_y = split_x_and_y(database.iloc[[9,10,11]],['A','E','N'],'Tmax')\n",
    "\n",
    "model = keras.Sequential([\n",
    "  layers.Dense(500, activation='sigmoid', input_shape=[len(variables.keys())]),\n",
    "  # layers.Dropout(0.3),\n",
    "  layers.Dense(500, activation='sigmoid'),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "# optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "model.compile(optimizer='adam',loss='mean_squared_error',metrics=['mse'])\n",
    "\n",
    "history = model.fit(variables.values,results.values,epochs=450,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1d48583d5b0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['loss','val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 95ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 25.        ,   1.        ,   8.        ,  86.05627629],\n",
       "       [ 25.        ,   2.        ,   5.        , 102.64300979],\n",
       "       [ 35.        ,   3.        ,  11.        ,  90.00943901]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guess = model.predict(test_x.values)\n",
    "desnormalizar = test_x.copy()\n",
    "desnormalizar['Tmax'] = guess\n",
    "desnormalizado_teste = standardscaler.inverse_transform(desnormalizar)\n",
    "desnormalizado_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25.  ,  1.  ,  8.  , 76.3 ],\n",
       "       [25.  ,  2.  ,  5.  , 98.76],\n",
       "       [35.  ,  3.  , 11.  , 94.7 ]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desnormalizar = test_x.copy()\n",
    "desnormalizar['Tmax'] = test_y\n",
    "desnormalizado_resultado = standardscaler.inverse_transform(desnormalizar)\n",
    "desnormalizado_resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: 0.538342781496221 meansquarederror: 44.088018149927734 meanabsoluteerror: 6.109949023421696 maxerror: 9.756276286939823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.538342781496221, 44.088018149927734, 6.109949023421696, 9.756276286939823)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores(desnormalizado_resultado[:,-1],desnormalizado_teste[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"keras_model_Tmax.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "edbada794071f9c875b2bc5e0e869a1d746a19a0ba8801f10239845106c51c5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
