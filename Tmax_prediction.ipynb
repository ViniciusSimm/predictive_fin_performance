{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>E</th>\n",
       "      <th>N</th>\n",
       "      <th>Tmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>67.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>126.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>72.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>162.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>94.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>61.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>63.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>77.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>63.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>76.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>98.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>94.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A  E   N    Tmax\n",
       "0   25  1  11   67.67\n",
       "1   25  1   5  126.85\n",
       "2   25  2   8   72.71\n",
       "3   25  3  11  162.85\n",
       "4   25  3   5   94.85\n",
       "5   35  1   8   61.15\n",
       "6   35  2  11   63.03\n",
       "7   35  2   5   77.35\n",
       "8   35  3   8   63.25\n",
       "9   25  1   8   76.30\n",
       "10  25  2   5   98.76\n",
       "11  35  3  11   94.70"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "database = pd.read_excel('database_TCC.xlsx')\n",
    "database = database[['A','E','N','Tmax']]\n",
    "database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standardscaler = StandardScaler()\n",
    "standardscaler.fit(database)\n",
    "data = standardscaler.transform(database)\n",
    "database = pd.DataFrame(data,columns=database.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(standardscaler, open('standard_scaler_Tmax.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error,max_error\n",
    "\n",
    "def split_x_and_y(database,x,y):\n",
    "  dataset_x = database[x]\n",
    "  dataset_y = database[y]\n",
    "  return dataset_x,dataset_y\n",
    "\n",
    "\n",
    "def scores(Y_true, Y_predicted):\n",
    "  r2 = r2_score(Y_true, Y_predicted)\n",
    "  meansquarederror = mean_squared_error(Y_true, Y_predicted)\n",
    "  meanabsoluteerror = mean_absolute_error(Y_true, Y_predicted)\n",
    "  maxerror = max_error(Y_true, Y_predicted)\n",
    "\n",
    "  print('r2:',r2,'meansquarederror:',meansquarederror,'meanabsoluteerror:',meanabsoluteerror,'maxerror:',maxerror)\n",
    "  return r2,meansquarederror,meanabsoluteerror,maxerror\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_x,dataset_y = split_x_and_y(database,['A','E','N'],'Tmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8447830391182938"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RFR = RandomForestRegressor(n_estimators=1000)\n",
    "RFR.fit(dataset_x,dataset_y)\n",
    "RFR.score(dataset_x,dataset_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7053810307734065"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_x,dataset_y = split_x_and_y(database.iloc[[0,1,2,3,4,5,6,7,8]],['A','E','N'],'Tmax')\n",
    "\n",
    "test_x,test_y = split_x_and_y(database.iloc[[9,10,11]],['A','E','N'],'Tmax')\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RFR = RandomForestRegressor(n_estimators=3000,criterion='absolute_error',random_state=100)\n",
    "RFR.fit(dataset_x,dataset_y)\n",
    "RFR.score(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21169354, 0.38198803, 0.40631843])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFR.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(RFR, open('Random_Forest_Regressor_Tmax.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6006148480401164"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_x,dataset_y = split_x_and_y(database.iloc[[0,1,2,3,4,5,6,7,8]],['A','E','N'],'Tmax')\n",
    "\n",
    "test_x,test_y = split_x_and_y(database.iloc[[9,10,11]],['A','E','N'],'Tmax')\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svr = svm.SVR(C=4,kernel ='rbf',gamma='scale')\n",
    "\n",
    "svr.fit(dataset_x,dataset_y)\n",
    "svr.score(test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.830254490027388"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_x,dataset_y = split_x_and_y(database.iloc[[0,1,2,3,4,5,6,7,8]],['A','E','N'],'Tmax')\n",
    "\n",
    "test_x,test_y = split_x_and_y(database.iloc[[9,10,11]],['A','E','N'],'Tmax')\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "MLP = MLPRegressor(max_iter=1000,hidden_layer_sizes=(64,32),activation='relu',solver='adam',learning_rate='constant',momentum=0.9,beta_1=0.6,beta_2=0.959,random_state = 100)\n",
    "MLP.fit(dataset_x,dataset_y)\n",
    "MLP.score(test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial with Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2550390584768786"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_x,dataset_y = split_x_and_y(database.iloc[[0,1,2,3,4,5,6,7,8]],['A','E','N'],'Tmax')\n",
    "\n",
    "test_x,test_y = split_x_and_y(database.iloc[[9,10,11]],['A','E','N'],'Tmax')\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "poly = PolynomialFeatures(4)\n",
    "LR = LinearRegression()\n",
    "\n",
    "dataset_x_transformed = poly.fit_transform(dataset_x)\n",
    "test_x_transformed = poly.fit_transform(test_x)\n",
    "\n",
    "LR.fit(dataset_x_transformed,dataset_y)\n",
    "LR.score(test_x_transformed,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/450\n",
      "1/1 [==============================] - 1s 538ms/step - loss: 1.5233 - mse: 1.5233 - val_loss: 0.9323 - val_mse: 0.9323\n",
      "Epoch 2/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4057 - mse: 4.4057 - val_loss: 0.1655 - val_mse: 0.1655\n",
      "Epoch 3/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.6880 - mse: 1.6880 - val_loss: 2.5342 - val_mse: 2.5342\n",
      "Epoch 4/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.1432 - mse: 2.1432 - val_loss: 4.2233 - val_mse: 4.2233\n",
      "Epoch 5/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.1158 - mse: 3.1158 - val_loss: 3.3451 - val_mse: 3.3451\n",
      "Epoch 6/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.5796 - mse: 2.5796 - val_loss: 1.5953 - val_mse: 1.5953\n",
      "Epoch 7/450\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.6985 - mse: 1.6985 - val_loss: 0.3963 - val_mse: 0.3963\n",
      "Epoch 8/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.5016 - mse: 1.5016 - val_loss: 0.0663 - val_mse: 0.0663\n",
      "Epoch 9/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.9484 - mse: 1.9484 - val_loss: 0.0821 - val_mse: 0.0821\n",
      "Epoch 10/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.2749 - mse: 2.2749 - val_loss: 0.0642 - val_mse: 0.0642\n",
      "Epoch 11/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.0934 - mse: 2.0934 - val_loss: 0.1438 - val_mse: 0.1438\n",
      "Epoch 12/450\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.6734 - mse: 1.6734 - val_loss: 0.5637 - val_mse: 0.5637\n",
      "Epoch 13/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.4422 - mse: 1.4422 - val_loss: 1.2798 - val_mse: 1.2798\n",
      "Epoch 14/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.5519 - mse: 1.5519 - val_loss: 1.9075 - val_mse: 1.9075\n",
      "Epoch 15/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.7878 - mse: 1.7878 - val_loss: 2.0645 - val_mse: 2.0645\n",
      "Epoch 16/450\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.8539 - mse: 1.8539 - val_loss: 1.7096 - val_mse: 1.7096\n",
      "Epoch 17/450\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.6926 - mse: 1.6926 - val_loss: 1.1076 - val_mse: 1.1076\n",
      "Epoch 18/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4802 - mse: 1.4802 - val_loss: 0.5734 - val_mse: 0.5734\n",
      "Epoch 19/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4063 - mse: 1.4063 - val_loss: 0.2648 - val_mse: 0.2648\n",
      "Epoch 20/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4951 - mse: 1.4951 - val_loss: 0.1513 - val_mse: 0.1513\n",
      "Epoch 21/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.6092 - mse: 1.6092 - val_loss: 0.1456 - val_mse: 0.1456\n",
      "Epoch 22/450\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.6127 - mse: 1.6127 - val_loss: 0.2281 - val_mse: 0.2281\n",
      "Epoch 23/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.5052 - mse: 1.5052 - val_loss: 0.4370 - val_mse: 0.4370\n",
      "Epoch 24/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3947 - mse: 1.3947 - val_loss: 0.7672 - val_mse: 0.7672\n",
      "Epoch 25/450\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.3742 - mse: 1.3742 - val_loss: 1.1089 - val_mse: 1.1089\n",
      "Epoch 26/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4333 - mse: 1.4333 - val_loss: 1.3011 - val_mse: 1.3011\n",
      "Epoch 27/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.4843 - mse: 1.4843 - val_loss: 1.2541 - val_mse: 1.2541\n",
      "Epoch 28/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.4631 - mse: 1.4631 - val_loss: 1.0133 - val_mse: 1.0133\n",
      "Epoch 29/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.3907 - mse: 1.3907 - val_loss: 0.7109 - val_mse: 0.7109\n",
      "Epoch 30/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.3368 - mse: 1.3368 - val_loss: 0.4672 - val_mse: 0.4672\n",
      "Epoch 31/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.3411 - mse: 1.3411 - val_loss: 0.3306 - val_mse: 0.3306\n",
      "Epoch 32/450\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.3770 - mse: 1.3770 - val_loss: 0.2934 - val_mse: 0.2934\n",
      "Epoch 33/450\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3895 - mse: 1.3895 - val_loss: 0.3408 - val_mse: 0.3408\n",
      "Epoch 34/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3578 - mse: 1.3578 - val_loss: 0.4695 - val_mse: 0.4695\n",
      "Epoch 35/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.3119 - mse: 1.3119 - val_loss: 0.6606 - val_mse: 0.6606\n",
      "Epoch 36/450\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.2922 - mse: 1.2922 - val_loss: 0.8535 - val_mse: 0.8535\n",
      "Epoch 37/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.3045 - mse: 1.3045 - val_loss: 0.9662 - val_mse: 0.9662\n",
      "Epoch 38/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3189 - mse: 1.3189 - val_loss: 0.9494 - val_mse: 0.9494\n",
      "Epoch 39/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.3081 - mse: 1.3081 - val_loss: 0.8215 - val_mse: 0.8215\n",
      "Epoch 40/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2776 - mse: 1.2776 - val_loss: 0.6506 - val_mse: 0.6506\n",
      "Epoch 41/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2543 - mse: 1.2543 - val_loss: 0.5053 - val_mse: 0.5053\n",
      "Epoch 42/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2527 - mse: 1.2527 - val_loss: 0.4225 - val_mse: 0.4225\n",
      "Epoch 43/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2601 - mse: 1.2601 - val_loss: 0.4089 - val_mse: 0.4089\n",
      "Epoch 44/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2556 - mse: 1.2556 - val_loss: 0.4594 - val_mse: 0.4594\n",
      "Epoch 45/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2356 - mse: 1.2356 - val_loss: 0.5608 - val_mse: 0.5608\n",
      "Epoch 46/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.2156 - mse: 1.2156 - val_loss: 0.6824 - val_mse: 0.6824\n",
      "Epoch 47/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2086 - mse: 1.2086 - val_loss: 0.7766 - val_mse: 0.7766\n",
      "Epoch 48/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2098 - mse: 1.2098 - val_loss: 0.8021 - val_mse: 0.8021\n",
      "Epoch 49/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2055 - mse: 1.2055 - val_loss: 0.7513 - val_mse: 0.7513\n",
      "Epoch 50/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1909 - mse: 1.1909 - val_loss: 0.6542 - val_mse: 0.6542\n",
      "Epoch 51/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1748 - mse: 1.1748 - val_loss: 0.5555 - val_mse: 0.5555\n",
      "Epoch 52/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1666 - mse: 1.1666 - val_loss: 0.4894 - val_mse: 0.4894\n",
      "Epoch 53/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1642 - mse: 1.1642 - val_loss: 0.4704 - val_mse: 0.4704\n",
      "Epoch 54/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1586 - mse: 1.1586 - val_loss: 0.4981 - val_mse: 0.4981\n",
      "Epoch 55/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1464 - mse: 1.1464 - val_loss: 0.5609 - val_mse: 0.5609\n",
      "Epoch 56/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.1335 - mse: 1.1335 - val_loss: 0.6347 - val_mse: 0.6347\n",
      "Epoch 57/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1257 - mse: 1.1257 - val_loss: 0.6882 - val_mse: 0.6882\n",
      "Epoch 58/450\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.1214 - mse: 1.1214 - val_loss: 0.6973 - val_mse: 0.6973\n",
      "Epoch 59/450\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1146 - mse: 1.1146 - val_loss: 0.6601 - val_mse: 0.6601\n",
      "Epoch 60/450\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1038 - mse: 1.1038 - val_loss: 0.5973 - val_mse: 0.5973\n",
      "Epoch 61/450\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0933 - mse: 1.0933 - val_loss: 0.5374 - val_mse: 0.5374\n",
      "Epoch 62/450\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.0865 - mse: 1.0865 - val_loss: 0.5019 - val_mse: 0.5019\n",
      "Epoch 63/450\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.0811 - mse: 1.0811 - val_loss: 0.4992 - val_mse: 0.4992\n",
      "Epoch 64/450\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0737 - mse: 1.0737 - val_loss: 0.5259 - val_mse: 0.5259\n",
      "Epoch 65/450\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0642 - mse: 1.0642 - val_loss: 0.5690 - val_mse: 0.5690\n",
      "Epoch 66/450\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0559 - mse: 1.0559 - val_loss: 0.6082 - val_mse: 0.6082\n",
      "Epoch 67/450\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0499 - mse: 1.0499 - val_loss: 0.6243 - val_mse: 0.6243\n",
      "Epoch 68/450\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0441 - mse: 1.0441 - val_loss: 0.6099 - val_mse: 0.6099\n",
      "Epoch 69/450\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0367 - mse: 1.0367 - val_loss: 0.5731 - val_mse: 0.5731\n",
      "Epoch 70/450\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0288 - mse: 1.0288 - val_loss: 0.5318 - val_mse: 0.5318\n",
      "Epoch 71/450\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0223 - mse: 1.0223 - val_loss: 0.5029 - val_mse: 0.5029\n",
      "Epoch 72/450\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0171 - mse: 1.0171 - val_loss: 0.4949 - val_mse: 0.4949\n",
      "Epoch 73/450\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0113 - mse: 1.0113 - val_loss: 0.5073 - val_mse: 0.5073\n",
      "Epoch 74/450\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.0047 - mse: 1.0047 - val_loss: 0.5314 - val_mse: 0.5314\n",
      "Epoch 75/450\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9985 - mse: 0.9985 - val_loss: 0.5538 - val_mse: 0.5538\n",
      "Epoch 76/450\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9936 - mse: 0.9936 - val_loss: 0.5618 - val_mse: 0.5618\n",
      "Epoch 77/450\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.9889 - mse: 0.9889 - val_loss: 0.5509 - val_mse: 0.5509\n",
      "Epoch 78/450\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.9837 - mse: 0.9837 - val_loss: 0.5263 - val_mse: 0.5263\n",
      "Epoch 79/450\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.9785 - mse: 0.9785 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 80/450\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9740 - mse: 0.9740 - val_loss: 0.4820 - val_mse: 0.4820\n",
      "Epoch 81/450\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9702 - mse: 0.9702 - val_loss: 0.4780 - val_mse: 0.4780\n",
      "Epoch 82/450\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9663 - mse: 0.9663 - val_loss: 0.4863 - val_mse: 0.4863\n",
      "Epoch 83/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9621 - mse: 0.9621 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 84/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9585 - mse: 0.9585 - val_loss: 0.5099 - val_mse: 0.5099\n",
      "Epoch 85/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9555 - mse: 0.9555 - val_loss: 0.5094 - val_mse: 0.5094\n",
      "Epoch 86/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9525 - mse: 0.9525 - val_loss: 0.4978 - val_mse: 0.4978\n",
      "Epoch 87/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9495 - mse: 0.9495 - val_loss: 0.4805 - val_mse: 0.4805\n",
      "Epoch 88/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9467 - mse: 0.9467 - val_loss: 0.4651 - val_mse: 0.4651\n",
      "Epoch 89/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9444 - mse: 0.9444 - val_loss: 0.4572 - val_mse: 0.4572\n",
      "Epoch 90/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9424 - mse: 0.9424 - val_loss: 0.4579 - val_mse: 0.4579\n",
      "Epoch 91/450\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9403 - mse: 0.9403 - val_loss: 0.4643 - val_mse: 0.4643\n",
      "Epoch 92/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9383 - mse: 0.9383 - val_loss: 0.4707 - val_mse: 0.4707\n",
      "Epoch 93/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9367 - mse: 0.9367 - val_loss: 0.4720 - val_mse: 0.4720\n",
      "Epoch 94/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9354 - mse: 0.9354 - val_loss: 0.4662 - val_mse: 0.4662\n",
      "Epoch 95/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9340 - mse: 0.9340 - val_loss: 0.4556 - val_mse: 0.4556\n",
      "Epoch 96/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9327 - mse: 0.9327 - val_loss: 0.4447 - val_mse: 0.4447\n",
      "Epoch 97/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9317 - mse: 0.9317 - val_loss: 0.4378 - val_mse: 0.4378\n",
      "Epoch 98/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9308 - mse: 0.9308 - val_loss: 0.4362 - val_mse: 0.4362\n",
      "Epoch 99/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9300 - mse: 0.9300 - val_loss: 0.4386 - val_mse: 0.4386\n",
      "Epoch 100/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9292 - mse: 0.9292 - val_loss: 0.4417 - val_mse: 0.4417\n",
      "Epoch 101/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9285 - mse: 0.9285 - val_loss: 0.4420 - val_mse: 0.4420\n",
      "Epoch 102/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9280 - mse: 0.9280 - val_loss: 0.4380 - val_mse: 0.4380\n",
      "Epoch 103/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9275 - mse: 0.9275 - val_loss: 0.4307 - val_mse: 0.4307\n",
      "Epoch 104/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9270 - mse: 0.9270 - val_loss: 0.4231 - val_mse: 0.4231\n",
      "Epoch 105/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9266 - mse: 0.9266 - val_loss: 0.4178 - val_mse: 0.4178\n",
      "Epoch 106/450\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9262 - mse: 0.9262 - val_loss: 0.4157 - val_mse: 0.4157\n",
      "Epoch 107/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9259 - mse: 0.9259 - val_loss: 0.4161 - val_mse: 0.4161\n",
      "Epoch 108/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9255 - mse: 0.9255 - val_loss: 0.4167 - val_mse: 0.4167\n",
      "Epoch 109/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9252 - mse: 0.9252 - val_loss: 0.4156 - val_mse: 0.4156\n",
      "Epoch 110/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9250 - mse: 0.9250 - val_loss: 0.4117 - val_mse: 0.4117\n",
      "Epoch 111/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9247 - mse: 0.9247 - val_loss: 0.4060 - val_mse: 0.4060\n",
      "Epoch 112/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9244 - mse: 0.9244 - val_loss: 0.4002 - val_mse: 0.4002\n",
      "Epoch 113/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9242 - mse: 0.9242 - val_loss: 0.3961 - val_mse: 0.3961\n",
      "Epoch 114/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9239 - mse: 0.9239 - val_loss: 0.3940 - val_mse: 0.3940\n",
      "Epoch 115/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9237 - mse: 0.9237 - val_loss: 0.3932 - val_mse: 0.3932\n",
      "Epoch 116/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9234 - mse: 0.9234 - val_loss: 0.3922 - val_mse: 0.3922\n",
      "Epoch 117/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9232 - mse: 0.9232 - val_loss: 0.3899 - val_mse: 0.3899\n",
      "Epoch 118/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9229 - mse: 0.9229 - val_loss: 0.3860 - val_mse: 0.3860\n",
      "Epoch 119/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9227 - mse: 0.9227 - val_loss: 0.3812 - val_mse: 0.3812\n",
      "Epoch 120/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9224 - mse: 0.9224 - val_loss: 0.3768 - val_mse: 0.3768\n",
      "Epoch 121/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9222 - mse: 0.9222 - val_loss: 0.3735 - val_mse: 0.3735\n",
      "Epoch 122/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9220 - mse: 0.9220 - val_loss: 0.3716 - val_mse: 0.3716\n",
      "Epoch 123/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9217 - mse: 0.9217 - val_loss: 0.3702 - val_mse: 0.3702\n",
      "Epoch 124/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9215 - mse: 0.9215 - val_loss: 0.3684 - val_mse: 0.3684\n",
      "Epoch 125/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9213 - mse: 0.9213 - val_loss: 0.3656 - val_mse: 0.3656\n",
      "Epoch 126/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9211 - mse: 0.9211 - val_loss: 0.3619 - val_mse: 0.3619\n",
      "Epoch 127/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9209 - mse: 0.9209 - val_loss: 0.3581 - val_mse: 0.3581\n",
      "Epoch 128/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9206 - mse: 0.9206 - val_loss: 0.3548 - val_mse: 0.3548\n",
      "Epoch 129/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9204 - mse: 0.9204 - val_loss: 0.3524 - val_mse: 0.3524\n",
      "Epoch 130/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9203 - mse: 0.9203 - val_loss: 0.3507 - val_mse: 0.3507\n",
      "Epoch 131/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9201 - mse: 0.9201 - val_loss: 0.3491 - val_mse: 0.3491\n",
      "Epoch 132/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9199 - mse: 0.9199 - val_loss: 0.3470 - val_mse: 0.3470\n",
      "Epoch 133/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9197 - mse: 0.9197 - val_loss: 0.3443 - val_mse: 0.3443\n",
      "Epoch 134/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9195 - mse: 0.9195 - val_loss: 0.3412 - val_mse: 0.3412\n",
      "Epoch 135/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9194 - mse: 0.9194 - val_loss: 0.3384 - val_mse: 0.3384\n",
      "Epoch 136/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9192 - mse: 0.9192 - val_loss: 0.3361 - val_mse: 0.3361\n",
      "Epoch 137/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9191 - mse: 0.9191 - val_loss: 0.3344 - val_mse: 0.3344\n",
      "Epoch 138/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9189 - mse: 0.9189 - val_loss: 0.3330 - val_mse: 0.3330\n",
      "Epoch 139/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9188 - mse: 0.9188 - val_loss: 0.3314 - val_mse: 0.3314\n",
      "Epoch 140/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9187 - mse: 0.9187 - val_loss: 0.3294 - val_mse: 0.3294\n",
      "Epoch 141/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9186 - mse: 0.9186 - val_loss: 0.3271 - val_mse: 0.3271\n",
      "Epoch 142/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9184 - mse: 0.9184 - val_loss: 0.3248 - val_mse: 0.3248\n",
      "Epoch 143/450\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9183 - mse: 0.9183 - val_loss: 0.3229 - val_mse: 0.3229\n",
      "Epoch 144/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9182 - mse: 0.9182 - val_loss: 0.3214 - val_mse: 0.3214\n",
      "Epoch 145/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9181 - mse: 0.9181 - val_loss: 0.3202 - val_mse: 0.3202\n",
      "Epoch 146/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9180 - mse: 0.9180 - val_loss: 0.3189 - val_mse: 0.3189\n",
      "Epoch 147/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9179 - mse: 0.9179 - val_loss: 0.3174 - val_mse: 0.3174\n",
      "Epoch 148/450\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9178 - mse: 0.9178 - val_loss: 0.3157 - val_mse: 0.3157\n",
      "Epoch 149/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9177 - mse: 0.9177 - val_loss: 0.3140 - val_mse: 0.3140\n",
      "Epoch 150/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9177 - mse: 0.9177 - val_loss: 0.3124 - val_mse: 0.3124\n",
      "Epoch 151/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9176 - mse: 0.9176 - val_loss: 0.3112 - val_mse: 0.3112\n",
      "Epoch 152/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9175 - mse: 0.9175 - val_loss: 0.3102 - val_mse: 0.3102\n",
      "Epoch 153/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9174 - mse: 0.9174 - val_loss: 0.3092 - val_mse: 0.3092\n",
      "Epoch 154/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9173 - mse: 0.9173 - val_loss: 0.3081 - val_mse: 0.3081\n",
      "Epoch 155/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9173 - mse: 0.9173 - val_loss: 0.3068 - val_mse: 0.3068\n",
      "Epoch 156/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9172 - mse: 0.9172 - val_loss: 0.3055 - val_mse: 0.3055\n",
      "Epoch 157/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9171 - mse: 0.9171 - val_loss: 0.3044 - val_mse: 0.3044\n",
      "Epoch 158/450\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9170 - mse: 0.9170 - val_loss: 0.3034 - val_mse: 0.3034\n",
      "Epoch 159/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9170 - mse: 0.9170 - val_loss: 0.3026 - val_mse: 0.3026\n",
      "Epoch 160/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9169 - mse: 0.9169 - val_loss: 0.3018 - val_mse: 0.3018\n",
      "Epoch 161/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9169 - mse: 0.9169 - val_loss: 0.3010 - val_mse: 0.3010\n",
      "Epoch 162/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9168 - mse: 0.9168 - val_loss: 0.3000 - val_mse: 0.3000\n",
      "Epoch 163/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9167 - mse: 0.9167 - val_loss: 0.2990 - val_mse: 0.2990\n",
      "Epoch 164/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9167 - mse: 0.9167 - val_loss: 0.2981 - val_mse: 0.2981\n",
      "Epoch 165/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9166 - mse: 0.9166 - val_loss: 0.2974 - val_mse: 0.2974\n",
      "Epoch 166/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9165 - mse: 0.9165 - val_loss: 0.2968 - val_mse: 0.2968\n",
      "Epoch 167/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9165 - mse: 0.9165 - val_loss: 0.2961 - val_mse: 0.2961\n",
      "Epoch 168/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9164 - mse: 0.9164 - val_loss: 0.2955 - val_mse: 0.2955\n",
      "Epoch 169/450\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9164 - mse: 0.9164 - val_loss: 0.2948 - val_mse: 0.2948\n",
      "Epoch 170/450\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9163 - mse: 0.9163 - val_loss: 0.2940 - val_mse: 0.2940\n",
      "Epoch 171/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9163 - mse: 0.9163 - val_loss: 0.2933 - val_mse: 0.2933\n",
      "Epoch 172/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9162 - mse: 0.9162 - val_loss: 0.2928 - val_mse: 0.2928\n",
      "Epoch 173/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9162 - mse: 0.9162 - val_loss: 0.2923 - val_mse: 0.2923\n",
      "Epoch 174/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9161 - mse: 0.9161 - val_loss: 0.2918 - val_mse: 0.2918\n",
      "Epoch 175/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9161 - mse: 0.9161 - val_loss: 0.2913 - val_mse: 0.2913\n",
      "Epoch 176/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9160 - mse: 0.9160 - val_loss: 0.2907 - val_mse: 0.2907\n",
      "Epoch 177/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9160 - mse: 0.9160 - val_loss: 0.2902 - val_mse: 0.2902\n",
      "Epoch 178/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9159 - mse: 0.9159 - val_loss: 0.2897 - val_mse: 0.2897\n",
      "Epoch 179/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9159 - mse: 0.9159 - val_loss: 0.2892 - val_mse: 0.2892\n",
      "Epoch 180/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9158 - mse: 0.9158 - val_loss: 0.2889 - val_mse: 0.2889\n",
      "Epoch 181/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9158 - mse: 0.9158 - val_loss: 0.2885 - val_mse: 0.2885\n",
      "Epoch 182/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9157 - mse: 0.9157 - val_loss: 0.2881 - val_mse: 0.2881\n",
      "Epoch 183/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9157 - mse: 0.9157 - val_loss: 0.2877 - val_mse: 0.2877\n",
      "Epoch 184/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9156 - mse: 0.9156 - val_loss: 0.2872 - val_mse: 0.2872\n",
      "Epoch 185/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9156 - mse: 0.9156 - val_loss: 0.2869 - val_mse: 0.2869\n",
      "Epoch 186/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9155 - mse: 0.9155 - val_loss: 0.2865 - val_mse: 0.2865\n",
      "Epoch 187/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9155 - mse: 0.9155 - val_loss: 0.2863 - val_mse: 0.2863\n",
      "Epoch 188/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9154 - mse: 0.9154 - val_loss: 0.2860 - val_mse: 0.2860\n",
      "Epoch 189/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9154 - mse: 0.9154 - val_loss: 0.2856 - val_mse: 0.2856\n",
      "Epoch 190/450\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9153 - mse: 0.9153 - val_loss: 0.2853 - val_mse: 0.2853\n",
      "Epoch 191/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9153 - mse: 0.9153 - val_loss: 0.2850 - val_mse: 0.2850\n",
      "Epoch 192/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9152 - mse: 0.9152 - val_loss: 0.2847 - val_mse: 0.2847\n",
      "Epoch 193/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9152 - mse: 0.9152 - val_loss: 0.2845 - val_mse: 0.2845\n",
      "Epoch 194/450\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.9151 - mse: 0.9151 - val_loss: 0.2843 - val_mse: 0.2843\n",
      "Epoch 195/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9151 - mse: 0.9151 - val_loss: 0.2841 - val_mse: 0.2841\n",
      "Epoch 196/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9150 - mse: 0.9150 - val_loss: 0.2838 - val_mse: 0.2838\n",
      "Epoch 197/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9150 - mse: 0.9150 - val_loss: 0.2836 - val_mse: 0.2836\n",
      "Epoch 198/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9149 - mse: 0.9149 - val_loss: 0.2833 - val_mse: 0.2833\n",
      "Epoch 199/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9149 - mse: 0.9149 - val_loss: 0.2831 - val_mse: 0.2831\n",
      "Epoch 200/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9148 - mse: 0.9148 - val_loss: 0.2830 - val_mse: 0.2830\n",
      "Epoch 201/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9148 - mse: 0.9148 - val_loss: 0.2828 - val_mse: 0.2828\n",
      "Epoch 202/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9147 - mse: 0.9147 - val_loss: 0.2826 - val_mse: 0.2826\n",
      "Epoch 203/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9146 - mse: 0.9146 - val_loss: 0.2824 - val_mse: 0.2824\n",
      "Epoch 204/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9146 - mse: 0.9146 - val_loss: 0.2823 - val_mse: 0.2823\n",
      "Epoch 205/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9145 - mse: 0.9145 - val_loss: 0.2821 - val_mse: 0.2821\n",
      "Epoch 206/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9145 - mse: 0.9145 - val_loss: 0.2820 - val_mse: 0.2820\n",
      "Epoch 207/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9144 - mse: 0.9144 - val_loss: 0.2818 - val_mse: 0.2818\n",
      "Epoch 208/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9144 - mse: 0.9144 - val_loss: 0.2817 - val_mse: 0.2817\n",
      "Epoch 209/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9143 - mse: 0.9143 - val_loss: 0.2816 - val_mse: 0.2816\n",
      "Epoch 210/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9143 - mse: 0.9143 - val_loss: 0.2814 - val_mse: 0.2814\n",
      "Epoch 211/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9142 - mse: 0.9142 - val_loss: 0.2813 - val_mse: 0.2813\n",
      "Epoch 212/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9142 - mse: 0.9142 - val_loss: 0.2812 - val_mse: 0.2812\n",
      "Epoch 213/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9141 - mse: 0.9141 - val_loss: 0.2811 - val_mse: 0.2811\n",
      "Epoch 214/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9140 - mse: 0.9140 - val_loss: 0.2810 - val_mse: 0.2810\n",
      "Epoch 215/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9140 - mse: 0.9140 - val_loss: 0.2809 - val_mse: 0.2809\n",
      "Epoch 216/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9139 - mse: 0.9139 - val_loss: 0.2809 - val_mse: 0.2809\n",
      "Epoch 217/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9139 - mse: 0.9139 - val_loss: 0.2808 - val_mse: 0.2808\n",
      "Epoch 218/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9138 - mse: 0.9138 - val_loss: 0.2807 - val_mse: 0.2807\n",
      "Epoch 219/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9137 - mse: 0.9137 - val_loss: 0.2806 - val_mse: 0.2806\n",
      "Epoch 220/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9137 - mse: 0.9137 - val_loss: 0.2806 - val_mse: 0.2806\n",
      "Epoch 221/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9136 - mse: 0.9136 - val_loss: 0.2805 - val_mse: 0.2805\n",
      "Epoch 222/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9135 - mse: 0.9135 - val_loss: 0.2805 - val_mse: 0.2805\n",
      "Epoch 223/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9135 - mse: 0.9135 - val_loss: 0.2804 - val_mse: 0.2804\n",
      "Epoch 224/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9134 - mse: 0.9134 - val_loss: 0.2804 - val_mse: 0.2804\n",
      "Epoch 225/450\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9134 - mse: 0.9134 - val_loss: 0.2803 - val_mse: 0.2803\n",
      "Epoch 226/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9133 - mse: 0.9133 - val_loss: 0.2803 - val_mse: 0.2803\n",
      "Epoch 227/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9132 - mse: 0.9132 - val_loss: 0.2803 - val_mse: 0.2803\n",
      "Epoch 228/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9132 - mse: 0.9132 - val_loss: 0.2802 - val_mse: 0.2802\n",
      "Epoch 229/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9131 - mse: 0.9131 - val_loss: 0.2802 - val_mse: 0.2802\n",
      "Epoch 230/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9130 - mse: 0.9130 - val_loss: 0.2802 - val_mse: 0.2802\n",
      "Epoch 231/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9130 - mse: 0.9130 - val_loss: 0.2802 - val_mse: 0.2802\n",
      "Epoch 232/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9129 - mse: 0.9129 - val_loss: 0.2801 - val_mse: 0.2801\n",
      "Epoch 233/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9128 - mse: 0.9128 - val_loss: 0.2801 - val_mse: 0.2801\n",
      "Epoch 234/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9127 - mse: 0.9127 - val_loss: 0.2801 - val_mse: 0.2801\n",
      "Epoch 235/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9127 - mse: 0.9127 - val_loss: 0.2801 - val_mse: 0.2801\n",
      "Epoch 236/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9126 - mse: 0.9126 - val_loss: 0.2801 - val_mse: 0.2801\n",
      "Epoch 237/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9125 - mse: 0.9125 - val_loss: 0.2801 - val_mse: 0.2801\n",
      "Epoch 238/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9124 - mse: 0.9124 - val_loss: 0.2801 - val_mse: 0.2801\n",
      "Epoch 239/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9124 - mse: 0.9124 - val_loss: 0.2801 - val_mse: 0.2801\n",
      "Epoch 240/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9123 - mse: 0.9123 - val_loss: 0.2801 - val_mse: 0.2801\n",
      "Epoch 241/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9122 - mse: 0.9122 - val_loss: 0.2802 - val_mse: 0.2802\n",
      "Epoch 242/450\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.9121 - mse: 0.9121 - val_loss: 0.2802 - val_mse: 0.2802\n",
      "Epoch 243/450\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.9121 - mse: 0.9121 - val_loss: 0.2802 - val_mse: 0.2802\n",
      "Epoch 244/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9120 - mse: 0.9120 - val_loss: 0.2802 - val_mse: 0.2802\n",
      "Epoch 245/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9119 - mse: 0.9119 - val_loss: 0.2802 - val_mse: 0.2802\n",
      "Epoch 246/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9118 - mse: 0.9118 - val_loss: 0.2802 - val_mse: 0.2802\n",
      "Epoch 247/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9117 - mse: 0.9117 - val_loss: 0.2803 - val_mse: 0.2803\n",
      "Epoch 248/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9116 - mse: 0.9116 - val_loss: 0.2803 - val_mse: 0.2803\n",
      "Epoch 249/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9115 - mse: 0.9115 - val_loss: 0.2803 - val_mse: 0.2803\n",
      "Epoch 250/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9115 - mse: 0.9115 - val_loss: 0.2803 - val_mse: 0.2803\n",
      "Epoch 251/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9114 - mse: 0.9114 - val_loss: 0.2804 - val_mse: 0.2804\n",
      "Epoch 252/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9113 - mse: 0.9113 - val_loss: 0.2804 - val_mse: 0.2804\n",
      "Epoch 253/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9112 - mse: 0.9112 - val_loss: 0.2804 - val_mse: 0.2804\n",
      "Epoch 254/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9111 - mse: 0.9111 - val_loss: 0.2805 - val_mse: 0.2805\n",
      "Epoch 255/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9110 - mse: 0.9110 - val_loss: 0.2805 - val_mse: 0.2805\n",
      "Epoch 256/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9109 - mse: 0.9109 - val_loss: 0.2805 - val_mse: 0.2805\n",
      "Epoch 257/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9108 - mse: 0.9108 - val_loss: 0.2806 - val_mse: 0.2806\n",
      "Epoch 258/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9107 - mse: 0.9107 - val_loss: 0.2806 - val_mse: 0.2806\n",
      "Epoch 259/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9106 - mse: 0.9106 - val_loss: 0.2807 - val_mse: 0.2807\n",
      "Epoch 260/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9105 - mse: 0.9105 - val_loss: 0.2807 - val_mse: 0.2807\n",
      "Epoch 261/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9104 - mse: 0.9104 - val_loss: 0.2807 - val_mse: 0.2807\n",
      "Epoch 262/450\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9103 - mse: 0.9103 - val_loss: 0.2808 - val_mse: 0.2808\n",
      "Epoch 263/450\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9102 - mse: 0.9102 - val_loss: 0.2808 - val_mse: 0.2808\n",
      "Epoch 264/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9101 - mse: 0.9101 - val_loss: 0.2809 - val_mse: 0.2809\n",
      "Epoch 265/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9100 - mse: 0.9100 - val_loss: 0.2809 - val_mse: 0.2809\n",
      "Epoch 266/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9099 - mse: 0.9099 - val_loss: 0.2810 - val_mse: 0.2810\n",
      "Epoch 267/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9098 - mse: 0.9098 - val_loss: 0.2810 - val_mse: 0.2810\n",
      "Epoch 268/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9097 - mse: 0.9097 - val_loss: 0.2811 - val_mse: 0.2811\n",
      "Epoch 269/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9096 - mse: 0.9096 - val_loss: 0.2811 - val_mse: 0.2811\n",
      "Epoch 270/450\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9094 - mse: 0.9094 - val_loss: 0.2812 - val_mse: 0.2812\n",
      "Epoch 271/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9093 - mse: 0.9093 - val_loss: 0.2813 - val_mse: 0.2813\n",
      "Epoch 272/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9092 - mse: 0.9092 - val_loss: 0.2813 - val_mse: 0.2813\n",
      "Epoch 273/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9091 - mse: 0.9091 - val_loss: 0.2814 - val_mse: 0.2814\n",
      "Epoch 274/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9090 - mse: 0.9090 - val_loss: 0.2814 - val_mse: 0.2814\n",
      "Epoch 275/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9088 - mse: 0.9088 - val_loss: 0.2815 - val_mse: 0.2815\n",
      "Epoch 276/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9087 - mse: 0.9087 - val_loss: 0.2816 - val_mse: 0.2816\n",
      "Epoch 277/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9086 - mse: 0.9086 - val_loss: 0.2816 - val_mse: 0.2816\n",
      "Epoch 278/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9085 - mse: 0.9085 - val_loss: 0.2817 - val_mse: 0.2817\n",
      "Epoch 279/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9083 - mse: 0.9083 - val_loss: 0.2818 - val_mse: 0.2818\n",
      "Epoch 280/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9082 - mse: 0.9082 - val_loss: 0.2818 - val_mse: 0.2818\n",
      "Epoch 281/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9081 - mse: 0.9081 - val_loss: 0.2819 - val_mse: 0.2819\n",
      "Epoch 282/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9079 - mse: 0.9079 - val_loss: 0.2820 - val_mse: 0.2820\n",
      "Epoch 283/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9078 - mse: 0.9078 - val_loss: 0.2821 - val_mse: 0.2821\n",
      "Epoch 284/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9077 - mse: 0.9077 - val_loss: 0.2821 - val_mse: 0.2821\n",
      "Epoch 285/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9075 - mse: 0.9075 - val_loss: 0.2822 - val_mse: 0.2822\n",
      "Epoch 286/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9074 - mse: 0.9074 - val_loss: 0.2823 - val_mse: 0.2823\n",
      "Epoch 287/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9072 - mse: 0.9072 - val_loss: 0.2824 - val_mse: 0.2824\n",
      "Epoch 288/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9071 - mse: 0.9071 - val_loss: 0.2824 - val_mse: 0.2824\n",
      "Epoch 289/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9069 - mse: 0.9069 - val_loss: 0.2825 - val_mse: 0.2825\n",
      "Epoch 290/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9068 - mse: 0.9068 - val_loss: 0.2826 - val_mse: 0.2826\n",
      "Epoch 291/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9066 - mse: 0.9066 - val_loss: 0.2827 - val_mse: 0.2827\n",
      "Epoch 292/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9064 - mse: 0.9064 - val_loss: 0.2828 - val_mse: 0.2828\n",
      "Epoch 293/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9063 - mse: 0.9063 - val_loss: 0.2829 - val_mse: 0.2829\n",
      "Epoch 294/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9061 - mse: 0.9061 - val_loss: 0.2829 - val_mse: 0.2829\n",
      "Epoch 295/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9060 - mse: 0.9060 - val_loss: 0.2830 - val_mse: 0.2830\n",
      "Epoch 296/450\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9058 - mse: 0.9058 - val_loss: 0.2831 - val_mse: 0.2831\n",
      "Epoch 297/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9056 - mse: 0.9056 - val_loss: 0.2832 - val_mse: 0.2832\n",
      "Epoch 298/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9054 - mse: 0.9054 - val_loss: 0.2833 - val_mse: 0.2833\n",
      "Epoch 299/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9053 - mse: 0.9053 - val_loss: 0.2834 - val_mse: 0.2834\n",
      "Epoch 300/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9051 - mse: 0.9051 - val_loss: 0.2835 - val_mse: 0.2835\n",
      "Epoch 301/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9049 - mse: 0.9049 - val_loss: 0.2836 - val_mse: 0.2836\n",
      "Epoch 302/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9047 - mse: 0.9047 - val_loss: 0.2837 - val_mse: 0.2837\n",
      "Epoch 303/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9045 - mse: 0.9045 - val_loss: 0.2838 - val_mse: 0.2838\n",
      "Epoch 304/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9043 - mse: 0.9043 - val_loss: 0.2839 - val_mse: 0.2839\n",
      "Epoch 305/450\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.9041 - mse: 0.9041 - val_loss: 0.2840 - val_mse: 0.2840\n",
      "Epoch 306/450\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9039 - mse: 0.9039 - val_loss: 0.2841 - val_mse: 0.2841\n",
      "Epoch 307/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9037 - mse: 0.9037 - val_loss: 0.2843 - val_mse: 0.2843\n",
      "Epoch 308/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9035 - mse: 0.9035 - val_loss: 0.2844 - val_mse: 0.2844\n",
      "Epoch 309/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9033 - mse: 0.9033 - val_loss: 0.2845 - val_mse: 0.2845\n",
      "Epoch 310/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9031 - mse: 0.9031 - val_loss: 0.2846 - val_mse: 0.2846\n",
      "Epoch 311/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9029 - mse: 0.9029 - val_loss: 0.2847 - val_mse: 0.2847\n",
      "Epoch 312/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9026 - mse: 0.9026 - val_loss: 0.2848 - val_mse: 0.2848\n",
      "Epoch 313/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9024 - mse: 0.9024 - val_loss: 0.2850 - val_mse: 0.2850\n",
      "Epoch 314/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9022 - mse: 0.9022 - val_loss: 0.2851 - val_mse: 0.2851\n",
      "Epoch 315/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9020 - mse: 0.9020 - val_loss: 0.2852 - val_mse: 0.2852\n",
      "Epoch 316/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9017 - mse: 0.9017 - val_loss: 0.2853 - val_mse: 0.2853\n",
      "Epoch 317/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9015 - mse: 0.9015 - val_loss: 0.2855 - val_mse: 0.2855\n",
      "Epoch 318/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9012 - mse: 0.9012 - val_loss: 0.2856 - val_mse: 0.2856\n",
      "Epoch 319/450\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.9010 - mse: 0.9010 - val_loss: 0.2858 - val_mse: 0.2858\n",
      "Epoch 320/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9007 - mse: 0.9007 - val_loss: 0.2859 - val_mse: 0.2859\n",
      "Epoch 321/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9005 - mse: 0.9005 - val_loss: 0.2860 - val_mse: 0.2860\n",
      "Epoch 322/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9002 - mse: 0.9002 - val_loss: 0.2862 - val_mse: 0.2862\n",
      "Epoch 323/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8999 - mse: 0.8999 - val_loss: 0.2863 - val_mse: 0.2863\n",
      "Epoch 324/450\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8997 - mse: 0.8997 - val_loss: 0.2865 - val_mse: 0.2865\n",
      "Epoch 325/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8994 - mse: 0.8994 - val_loss: 0.2866 - val_mse: 0.2866\n",
      "Epoch 326/450\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8991 - mse: 0.8991 - val_loss: 0.2868 - val_mse: 0.2868\n",
      "Epoch 327/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8988 - mse: 0.8988 - val_loss: 0.2869 - val_mse: 0.2869\n",
      "Epoch 328/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8985 - mse: 0.8985 - val_loss: 0.2871 - val_mse: 0.2871\n",
      "Epoch 329/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8982 - mse: 0.8982 - val_loss: 0.2873 - val_mse: 0.2873\n",
      "Epoch 330/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8979 - mse: 0.8979 - val_loss: 0.2874 - val_mse: 0.2874\n",
      "Epoch 331/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8976 - mse: 0.8976 - val_loss: 0.2876 - val_mse: 0.2876\n",
      "Epoch 332/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8973 - mse: 0.8973 - val_loss: 0.2878 - val_mse: 0.2878\n",
      "Epoch 333/450\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8970 - mse: 0.8970 - val_loss: 0.2879 - val_mse: 0.2879\n",
      "Epoch 334/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8967 - mse: 0.8967 - val_loss: 0.2881 - val_mse: 0.2881\n",
      "Epoch 335/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8963 - mse: 0.8963 - val_loss: 0.2883 - val_mse: 0.2883\n",
      "Epoch 336/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8960 - mse: 0.8960 - val_loss: 0.2885 - val_mse: 0.2885\n",
      "Epoch 337/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8956 - mse: 0.8956 - val_loss: 0.2887 - val_mse: 0.2887\n",
      "Epoch 338/450\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8953 - mse: 0.8953 - val_loss: 0.2889 - val_mse: 0.2889\n",
      "Epoch 339/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8949 - mse: 0.8949 - val_loss: 0.2891 - val_mse: 0.2891\n",
      "Epoch 340/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8945 - mse: 0.8945 - val_loss: 0.2893 - val_mse: 0.2893\n",
      "Epoch 341/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8942 - mse: 0.8942 - val_loss: 0.2895 - val_mse: 0.2895\n",
      "Epoch 342/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8938 - mse: 0.8938 - val_loss: 0.2897 - val_mse: 0.2897\n",
      "Epoch 343/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8934 - mse: 0.8934 - val_loss: 0.2899 - val_mse: 0.2899\n",
      "Epoch 344/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8930 - mse: 0.8930 - val_loss: 0.2901 - val_mse: 0.2901\n",
      "Epoch 345/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8926 - mse: 0.8926 - val_loss: 0.2903 - val_mse: 0.2903\n",
      "Epoch 346/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8922 - mse: 0.8922 - val_loss: 0.2905 - val_mse: 0.2905\n",
      "Epoch 347/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8918 - mse: 0.8918 - val_loss: 0.2907 - val_mse: 0.2907\n",
      "Epoch 348/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8913 - mse: 0.8913 - val_loss: 0.2910 - val_mse: 0.2910\n",
      "Epoch 349/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8909 - mse: 0.8909 - val_loss: 0.2912 - val_mse: 0.2912\n",
      "Epoch 350/450\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8905 - mse: 0.8905 - val_loss: 0.2914 - val_mse: 0.2914\n",
      "Epoch 351/450\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8900 - mse: 0.8900 - val_loss: 0.2917 - val_mse: 0.2917\n",
      "Epoch 352/450\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8895 - mse: 0.8895 - val_loss: 0.2919 - val_mse: 0.2919\n",
      "Epoch 353/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8891 - mse: 0.8891 - val_loss: 0.2922 - val_mse: 0.2922\n",
      "Epoch 354/450\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8886 - mse: 0.8886 - val_loss: 0.2924 - val_mse: 0.2924\n",
      "Epoch 355/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8881 - mse: 0.8881 - val_loss: 0.2927 - val_mse: 0.2927\n",
      "Epoch 356/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8876 - mse: 0.8876 - val_loss: 0.2929 - val_mse: 0.2929\n",
      "Epoch 357/450\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8871 - mse: 0.8871 - val_loss: 0.2932 - val_mse: 0.2932\n",
      "Epoch 358/450\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8865 - mse: 0.8865 - val_loss: 0.2935 - val_mse: 0.2935\n",
      "Epoch 359/450\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8860 - mse: 0.8860 - val_loss: 0.2938 - val_mse: 0.2938\n",
      "Epoch 360/450\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8854 - mse: 0.8854 - val_loss: 0.2940 - val_mse: 0.2940\n",
      "Epoch 361/450\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8849 - mse: 0.8849 - val_loss: 0.2943 - val_mse: 0.2943\n",
      "Epoch 362/450\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8843 - mse: 0.8843 - val_loss: 0.2946 - val_mse: 0.2946\n",
      "Epoch 363/450\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8837 - mse: 0.8837 - val_loss: 0.2949 - val_mse: 0.2949\n",
      "Epoch 364/450\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8831 - mse: 0.8831 - val_loss: 0.2952 - val_mse: 0.2952\n",
      "Epoch 365/450\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8825 - mse: 0.8825 - val_loss: 0.2955 - val_mse: 0.2955\n",
      "Epoch 366/450\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8819 - mse: 0.8819 - val_loss: 0.2958 - val_mse: 0.2958\n",
      "Epoch 367/450\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8812 - mse: 0.8812 - val_loss: 0.2961 - val_mse: 0.2961\n",
      "Epoch 368/450\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8806 - mse: 0.8806 - val_loss: 0.2965 - val_mse: 0.2965\n",
      "Epoch 369/450\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8799 - mse: 0.8799 - val_loss: 0.2968 - val_mse: 0.2968\n",
      "Epoch 370/450\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8792 - mse: 0.8792 - val_loss: 0.2971 - val_mse: 0.2971\n",
      "Epoch 371/450\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8785 - mse: 0.8785 - val_loss: 0.2975 - val_mse: 0.2975\n",
      "Epoch 372/450\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8778 - mse: 0.8778 - val_loss: 0.2978 - val_mse: 0.2978\n",
      "Epoch 373/450\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8771 - mse: 0.8771 - val_loss: 0.2981 - val_mse: 0.2981\n",
      "Epoch 374/450\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8763 - mse: 0.8763 - val_loss: 0.2985 - val_mse: 0.2985\n",
      "Epoch 375/450\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.8756 - mse: 0.8756 - val_loss: 0.2989 - val_mse: 0.2989\n",
      "Epoch 376/450\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8748 - mse: 0.8748 - val_loss: 0.2992 - val_mse: 0.2992\n",
      "Epoch 377/450\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8740 - mse: 0.8740 - val_loss: 0.2996 - val_mse: 0.2996\n",
      "Epoch 378/450\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8731 - mse: 0.8731 - val_loss: 0.3000 - val_mse: 0.3000\n",
      "Epoch 379/450\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8723 - mse: 0.8723 - val_loss: 0.3003 - val_mse: 0.3003\n",
      "Epoch 380/450\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8714 - mse: 0.8714 - val_loss: 0.3007 - val_mse: 0.3007\n",
      "Epoch 381/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8705 - mse: 0.8705 - val_loss: 0.3011 - val_mse: 0.3011\n",
      "Epoch 382/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8696 - mse: 0.8696 - val_loss: 0.3015 - val_mse: 0.3015\n",
      "Epoch 383/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8687 - mse: 0.8687 - val_loss: 0.3019 - val_mse: 0.3019\n",
      "Epoch 384/450\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8677 - mse: 0.8677 - val_loss: 0.3023 - val_mse: 0.3023\n",
      "Epoch 385/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8667 - mse: 0.8667 - val_loss: 0.3027 - val_mse: 0.3027\n",
      "Epoch 386/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8657 - mse: 0.8657 - val_loss: 0.3032 - val_mse: 0.3032\n",
      "Epoch 387/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8647 - mse: 0.8647 - val_loss: 0.3036 - val_mse: 0.3036\n",
      "Epoch 388/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8636 - mse: 0.8636 - val_loss: 0.3040 - val_mse: 0.3040\n",
      "Epoch 389/450\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8625 - mse: 0.8625 - val_loss: 0.3044 - val_mse: 0.3044\n",
      "Epoch 390/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8614 - mse: 0.8614 - val_loss: 0.3049 - val_mse: 0.3049\n",
      "Epoch 391/450\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8602 - mse: 0.8602 - val_loss: 0.3053 - val_mse: 0.3053\n",
      "Epoch 392/450\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8591 - mse: 0.8591 - val_loss: 0.3058 - val_mse: 0.3058\n",
      "Epoch 393/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8578 - mse: 0.8578 - val_loss: 0.3062 - val_mse: 0.3062\n",
      "Epoch 394/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8566 - mse: 0.8566 - val_loss: 0.3067 - val_mse: 0.3067\n",
      "Epoch 395/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8553 - mse: 0.8553 - val_loss: 0.3071 - val_mse: 0.3071\n",
      "Epoch 396/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8539 - mse: 0.8539 - val_loss: 0.3076 - val_mse: 0.3076\n",
      "Epoch 397/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8525 - mse: 0.8525 - val_loss: 0.3080 - val_mse: 0.3080\n",
      "Epoch 398/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8511 - mse: 0.8511 - val_loss: 0.3085 - val_mse: 0.3085\n",
      "Epoch 399/450\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8496 - mse: 0.8496 - val_loss: 0.3090 - val_mse: 0.3090\n",
      "Epoch 400/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8481 - mse: 0.8481 - val_loss: 0.3094 - val_mse: 0.3094\n",
      "Epoch 401/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8466 - mse: 0.8466 - val_loss: 0.3099 - val_mse: 0.3099\n",
      "Epoch 402/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8449 - mse: 0.8449 - val_loss: 0.3104 - val_mse: 0.3104\n",
      "Epoch 403/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8433 - mse: 0.8433 - val_loss: 0.3108 - val_mse: 0.3108\n",
      "Epoch 404/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8415 - mse: 0.8415 - val_loss: 0.3113 - val_mse: 0.3113\n",
      "Epoch 405/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8397 - mse: 0.8397 - val_loss: 0.3117 - val_mse: 0.3117\n",
      "Epoch 406/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8379 - mse: 0.8379 - val_loss: 0.3122 - val_mse: 0.3122\n",
      "Epoch 407/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8359 - mse: 0.8359 - val_loss: 0.3126 - val_mse: 0.3126\n",
      "Epoch 408/450\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8339 - mse: 0.8339 - val_loss: 0.3131 - val_mse: 0.3131\n",
      "Epoch 409/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8319 - mse: 0.8319 - val_loss: 0.3135 - val_mse: 0.3135\n",
      "Epoch 410/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8297 - mse: 0.8297 - val_loss: 0.3139 - val_mse: 0.3139\n",
      "Epoch 411/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8275 - mse: 0.8275 - val_loss: 0.3144 - val_mse: 0.3144\n",
      "Epoch 412/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8252 - mse: 0.8252 - val_loss: 0.3148 - val_mse: 0.3148\n",
      "Epoch 413/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8228 - mse: 0.8228 - val_loss: 0.3152 - val_mse: 0.3152\n",
      "Epoch 414/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8203 - mse: 0.8203 - val_loss: 0.3155 - val_mse: 0.3155\n",
      "Epoch 415/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8177 - mse: 0.8177 - val_loss: 0.3159 - val_mse: 0.3159\n",
      "Epoch 416/450\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8151 - mse: 0.8151 - val_loss: 0.3163 - val_mse: 0.3163\n",
      "Epoch 417/450\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8123 - mse: 0.8123 - val_loss: 0.3166 - val_mse: 0.3166\n",
      "Epoch 418/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8094 - mse: 0.8094 - val_loss: 0.3169 - val_mse: 0.3169\n",
      "Epoch 419/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8065 - mse: 0.8065 - val_loss: 0.3172 - val_mse: 0.3172\n",
      "Epoch 420/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8034 - mse: 0.8034 - val_loss: 0.3175 - val_mse: 0.3175\n",
      "Epoch 421/450\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8002 - mse: 0.8002 - val_loss: 0.3178 - val_mse: 0.3178\n",
      "Epoch 422/450\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7969 - mse: 0.7969 - val_loss: 0.3180 - val_mse: 0.3180\n",
      "Epoch 423/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7935 - mse: 0.7935 - val_loss: 0.3183 - val_mse: 0.3183\n",
      "Epoch 424/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7900 - mse: 0.7900 - val_loss: 0.3185 - val_mse: 0.3185\n",
      "Epoch 425/450\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7863 - mse: 0.7863 - val_loss: 0.3186 - val_mse: 0.3186\n",
      "Epoch 426/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7826 - mse: 0.7826 - val_loss: 0.3188 - val_mse: 0.3188\n",
      "Epoch 427/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7787 - mse: 0.7787 - val_loss: 0.3189 - val_mse: 0.3189\n",
      "Epoch 428/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7747 - mse: 0.7747 - val_loss: 0.3190 - val_mse: 0.3190\n",
      "Epoch 429/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7706 - mse: 0.7706 - val_loss: 0.3191 - val_mse: 0.3191\n",
      "Epoch 430/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7664 - mse: 0.7664 - val_loss: 0.3191 - val_mse: 0.3191\n",
      "Epoch 431/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7620 - mse: 0.7620 - val_loss: 0.3191 - val_mse: 0.3191\n",
      "Epoch 432/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7575 - mse: 0.7575 - val_loss: 0.3191 - val_mse: 0.3191\n",
      "Epoch 433/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7529 - mse: 0.7529 - val_loss: 0.3190 - val_mse: 0.3190\n",
      "Epoch 434/450\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7482 - mse: 0.7482 - val_loss: 0.3189 - val_mse: 0.3189\n",
      "Epoch 435/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7433 - mse: 0.7433 - val_loss: 0.3188 - val_mse: 0.3188\n",
      "Epoch 436/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7384 - mse: 0.7384 - val_loss: 0.3186 - val_mse: 0.3186\n",
      "Epoch 437/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7333 - mse: 0.7333 - val_loss: 0.3184 - val_mse: 0.3184\n",
      "Epoch 438/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7281 - mse: 0.7281 - val_loss: 0.3182 - val_mse: 0.3182\n",
      "Epoch 439/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7227 - mse: 0.7227 - val_loss: 0.3179 - val_mse: 0.3179\n",
      "Epoch 440/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7173 - mse: 0.7173 - val_loss: 0.3175 - val_mse: 0.3175\n",
      "Epoch 441/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7117 - mse: 0.7117 - val_loss: 0.3172 - val_mse: 0.3172\n",
      "Epoch 442/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7060 - mse: 0.7060 - val_loss: 0.3167 - val_mse: 0.3167\n",
      "Epoch 443/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7003 - mse: 0.7003 - val_loss: 0.3163 - val_mse: 0.3163\n",
      "Epoch 444/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6943 - mse: 0.6943 - val_loss: 0.3157 - val_mse: 0.3157\n",
      "Epoch 445/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6883 - mse: 0.6883 - val_loss: 0.3152 - val_mse: 0.3152\n",
      "Epoch 446/450\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6822 - mse: 0.6822 - val_loss: 0.3146 - val_mse: 0.3146\n",
      "Epoch 447/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6760 - mse: 0.6760 - val_loss: 0.3139 - val_mse: 0.3139\n",
      "Epoch 448/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6696 - mse: 0.6696 - val_loss: 0.3132 - val_mse: 0.3132\n",
      "Epoch 449/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6632 - mse: 0.6632 - val_loss: 0.3124 - val_mse: 0.3124\n",
      "Epoch 450/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6567 - mse: 0.6567 - val_loss: 0.3116 - val_mse: 0.3116\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# from tensorflow.python.keras.layers import Dense\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "variables,results = split_x_and_y(database.iloc[[0,1,2,3,4,5,6,7,8]],['A','E','N'],'Tmax')\n",
    "test_x,test_y = split_x_and_y(database.iloc[[9,10,11]],['A','E','N'],'Tmax')\n",
    "\n",
    "model = keras.Sequential([\n",
    "  layers.Dense(500, activation='sigmoid', input_shape=[len(variables.keys())]),\n",
    "  # layers.Dropout(0.3),\n",
    "  layers.Dense(500, activation='sigmoid'),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "# optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "model.compile(optimizer='adam',loss='mean_squared_error',metrics=['mse'])\n",
    "\n",
    "history = model.fit(variables.values,results.values,epochs=450,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1d48583d5b0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['loss','val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 95ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 25.        ,   1.        ,   8.        ,  86.05627629],\n",
       "       [ 25.        ,   2.        ,   5.        , 102.64300979],\n",
       "       [ 35.        ,   3.        ,  11.        ,  90.00943901]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guess = model.predict(test_x.values)\n",
    "desnormalizar = test_x.copy()\n",
    "desnormalizar['Tmax'] = guess\n",
    "desnormalizado_teste = standardscaler.inverse_transform(desnormalizar)\n",
    "desnormalizado_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25.  ,  1.  ,  8.  , 76.3 ],\n",
       "       [25.  ,  2.  ,  5.  , 98.76],\n",
       "       [35.  ,  3.  , 11.  , 94.7 ]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desnormalizar = test_x.copy()\n",
    "desnormalizar['Tmax'] = test_y\n",
    "desnormalizado_resultado = standardscaler.inverse_transform(desnormalizar)\n",
    "desnormalizado_resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: 0.538342781496221 meansquarederror: 44.088018149927734 meanabsoluteerror: 6.109949023421696 maxerror: 9.756276286939823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.538342781496221, 44.088018149927734, 6.109949023421696, 9.756276286939823)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores(desnormalizado_resultado[:,-1],desnormalizado_teste[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"keras_model_Tmax.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 4.0279 - mse: 4.0279 - val_loss: 7.8944 - val_mse: 7.8944\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 14.3551 - mse: 14.3551 - val_loss: 0.7331 - val_mse: 0.7331\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0734 - mse: 4.0734 - val_loss: 3.5909 - val_mse: 3.5909\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.7130 - mse: 2.7130 - val_loss: 10.4762 - val_mse: 10.4762\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 7.4937 - mse: 7.4937 - val_loss: 7.9368 - val_mse: 7.9368\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.6058 - mse: 5.6058 - val_loss: 2.2395 - val_mse: 2.2395\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.9762 - mse: 1.9762 - val_loss: 0.0641 - val_mse: 0.0641\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0479 - mse: 2.0479 - val_loss: 0.8429 - val_mse: 0.8429\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.2270 - mse: 4.2270 - val_loss: 1.0264 - val_mse: 1.0264\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5532 - mse: 4.5532 - val_loss: 0.2309 - val_mse: 0.2309\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.8629 - mse: 2.8629 - val_loss: 0.3433 - val_mse: 0.3433\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5247 - mse: 1.5247 - val_loss: 2.1737 - val_mse: 2.1737\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9201 - mse: 1.9201 - val_loss: 4.1733 - val_mse: 4.1733\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.0263 - mse: 3.0263 - val_loss: 4.4131 - val_mse: 4.4131\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.1723 - mse: 3.1723 - val_loss: 2.8948 - val_mse: 2.8948\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.2730 - mse: 2.2730 - val_loss: 1.0974 - val_mse: 1.0974\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4987 - mse: 1.4987 - val_loss: 0.1817 - val_mse: 0.1817\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.6197 - mse: 1.6197 - val_loss: 0.0849 - val_mse: 0.0849\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.2252 - mse: 2.2252 - val_loss: 0.1298 - val_mse: 0.1298\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.4458 - mse: 2.4458 - val_loss: 0.0707 - val_mse: 0.0707\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0413 - mse: 2.0413 - val_loss: 0.2560 - val_mse: 0.2560\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.5245 - mse: 1.5245 - val_loss: 0.9767 - val_mse: 0.9767\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4424 - mse: 1.4424 - val_loss: 1.9256 - val_mse: 1.9256\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7592 - mse: 1.7592 - val_loss: 2.4223 - val_mse: 2.4223\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.9890 - mse: 1.9890 - val_loss: 2.1219 - val_mse: 2.1219\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8389 - mse: 1.8389 - val_loss: 1.3230 - val_mse: 1.3230\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.5130 - mse: 1.5130 - val_loss: 0.5871 - val_mse: 0.5871\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3825 - mse: 1.3825 - val_loss: 0.2101 - val_mse: 0.2101\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.5281 - mse: 1.5281 - val_loss: 0.1090 - val_mse: 0.1090\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.6995 - mse: 1.6995 - val_loss: 0.1196 - val_mse: 0.1196\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.6643 - mse: 1.6643 - val_loss: 0.2500 - val_mse: 0.2500\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4738 - mse: 1.4738 - val_loss: 0.5956 - val_mse: 0.5956\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3535 - mse: 1.3535 - val_loss: 1.0943 - val_mse: 1.0943\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4102 - mse: 1.4102 - val_loss: 1.4758 - val_mse: 1.4758\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.5231 - mse: 1.5231 - val_loss: 1.4951 - val_mse: 1.4951\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.5246 - mse: 1.5246 - val_loss: 1.1682 - val_mse: 1.1682\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4126 - mse: 1.4126 - val_loss: 0.7322 - val_mse: 0.7322\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3250 - mse: 1.3250 - val_loss: 0.4100 - val_mse: 0.4100\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.3472 - mse: 1.3472 - val_loss: 0.2625 - val_mse: 0.2625\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4148 - mse: 1.4148 - val_loss: 0.2488 - val_mse: 0.2488\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.4193 - mse: 1.4193 - val_loss: 0.3498 - val_mse: 0.3498\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3500 - mse: 1.3500 - val_loss: 0.5740 - val_mse: 0.5740\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.2917 - mse: 1.2917 - val_loss: 0.8672 - val_mse: 0.8672\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.3019 - mse: 1.3019 - val_loss: 1.0857 - val_mse: 1.0857\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3410 - mse: 1.3410 - val_loss: 1.1021 - val_mse: 1.1021\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3386 - mse: 1.3386 - val_loss: 0.9216 - val_mse: 0.9216\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2910 - mse: 1.2910 - val_loss: 0.6683 - val_mse: 0.6683\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2551 - mse: 1.2551 - val_loss: 0.4685 - val_mse: 0.4685\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2630 - mse: 1.2630 - val_loss: 0.3737 - val_mse: 0.3737\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2830 - mse: 1.2830 - val_loss: 0.3811 - val_mse: 0.3811\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.2727 - mse: 1.2727 - val_loss: 0.4810 - val_mse: 0.4810\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2381 - mse: 1.2381 - val_loss: 0.6504 - val_mse: 0.6504\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2179 - mse: 1.2179 - val_loss: 0.8227 - val_mse: 0.8227\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2245 - mse: 1.2245 - val_loss: 0.9073 - val_mse: 0.9073\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2311 - mse: 1.2311 - val_loss: 0.8598 - val_mse: 0.8598\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2153 - mse: 1.2153 - val_loss: 0.7193 - val_mse: 0.7193\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.1906 - mse: 1.1906 - val_loss: 0.5692 - val_mse: 0.5692\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1810 - mse: 1.1810 - val_loss: 0.4727 - val_mse: 0.4727\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1849 - mse: 1.1849 - val_loss: 0.4514 - val_mse: 0.4514\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1813 - mse: 1.1813 - val_loss: 0.5024 - val_mse: 0.5024\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1639 - mse: 1.1639 - val_loss: 0.6062 - val_mse: 0.6062\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1480 - mse: 1.1480 - val_loss: 0.7187 - val_mse: 0.7187\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1442 - mse: 1.1442 - val_loss: 0.7818 - val_mse: 0.7818\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1432 - mse: 1.1432 - val_loss: 0.7621 - val_mse: 0.7621\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1332 - mse: 1.1332 - val_loss: 0.6774 - val_mse: 0.6774\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.1183 - mse: 1.1183 - val_loss: 0.5794 - val_mse: 0.5794\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.1095 - mse: 1.1095 - val_loss: 0.5138 - val_mse: 0.5138\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.1068 - mse: 1.1068 - val_loss: 0.5010 - val_mse: 0.5010\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1007 - mse: 1.1007 - val_loss: 0.5394 - val_mse: 0.5394\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0889 - mse: 1.0889 - val_loss: 0.6100 - val_mse: 0.6100\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0787 - mse: 1.0787 - val_loss: 0.6774 - val_mse: 0.6774\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0739 - mse: 1.0739 - val_loss: 0.7044 - val_mse: 0.7044\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0691 - mse: 1.0691 - val_loss: 0.6773 - val_mse: 0.6773\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0600 - mse: 1.0600 - val_loss: 0.6157 - val_mse: 0.6157\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0505 - mse: 1.0505 - val_loss: 0.5553 - val_mse: 0.5553\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0446 - mse: 1.0446 - val_loss: 0.5235 - val_mse: 0.5235\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0400 - mse: 1.0400 - val_loss: 0.5296 - val_mse: 0.5296\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0329 - mse: 1.0329 - val_loss: 0.5665 - val_mse: 0.5665\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0247 - mse: 1.0247 - val_loss: 0.6130 - val_mse: 0.6130\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0188 - mse: 1.0188 - val_loss: 0.6420 - val_mse: 0.6420\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0144 - mse: 1.0144 - val_loss: 0.6365 - val_mse: 0.6365\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0087 - mse: 1.0087 - val_loss: 0.6013 - val_mse: 0.6013\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0019 - mse: 1.0019 - val_loss: 0.5580 - val_mse: 0.5580\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9965 - mse: 0.9965 - val_loss: 0.5291 - val_mse: 0.5291\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9925 - mse: 0.9925 - val_loss: 0.5255 - val_mse: 0.5255\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9878 - mse: 0.9878 - val_loss: 0.5449 - val_mse: 0.5449\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9823 - mse: 0.9823 - val_loss: 0.5735 - val_mse: 0.5735\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9779 - mse: 0.9779 - val_loss: 0.5927 - val_mse: 0.5927\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9745 - mse: 0.9745 - val_loss: 0.5897 - val_mse: 0.5897\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9707 - mse: 0.9707 - val_loss: 0.5666 - val_mse: 0.5666\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9664 - mse: 0.9664 - val_loss: 0.5372 - val_mse: 0.5372\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9629 - mse: 0.9629 - val_loss: 0.5169 - val_mse: 0.5169\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9601 - mse: 0.9601 - val_loss: 0.5137 - val_mse: 0.5137\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9571 - mse: 0.9571 - val_loss: 0.5255 - val_mse: 0.5255\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9539 - mse: 0.9539 - val_loss: 0.5421 - val_mse: 0.5421\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9513 - mse: 0.9513 - val_loss: 0.5510 - val_mse: 0.5510\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9492 - mse: 0.9492 - val_loss: 0.5451 - val_mse: 0.5451\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9469 - mse: 0.9469 - val_loss: 0.5274 - val_mse: 0.5274\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9446 - mse: 0.9446 - val_loss: 0.5077 - val_mse: 0.5077\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9428 - mse: 0.9428 - val_loss: 0.4959 - val_mse: 0.4959\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9412 - mse: 0.9412 - val_loss: 0.4956 - val_mse: 0.4956\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9395 - mse: 0.9395 - val_loss: 0.5034 - val_mse: 0.5034\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9379 - mse: 0.9379 - val_loss: 0.5116 - val_mse: 0.5116\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9367 - mse: 0.9367 - val_loss: 0.5125 - val_mse: 0.5125\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9356 - mse: 0.9356 - val_loss: 0.5038 - val_mse: 0.5038\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9343 - mse: 0.9343 - val_loss: 0.4899 - val_mse: 0.4899\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9333 - mse: 0.9333 - val_loss: 0.4778 - val_mse: 0.4778\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9324 - mse: 0.9324 - val_loss: 0.4723 - val_mse: 0.4723\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9316 - mse: 0.9316 - val_loss: 0.4738 - val_mse: 0.4738\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9308 - mse: 0.9308 - val_loss: 0.4782 - val_mse: 0.4782\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9300 - mse: 0.9300 - val_loss: 0.4798 - val_mse: 0.4798\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9294 - mse: 0.9294 - val_loss: 0.4755 - val_mse: 0.4755\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9288 - mse: 0.9288 - val_loss: 0.4663 - val_mse: 0.4663\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9282 - mse: 0.9282 - val_loss: 0.4563 - val_mse: 0.4563\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9277 - mse: 0.9277 - val_loss: 0.4498 - val_mse: 0.4498\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9272 - mse: 0.9272 - val_loss: 0.4481 - val_mse: 0.4481\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9267 - mse: 0.9267 - val_loss: 0.4493 - val_mse: 0.4493\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9262 - mse: 0.9262 - val_loss: 0.4499 - val_mse: 0.4499\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9259 - mse: 0.9259 - val_loss: 0.4470 - val_mse: 0.4470\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9255 - mse: 0.9255 - val_loss: 0.4405 - val_mse: 0.4405\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9250 - mse: 0.9250 - val_loss: 0.4327 - val_mse: 0.4327\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.9246 - mse: 0.9246 - val_loss: 0.4267 - val_mse: 0.4267\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.9243 - mse: 0.9243 - val_loss: 0.4237 - val_mse: 0.4237\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9239 - mse: 0.9239 - val_loss: 0.4231 - val_mse: 0.4231\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9235 - mse: 0.9235 - val_loss: 0.4225 - val_mse: 0.4225\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9232 - mse: 0.9232 - val_loss: 0.4198 - val_mse: 0.4198\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9229 - mse: 0.9229 - val_loss: 0.4147 - val_mse: 0.4147\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9225 - mse: 0.9225 - val_loss: 0.4086 - val_mse: 0.4086\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9222 - mse: 0.9222 - val_loss: 0.4034 - val_mse: 0.4034\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.9218 - mse: 0.9218 - val_loss: 0.4002 - val_mse: 0.4002\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.9215 - mse: 0.9215 - val_loss: 0.3987 - val_mse: 0.3987\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9212 - mse: 0.9212 - val_loss: 0.3973 - val_mse: 0.3973\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9209 - mse: 0.9209 - val_loss: 0.3947 - val_mse: 0.3947\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9206 - mse: 0.9206 - val_loss: 0.3904 - val_mse: 0.3904\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9203 - mse: 0.9203 - val_loss: 0.3855 - val_mse: 0.3855\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9200 - mse: 0.9200 - val_loss: 0.3812 - val_mse: 0.3812\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9197 - mse: 0.9197 - val_loss: 0.3783 - val_mse: 0.3783\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9195 - mse: 0.9195 - val_loss: 0.3765 - val_mse: 0.3765\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.9192 - mse: 0.9192 - val_loss: 0.3747 - val_mse: 0.3747\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9189 - mse: 0.9189 - val_loss: 0.3721 - val_mse: 0.3721\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9187 - mse: 0.9187 - val_loss: 0.3685 - val_mse: 0.3685\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9185 - mse: 0.9185 - val_loss: 0.3646 - val_mse: 0.3646\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9182 - mse: 0.9182 - val_loss: 0.3612 - val_mse: 0.3612\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9180 - mse: 0.9180 - val_loss: 0.3587 - val_mse: 0.3587\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9178 - mse: 0.9178 - val_loss: 0.3570 - val_mse: 0.3570\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9176 - mse: 0.9176 - val_loss: 0.3552 - val_mse: 0.3552\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9174 - mse: 0.9174 - val_loss: 0.3528 - val_mse: 0.3528\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9172 - mse: 0.9172 - val_loss: 0.3497 - val_mse: 0.3497\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9170 - mse: 0.9170 - val_loss: 0.3466 - val_mse: 0.3466\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9168 - mse: 0.9168 - val_loss: 0.3440 - val_mse: 0.3440\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9167 - mse: 0.9167 - val_loss: 0.3420 - val_mse: 0.3420\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9165 - mse: 0.9165 - val_loss: 0.3405 - val_mse: 0.3405\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9163 - mse: 0.9163 - val_loss: 0.3388 - val_mse: 0.3388\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9162 - mse: 0.9162 - val_loss: 0.3367 - val_mse: 0.3367\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9160 - mse: 0.9160 - val_loss: 0.3342 - val_mse: 0.3342\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9159 - mse: 0.9159 - val_loss: 0.3319 - val_mse: 0.3319\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9157 - mse: 0.9157 - val_loss: 0.3299 - val_mse: 0.3299\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9156 - mse: 0.9156 - val_loss: 0.3284 - val_mse: 0.3284\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9155 - mse: 0.9155 - val_loss: 0.3271 - val_mse: 0.3271\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9153 - mse: 0.9153 - val_loss: 0.3256 - val_mse: 0.3256\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9152 - mse: 0.9152 - val_loss: 0.3238 - val_mse: 0.3238\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9151 - mse: 0.9151 - val_loss: 0.3219 - val_mse: 0.3219\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9150 - mse: 0.9150 - val_loss: 0.3201 - val_mse: 0.3201\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9149 - mse: 0.9149 - val_loss: 0.3187 - val_mse: 0.3187\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9148 - mse: 0.9148 - val_loss: 0.3176 - val_mse: 0.3176\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9147 - mse: 0.9147 - val_loss: 0.3165 - val_mse: 0.3165\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9146 - mse: 0.9146 - val_loss: 0.3152 - val_mse: 0.3152\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9145 - mse: 0.9145 - val_loss: 0.3137 - val_mse: 0.3137\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9144 - mse: 0.9144 - val_loss: 0.3123 - val_mse: 0.3123\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9143 - mse: 0.9143 - val_loss: 0.3111 - val_mse: 0.3111\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9142 - mse: 0.9142 - val_loss: 0.3101 - val_mse: 0.3101\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9141 - mse: 0.9141 - val_loss: 0.3092 - val_mse: 0.3092\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9140 - mse: 0.9140 - val_loss: 0.3082 - val_mse: 0.3082\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9139 - mse: 0.9139 - val_loss: 0.3072 - val_mse: 0.3072\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9138 - mse: 0.9138 - val_loss: 0.3060 - val_mse: 0.3060\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9137 - mse: 0.9137 - val_loss: 0.3050 - val_mse: 0.3050\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9136 - mse: 0.9136 - val_loss: 0.3041 - val_mse: 0.3041\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9136 - mse: 0.9136 - val_loss: 0.3034 - val_mse: 0.3034\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9135 - mse: 0.9135 - val_loss: 0.3027 - val_mse: 0.3027\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9134 - mse: 0.9134 - val_loss: 0.3019 - val_mse: 0.3019\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9133 - mse: 0.9133 - val_loss: 0.3010 - val_mse: 0.3010\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9132 - mse: 0.9132 - val_loss: 0.3002 - val_mse: 0.3002\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9132 - mse: 0.9132 - val_loss: 0.2994 - val_mse: 0.2994\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9131 - mse: 0.9131 - val_loss: 0.2988 - val_mse: 0.2988\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9130 - mse: 0.9130 - val_loss: 0.2982 - val_mse: 0.2982\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9129 - mse: 0.9129 - val_loss: 0.2976 - val_mse: 0.2976\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9129 - mse: 0.9129 - val_loss: 0.2970 - val_mse: 0.2970\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9128 - mse: 0.9128 - val_loss: 0.2963 - val_mse: 0.2963\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9127 - mse: 0.9127 - val_loss: 0.2957 - val_mse: 0.2957\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9126 - mse: 0.9126 - val_loss: 0.2951 - val_mse: 0.2951\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9126 - mse: 0.9126 - val_loss: 0.2947 - val_mse: 0.2947\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9125 - mse: 0.9125 - val_loss: 0.2942 - val_mse: 0.2942\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9124 - mse: 0.9124 - val_loss: 0.2937 - val_mse: 0.2937\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9124 - mse: 0.9124 - val_loss: 0.2931 - val_mse: 0.2931\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9123 - mse: 0.9123 - val_loss: 0.2926 - val_mse: 0.2926\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9122 - mse: 0.9122 - val_loss: 0.2922 - val_mse: 0.2922\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9121 - mse: 0.9121 - val_loss: 0.2918 - val_mse: 0.2918\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9121 - mse: 0.9121 - val_loss: 0.2914 - val_mse: 0.2914\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9120 - mse: 0.9120 - val_loss: 0.2910 - val_mse: 0.2910\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9119 - mse: 0.9119 - val_loss: 0.2906 - val_mse: 0.2906\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9119 - mse: 0.9119 - val_loss: 0.2902 - val_mse: 0.2902\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9118 - mse: 0.9118 - val_loss: 0.2898 - val_mse: 0.2898\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9117 - mse: 0.9117 - val_loss: 0.2895 - val_mse: 0.2895\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9116 - mse: 0.9116 - val_loss: 0.2892 - val_mse: 0.2892\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9116 - mse: 0.9116 - val_loss: 0.2889 - val_mse: 0.2889\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9115 - mse: 0.9115 - val_loss: 0.2885 - val_mse: 0.2885\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9114 - mse: 0.9114 - val_loss: 0.2882 - val_mse: 0.2882\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9114 - mse: 0.9114 - val_loss: 0.2879 - val_mse: 0.2879\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9113 - mse: 0.9113 - val_loss: 0.2876 - val_mse: 0.2876\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9112 - mse: 0.9112 - val_loss: 0.2874 - val_mse: 0.2874\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9111 - mse: 0.9111 - val_loss: 0.2871 - val_mse: 0.2871\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.9111 - mse: 0.9111 - val_loss: 0.2869 - val_mse: 0.2869\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9110 - mse: 0.9110 - val_loss: 0.2866 - val_mse: 0.2866\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9109 - mse: 0.9109 - val_loss: 0.2864 - val_mse: 0.2864\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9108 - mse: 0.9108 - val_loss: 0.2862 - val_mse: 0.2862\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9108 - mse: 0.9108 - val_loss: 0.2860 - val_mse: 0.2860\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9107 - mse: 0.9107 - val_loss: 0.2858 - val_mse: 0.2858\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9106 - mse: 0.9106 - val_loss: 0.2856 - val_mse: 0.2856\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9105 - mse: 0.9105 - val_loss: 0.2854 - val_mse: 0.2854\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9105 - mse: 0.9105 - val_loss: 0.2852 - val_mse: 0.2852\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9104 - mse: 0.9104 - val_loss: 0.2851 - val_mse: 0.2851\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9103 - mse: 0.9103 - val_loss: 0.2849 - val_mse: 0.2849\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9102 - mse: 0.9102 - val_loss: 0.2848 - val_mse: 0.2848\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9101 - mse: 0.9101 - val_loss: 0.2846 - val_mse: 0.2846\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9101 - mse: 0.9101 - val_loss: 0.2845 - val_mse: 0.2845\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9100 - mse: 0.9100 - val_loss: 0.2844 - val_mse: 0.2844\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9099 - mse: 0.9099 - val_loss: 0.2843 - val_mse: 0.2843\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9098 - mse: 0.9098 - val_loss: 0.2842 - val_mse: 0.2842\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9097 - mse: 0.9097 - val_loss: 0.2841 - val_mse: 0.2841\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9096 - mse: 0.9096 - val_loss: 0.2840 - val_mse: 0.2840\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9095 - mse: 0.9095 - val_loss: 0.2839 - val_mse: 0.2839\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9095 - mse: 0.9095 - val_loss: 0.2838 - val_mse: 0.2838\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9094 - mse: 0.9094 - val_loss: 0.2837 - val_mse: 0.2837\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9093 - mse: 0.9093 - val_loss: 0.2837 - val_mse: 0.2837\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9092 - mse: 0.9092 - val_loss: 0.2836 - val_mse: 0.2836\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9091 - mse: 0.9091 - val_loss: 0.2835 - val_mse: 0.2835\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9090 - mse: 0.9090 - val_loss: 0.2835 - val_mse: 0.2835\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9089 - mse: 0.9089 - val_loss: 0.2834 - val_mse: 0.2834\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9088 - mse: 0.9088 - val_loss: 0.2834 - val_mse: 0.2834\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9087 - mse: 0.9087 - val_loss: 0.2833 - val_mse: 0.2833\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9086 - mse: 0.9086 - val_loss: 0.2833 - val_mse: 0.2833\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9085 - mse: 0.9085 - val_loss: 0.2833 - val_mse: 0.2833\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9084 - mse: 0.9084 - val_loss: 0.2832 - val_mse: 0.2832\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9083 - mse: 0.9083 - val_loss: 0.2832 - val_mse: 0.2832\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9082 - mse: 0.9082 - val_loss: 0.2832 - val_mse: 0.2832\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9081 - mse: 0.9081 - val_loss: 0.2832 - val_mse: 0.2832\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9080 - mse: 0.9080 - val_loss: 0.2832 - val_mse: 0.2832\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9079 - mse: 0.9079 - val_loss: 0.2832 - val_mse: 0.2832\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9078 - mse: 0.9078 - val_loss: 0.2832 - val_mse: 0.2832\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9077 - mse: 0.9077 - val_loss: 0.2832 - val_mse: 0.2832\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9076 - mse: 0.9076 - val_loss: 0.2832 - val_mse: 0.2832\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9075 - mse: 0.9075 - val_loss: 0.2832 - val_mse: 0.2832\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9074 - mse: 0.9074 - val_loss: 0.2832 - val_mse: 0.2832\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9073 - mse: 0.9073 - val_loss: 0.2832 - val_mse: 0.2832\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9072 - mse: 0.9072 - val_loss: 0.2832 - val_mse: 0.2832\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9070 - mse: 0.9070 - val_loss: 0.2832 - val_mse: 0.2832\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9069 - mse: 0.9069 - val_loss: 0.2833 - val_mse: 0.2833\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9068 - mse: 0.9068 - val_loss: 0.2833 - val_mse: 0.2833\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9067 - mse: 0.9067 - val_loss: 0.2833 - val_mse: 0.2833\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9066 - mse: 0.9066 - val_loss: 0.2833 - val_mse: 0.2833\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9065 - mse: 0.9065 - val_loss: 0.2834 - val_mse: 0.2834\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.9063 - mse: 0.9063 - val_loss: 0.2834 - val_mse: 0.2834\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9062 - mse: 0.9062 - val_loss: 0.2834 - val_mse: 0.2834\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9061 - mse: 0.9061 - val_loss: 0.2835 - val_mse: 0.2835\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9060 - mse: 0.9060 - val_loss: 0.2835 - val_mse: 0.2835\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9058 - mse: 0.9058 - val_loss: 0.2835 - val_mse: 0.2835\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9057 - mse: 0.9057 - val_loss: 0.2836 - val_mse: 0.2836\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9056 - mse: 0.9056 - val_loss: 0.2836 - val_mse: 0.2836\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9054 - mse: 0.9054 - val_loss: 0.2837 - val_mse: 0.2837\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9053 - mse: 0.9053 - val_loss: 0.2837 - val_mse: 0.2837\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9052 - mse: 0.9052 - val_loss: 0.2838 - val_mse: 0.2838\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9050 - mse: 0.9050 - val_loss: 0.2838 - val_mse: 0.2838\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9049 - mse: 0.9049 - val_loss: 0.2839 - val_mse: 0.2839\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9047 - mse: 0.9047 - val_loss: 0.2839 - val_mse: 0.2839\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9046 - mse: 0.9046 - val_loss: 0.2840 - val_mse: 0.2840\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9044 - mse: 0.9044 - val_loss: 0.2840 - val_mse: 0.2840\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9043 - mse: 0.9043 - val_loss: 0.2841 - val_mse: 0.2841\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9041 - mse: 0.9041 - val_loss: 0.2841 - val_mse: 0.2841\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9040 - mse: 0.9040 - val_loss: 0.2842 - val_mse: 0.2842\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9038 - mse: 0.9038 - val_loss: 0.2843 - val_mse: 0.2843\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9037 - mse: 0.9037 - val_loss: 0.2843 - val_mse: 0.2843\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9035 - mse: 0.9035 - val_loss: 0.2844 - val_mse: 0.2844\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9034 - mse: 0.9034 - val_loss: 0.2845 - val_mse: 0.2845\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9032 - mse: 0.9032 - val_loss: 0.2845 - val_mse: 0.2845\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9030 - mse: 0.9030 - val_loss: 0.2846 - val_mse: 0.2846\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9029 - mse: 0.9029 - val_loss: 0.2847 - val_mse: 0.2847\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9027 - mse: 0.9027 - val_loss: 0.2847 - val_mse: 0.2847\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9025 - mse: 0.9025 - val_loss: 0.2848 - val_mse: 0.2848\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9023 - mse: 0.9023 - val_loss: 0.2849 - val_mse: 0.2849\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9022 - mse: 0.9022 - val_loss: 0.2849 - val_mse: 0.2849\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9020 - mse: 0.9020 - val_loss: 0.2850 - val_mse: 0.2850\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9018 - mse: 0.9018 - val_loss: 0.2851 - val_mse: 0.2851\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9016 - mse: 0.9016 - val_loss: 0.2852 - val_mse: 0.2852\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.9014 - mse: 0.9014 - val_loss: 0.2853 - val_mse: 0.2853\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9012 - mse: 0.9012 - val_loss: 0.2853 - val_mse: 0.2853\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9011 - mse: 0.9011 - val_loss: 0.2854 - val_mse: 0.2854\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9009 - mse: 0.9009 - val_loss: 0.2855 - val_mse: 0.2855\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9007 - mse: 0.9007 - val_loss: 0.2856 - val_mse: 0.2856\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9005 - mse: 0.9005 - val_loss: 0.2857 - val_mse: 0.2857\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9003 - mse: 0.9003 - val_loss: 0.2857 - val_mse: 0.2857\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9001 - mse: 0.9001 - val_loss: 0.2858 - val_mse: 0.2858\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8998 - mse: 0.8998 - val_loss: 0.2859 - val_mse: 0.2859\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8996 - mse: 0.8996 - val_loss: 0.2860 - val_mse: 0.2860\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8994 - mse: 0.8994 - val_loss: 0.2861 - val_mse: 0.2861\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8992 - mse: 0.8992 - val_loss: 0.2862 - val_mse: 0.2862\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8990 - mse: 0.8990 - val_loss: 0.2863 - val_mse: 0.2863\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8987 - mse: 0.8987 - val_loss: 0.2864 - val_mse: 0.2864\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8985 - mse: 0.8985 - val_loss: 0.2865 - val_mse: 0.2865\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8983 - mse: 0.8983 - val_loss: 0.2866 - val_mse: 0.2866\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8980 - mse: 0.8980 - val_loss: 0.2867 - val_mse: 0.2867\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8978 - mse: 0.8978 - val_loss: 0.2867 - val_mse: 0.2867\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8976 - mse: 0.8976 - val_loss: 0.2868 - val_mse: 0.2868\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8973 - mse: 0.8973 - val_loss: 0.2869 - val_mse: 0.2869\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8971 - mse: 0.8971 - val_loss: 0.2870 - val_mse: 0.2870\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8968 - mse: 0.8968 - val_loss: 0.2871 - val_mse: 0.2871\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8965 - mse: 0.8965 - val_loss: 0.2872 - val_mse: 0.2872\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8963 - mse: 0.8963 - val_loss: 0.2873 - val_mse: 0.2873\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8960 - mse: 0.8960 - val_loss: 0.2874 - val_mse: 0.2874\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8957 - mse: 0.8957 - val_loss: 0.2875 - val_mse: 0.2875\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8955 - mse: 0.8955 - val_loss: 0.2877 - val_mse: 0.2877\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8952 - mse: 0.8952 - val_loss: 0.2878 - val_mse: 0.2878\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8949 - mse: 0.8949 - val_loss: 0.2879 - val_mse: 0.2879\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8946 - mse: 0.8946 - val_loss: 0.2880 - val_mse: 0.2880\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8943 - mse: 0.8943 - val_loss: 0.2881 - val_mse: 0.2881\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8940 - mse: 0.8940 - val_loss: 0.2882 - val_mse: 0.2882\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8937 - mse: 0.8937 - val_loss: 0.2883 - val_mse: 0.2883\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8934 - mse: 0.8934 - val_loss: 0.2884 - val_mse: 0.2884\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.8931 - mse: 0.8931 - val_loss: 0.2885 - val_mse: 0.2885\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8928 - mse: 0.8928 - val_loss: 0.2886 - val_mse: 0.2886\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8924 - mse: 0.8924 - val_loss: 0.2888 - val_mse: 0.2888\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8921 - mse: 0.8921 - val_loss: 0.2889 - val_mse: 0.2889\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8918 - mse: 0.8918 - val_loss: 0.2890 - val_mse: 0.2890\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8914 - mse: 0.8914 - val_loss: 0.2891 - val_mse: 0.2891\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8911 - mse: 0.8911 - val_loss: 0.2892 - val_mse: 0.2892\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8907 - mse: 0.8907 - val_loss: 0.2893 - val_mse: 0.2893\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8904 - mse: 0.8904 - val_loss: 0.2895 - val_mse: 0.2895\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8900 - mse: 0.8900 - val_loss: 0.2896 - val_mse: 0.2896\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8896 - mse: 0.8896 - val_loss: 0.2897 - val_mse: 0.2897\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8893 - mse: 0.8893 - val_loss: 0.2898 - val_mse: 0.2898\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8889 - mse: 0.8889 - val_loss: 0.2899 - val_mse: 0.2899\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8885 - mse: 0.8885 - val_loss: 0.2901 - val_mse: 0.2901\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8881 - mse: 0.8881 - val_loss: 0.2902 - val_mse: 0.2902\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8877 - mse: 0.8877 - val_loss: 0.2903 - val_mse: 0.2903\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8873 - mse: 0.8873 - val_loss: 0.2904 - val_mse: 0.2904\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8868 - mse: 0.8868 - val_loss: 0.2906 - val_mse: 0.2906\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8864 - mse: 0.8864 - val_loss: 0.2907 - val_mse: 0.2907\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8860 - mse: 0.8860 - val_loss: 0.2908 - val_mse: 0.2908\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8855 - mse: 0.8855 - val_loss: 0.2910 - val_mse: 0.2910\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8851 - mse: 0.8851 - val_loss: 0.2911 - val_mse: 0.2911\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8846 - mse: 0.8846 - val_loss: 0.2912 - val_mse: 0.2912\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8841 - mse: 0.8841 - val_loss: 0.2914 - val_mse: 0.2914\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8837 - mse: 0.8837 - val_loss: 0.2915 - val_mse: 0.2915\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8832 - mse: 0.8832 - val_loss: 0.2916 - val_mse: 0.2916\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8827 - mse: 0.8827 - val_loss: 0.2918 - val_mse: 0.2918\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8822 - mse: 0.8822 - val_loss: 0.2919 - val_mse: 0.2919\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8817 - mse: 0.8817 - val_loss: 0.2920 - val_mse: 0.2920\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8811 - mse: 0.8811 - val_loss: 0.2922 - val_mse: 0.2922\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8806 - mse: 0.8806 - val_loss: 0.2923 - val_mse: 0.2923\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8801 - mse: 0.8801 - val_loss: 0.2924 - val_mse: 0.2924\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8795 - mse: 0.8795 - val_loss: 0.2926 - val_mse: 0.2926\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8789 - mse: 0.8789 - val_loss: 0.2927 - val_mse: 0.2927\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8784 - mse: 0.8784 - val_loss: 0.2928 - val_mse: 0.2928\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8778 - mse: 0.8778 - val_loss: 0.2930 - val_mse: 0.2930\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8772 - mse: 0.8772 - val_loss: 0.2931 - val_mse: 0.2931\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8766 - mse: 0.8766 - val_loss: 0.2933 - val_mse: 0.2933\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8759 - mse: 0.8759 - val_loss: 0.2934 - val_mse: 0.2934\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8753 - mse: 0.8753 - val_loss: 0.2935 - val_mse: 0.2935\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8747 - mse: 0.8747 - val_loss: 0.2937 - val_mse: 0.2937\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8740 - mse: 0.8740 - val_loss: 0.2938 - val_mse: 0.2938\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8733 - mse: 0.8733 - val_loss: 0.2939 - val_mse: 0.2939\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8726 - mse: 0.8726 - val_loss: 0.2941 - val_mse: 0.2941\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8719 - mse: 0.8719 - val_loss: 0.2942 - val_mse: 0.2942\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8712 - mse: 0.8712 - val_loss: 0.2944 - val_mse: 0.2944\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8705 - mse: 0.8705 - val_loss: 0.2945 - val_mse: 0.2945\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8697 - mse: 0.8697 - val_loss: 0.2946 - val_mse: 0.2946\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8690 - mse: 0.8690 - val_loss: 0.2948 - val_mse: 0.2948\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8682 - mse: 0.8682 - val_loss: 0.2949 - val_mse: 0.2949\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8674 - mse: 0.8674 - val_loss: 0.2950 - val_mse: 0.2950\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8666 - mse: 0.8666 - val_loss: 0.2952 - val_mse: 0.2952\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8658 - mse: 0.8658 - val_loss: 0.2953 - val_mse: 0.2953\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8649 - mse: 0.8649 - val_loss: 0.2954 - val_mse: 0.2954\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8641 - mse: 0.8641 - val_loss: 0.2956 - val_mse: 0.2956\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8632 - mse: 0.8632 - val_loss: 0.2957 - val_mse: 0.2957\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8623 - mse: 0.8623 - val_loss: 0.2958 - val_mse: 0.2958\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8614 - mse: 0.8614 - val_loss: 0.2959 - val_mse: 0.2959\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8605 - mse: 0.8605 - val_loss: 0.2961 - val_mse: 0.2961\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8595 - mse: 0.8595 - val_loss: 0.2962 - val_mse: 0.2962\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8585 - mse: 0.8585 - val_loss: 0.2963 - val_mse: 0.2963\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8575 - mse: 0.8575 - val_loss: 0.2964 - val_mse: 0.2964\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8565 - mse: 0.8565 - val_loss: 0.2965 - val_mse: 0.2965\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8555 - mse: 0.8555 - val_loss: 0.2966 - val_mse: 0.2966\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8544 - mse: 0.8544 - val_loss: 0.2967 - val_mse: 0.2967\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8533 - mse: 0.8533 - val_loss: 0.2968 - val_mse: 0.2968\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8522 - mse: 0.8522 - val_loss: 0.2969 - val_mse: 0.2969\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8510 - mse: 0.8510 - val_loss: 0.2970 - val_mse: 0.2970\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8499 - mse: 0.8499 - val_loss: 0.2971 - val_mse: 0.2971\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8487 - mse: 0.8487 - val_loss: 0.2972 - val_mse: 0.2972\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8475 - mse: 0.8475 - val_loss: 0.2973 - val_mse: 0.2973\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8462 - mse: 0.8462 - val_loss: 0.2974 - val_mse: 0.2974\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8450 - mse: 0.8450 - val_loss: 0.2975 - val_mse: 0.2975\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8437 - mse: 0.8437 - val_loss: 0.2975 - val_mse: 0.2975\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.8423 - mse: 0.8423 - val_loss: 0.2976 - val_mse: 0.2976\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8410 - mse: 0.8410 - val_loss: 0.2977 - val_mse: 0.2977\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8396 - mse: 0.8396 - val_loss: 0.2977 - val_mse: 0.2977\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8381 - mse: 0.8381 - val_loss: 0.2978 - val_mse: 0.2978\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8367 - mse: 0.8367 - val_loss: 0.2978 - val_mse: 0.2978\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8352 - mse: 0.8352 - val_loss: 0.2979 - val_mse: 0.2979\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8337 - mse: 0.8337 - val_loss: 0.2979 - val_mse: 0.2979\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8321 - mse: 0.8321 - val_loss: 0.2979 - val_mse: 0.2979\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8305 - mse: 0.8305 - val_loss: 0.2979 - val_mse: 0.2979\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8289 - mse: 0.8289 - val_loss: 0.2979 - val_mse: 0.2979\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8272 - mse: 0.8272 - val_loss: 0.2979 - val_mse: 0.2979\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8255 - mse: 0.8255 - val_loss: 0.2979 - val_mse: 0.2979\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8237 - mse: 0.8237 - val_loss: 0.2979 - val_mse: 0.2979\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8219 - mse: 0.8219 - val_loss: 0.2979 - val_mse: 0.2979\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8201 - mse: 0.8201 - val_loss: 0.2978 - val_mse: 0.2978\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8182 - mse: 0.8182 - val_loss: 0.2978 - val_mse: 0.2978\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8162 - mse: 0.8162 - val_loss: 0.2977 - val_mse: 0.2977\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8142 - mse: 0.8142 - val_loss: 0.2976 - val_mse: 0.2976\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8122 - mse: 0.8122 - val_loss: 0.2975 - val_mse: 0.2975\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8101 - mse: 0.8101 - val_loss: 0.2974 - val_mse: 0.2974\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8080 - mse: 0.8080 - val_loss: 0.2973 - val_mse: 0.2973\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8058 - mse: 0.8058 - val_loss: 0.2972 - val_mse: 0.2972\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8036 - mse: 0.8036 - val_loss: 0.2970 - val_mse: 0.2970\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8013 - mse: 0.8013 - val_loss: 0.2969 - val_mse: 0.2969\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7990 - mse: 0.7990 - val_loss: 0.2967 - val_mse: 0.2967\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7966 - mse: 0.7966 - val_loss: 0.2965 - val_mse: 0.2965\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7941 - mse: 0.7941 - val_loss: 0.2963 - val_mse: 0.2963\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7916 - mse: 0.7916 - val_loss: 0.2960 - val_mse: 0.2960\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7890 - mse: 0.7890 - val_loss: 0.2958 - val_mse: 0.2958\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.7863 - mse: 0.7863 - val_loss: 0.2955 - val_mse: 0.2955\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7836 - mse: 0.7836 - val_loss: 0.2952 - val_mse: 0.2952\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7808 - mse: 0.7808 - val_loss: 0.2949 - val_mse: 0.2949\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7780 - mse: 0.7780 - val_loss: 0.2946 - val_mse: 0.2946\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7750 - mse: 0.7750 - val_loss: 0.2942 - val_mse: 0.2942\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7720 - mse: 0.7720 - val_loss: 0.2938 - val_mse: 0.2938\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7690 - mse: 0.7690 - val_loss: 0.2934 - val_mse: 0.2934\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7658 - mse: 0.7658 - val_loss: 0.2929 - val_mse: 0.2929\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.7626 - mse: 0.7626 - val_loss: 0.2925 - val_mse: 0.2925\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7593 - mse: 0.7593 - val_loss: 0.2919 - val_mse: 0.2919\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7559 - mse: 0.7559 - val_loss: 0.2914 - val_mse: 0.2914\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7524 - mse: 0.7524 - val_loss: 0.2908 - val_mse: 0.2908\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7488 - mse: 0.7488 - val_loss: 0.2902 - val_mse: 0.2902\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7452 - mse: 0.7452 - val_loss: 0.2896 - val_mse: 0.2896\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7414 - mse: 0.7414 - val_loss: 0.2889 - val_mse: 0.2889\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7376 - mse: 0.7376 - val_loss: 0.2882 - val_mse: 0.2882\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7336 - mse: 0.7336 - val_loss: 0.2875 - val_mse: 0.2875\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7296 - mse: 0.7296 - val_loss: 0.2867 - val_mse: 0.2867\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7255 - mse: 0.7255 - val_loss: 0.2859 - val_mse: 0.2859\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7212 - mse: 0.7212 - val_loss: 0.2850 - val_mse: 0.2850\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7169 - mse: 0.7169 - val_loss: 0.2841 - val_mse: 0.2841\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7124 - mse: 0.7124 - val_loss: 0.2831 - val_mse: 0.2831\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7079 - mse: 0.7079 - val_loss: 0.2821 - val_mse: 0.2821\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7032 - mse: 0.7032 - val_loss: 0.2811 - val_mse: 0.2811\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6984 - mse: 0.6984 - val_loss: 0.2799 - val_mse: 0.2799\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6935 - mse: 0.6935 - val_loss: 0.2788 - val_mse: 0.2788\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6885 - mse: 0.6885 - val_loss: 0.2776 - val_mse: 0.2776\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6834 - mse: 0.6834 - val_loss: 0.2763 - val_mse: 0.2763\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6781 - mse: 0.6781 - val_loss: 0.2750 - val_mse: 0.2750\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6727 - mse: 0.6727 - val_loss: 0.2736 - val_mse: 0.2736\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6672 - mse: 0.6672 - val_loss: 0.2721 - val_mse: 0.2721\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6615 - mse: 0.6615 - val_loss: 0.2706 - val_mse: 0.2706\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6558 - mse: 0.6558 - val_loss: 0.2691 - val_mse: 0.2691\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6499 - mse: 0.6499 - val_loss: 0.2674 - val_mse: 0.2674\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6438 - mse: 0.6438 - val_loss: 0.2657 - val_mse: 0.2657\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6377 - mse: 0.6377 - val_loss: 0.2640 - val_mse: 0.2640\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6314 - mse: 0.6314 - val_loss: 0.2621 - val_mse: 0.2621\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6249 - mse: 0.6249 - val_loss: 0.2602 - val_mse: 0.2602\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6183 - mse: 0.6183 - val_loss: 0.2583 - val_mse: 0.2583\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6116 - mse: 0.6116 - val_loss: 0.2562 - val_mse: 0.2562\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6047 - mse: 0.6047 - val_loss: 0.2541 - val_mse: 0.2541\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5977 - mse: 0.5977 - val_loss: 0.2519 - val_mse: 0.2519\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5906 - mse: 0.5906 - val_loss: 0.2497 - val_mse: 0.2497\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5833 - mse: 0.5833 - val_loss: 0.2473 - val_mse: 0.2473\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5759 - mse: 0.5759 - val_loss: 0.2449 - val_mse: 0.2449\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5683 - mse: 0.5683 - val_loss: 0.2424 - val_mse: 0.2424\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5606 - mse: 0.5606 - val_loss: 0.2399 - val_mse: 0.2399\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5528 - mse: 0.5528 - val_loss: 0.2372 - val_mse: 0.2372\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5448 - mse: 0.5448 - val_loss: 0.2345 - val_mse: 0.2345\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5367 - mse: 0.5367 - val_loss: 0.2318 - val_mse: 0.2318\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5285 - mse: 0.5285 - val_loss: 0.2289 - val_mse: 0.2289\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5201 - mse: 0.5201 - val_loss: 0.2260 - val_mse: 0.2260\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5116 - mse: 0.5116 - val_loss: 0.2230 - val_mse: 0.2230\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5030 - mse: 0.5030 - val_loss: 0.2200 - val_mse: 0.2200\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4943 - mse: 0.4943 - val_loss: 0.2169 - val_mse: 0.2169\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4855 - mse: 0.4855 - val_loss: 0.2137 - val_mse: 0.2137\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4766 - mse: 0.4766 - val_loss: 0.2105 - val_mse: 0.2105\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4676 - mse: 0.4676 - val_loss: 0.2072 - val_mse: 0.2072\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4585 - mse: 0.4585 - val_loss: 0.2039 - val_mse: 0.2039\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4493 - mse: 0.4493 - val_loss: 0.2005 - val_mse: 0.2005\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4400 - mse: 0.4400 - val_loss: 0.1971 - val_mse: 0.1971\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4307 - mse: 0.4307 - val_loss: 0.1937 - val_mse: 0.1937\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4213 - mse: 0.4213 - val_loss: 0.1902 - val_mse: 0.1902\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4118 - mse: 0.4118 - val_loss: 0.1867 - val_mse: 0.1867\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4024 - mse: 0.4024 - val_loss: 0.1832 - val_mse: 0.1832\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3928 - mse: 0.3928 - val_loss: 0.1797 - val_mse: 0.1797\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3833 - mse: 0.3833 - val_loss: 0.1762 - val_mse: 0.1762\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3738 - mse: 0.3738 - val_loss: 0.1727 - val_mse: 0.1727\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3642 - mse: 0.3642 - val_loss: 0.1692 - val_mse: 0.1692\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3547 - mse: 0.3547 - val_loss: 0.1657 - val_mse: 0.1657\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# from tensorflow.python.keras.layers import Dense\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "variables,results = split_x_and_y(database.iloc[[0,1,2,3,4,5,6,7,8]],['A','E','N'],'Tmax')\n",
    "test_x,test_y = split_x_and_y(database.iloc[[9,10,11]],['A','E','N'],'Tmax')\n",
    "\n",
    "model_3 = keras.Sequential([\n",
    "  layers.Dense(256*4, activation='sigmoid', input_shape=[len(variables.keys())]),\n",
    "  # layers.Dropout(0.3),\n",
    "  layers.Dense(256*4, activation='sigmoid'),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "# optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "model_3.compile(optimizer='adam',loss='mean_squared_error',metrics=['mse'])\n",
    "\n",
    "history = model_3.fit(variables.values,results.values,epochs=500,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2126cffe070>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['loss','val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 25.        ,   1.        ,   8.        ,  83.86557582],\n",
       "       [ 25.        ,   2.        ,   5.        , 100.94431703],\n",
       "       [ 35.        ,   3.        ,  11.        ,  94.71345111]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guess = model_3.predict(test_x.values)\n",
    "desnormalizar = test_x.copy()\n",
    "desnormalizar['Tmax'] = guess\n",
    "desnormalizado_teste = standardscaler.inverse_transform(desnormalizar)\n",
    "desnormalizado_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25.  ,  1.  ,  8.  , 76.3 ],\n",
       "       [25.  ,  2.  ,  5.  , 98.76],\n",
       "       [35.  ,  3.  , 11.  , 94.7 ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desnormalizar = test_x.copy()\n",
    "desnormalizar['Tmax'] = test_y\n",
    "desnormalizado_resultado = standardscaler.inverse_transform(desnormalizar)\n",
    "desnormalizado_resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: 0.7835612372364952 meansquarederror: 20.669786409907918 meanabsoluteerror: 3.2544479857934525 maxerror: 7.565575815794801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7835612372364952, 20.669786409907918, 3.2544479857934525, 7.565575815794801)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores(desnormalizado_resultado[:,-1],desnormalizado_teste[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.save(\"keras_model_Tmax.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "edbada794071f9c875b2bc5e0e869a1d746a19a0ba8801f10239845106c51c5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
