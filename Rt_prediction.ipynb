{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>E</th>\n",
       "      <th>N</th>\n",
       "      <th>Rt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1.638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>4.164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2.869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1.421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1.564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1.591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1.946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2.896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A  E   N     Rt\n",
       "0   25  1  11  1.638\n",
       "1   25  1   5  2.595\n",
       "2   25  2   8  1.976\n",
       "3   25  3  11  4.164\n",
       "4   25  3   5  2.869\n",
       "5   35  1   8  1.421\n",
       "6   35  2  11  1.564\n",
       "7   35  2   5  2.101\n",
       "8   35  3   8  1.591\n",
       "9   25  1   8  1.946\n",
       "10  25  2   5  2.991\n",
       "11  35  3  11  2.896"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "database = pd.read_excel('database_TCC.xlsx')\n",
    "database = database[['A','E','N','Rt']]\n",
    "database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standardscaler = StandardScaler()\n",
    "standardscaler.fit(database)\n",
    "data = standardscaler.transform(database)\n",
    "database = pd.DataFrame(data,columns=database.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(standardscaler, open('standard_scaler_Rt.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error,max_error\n",
    "\n",
    "def split_x_and_y(database,x,y):\n",
    "  dataset_x = database[x]\n",
    "  dataset_y = database[y]\n",
    "  return dataset_x,dataset_y\n",
    "\n",
    "\n",
    "def scores(Y_true, Y_predicted):\n",
    "  r2 = r2_score(Y_true, Y_predicted)\n",
    "  meansquarederror = mean_squared_error(Y_true, Y_predicted)\n",
    "  meanabsoluteerror = mean_absolute_error(Y_true, Y_predicted)\n",
    "  maxerror = max_error(Y_true, Y_predicted)\n",
    "\n",
    "  print('r2:',r2,'meansquarederror:',meansquarederror,'meanabsoluteerror:',meanabsoluteerror,'maxerror:',maxerror)\n",
    "  return r2,meansquarederror,meanabsoluteerror,maxerror\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3306427822593704"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# database.iloc[[0,2,4,5,7,8]]\n",
    "\n",
    "dataset_x,dataset_y = split_x_and_y(database.iloc[[0,1,2,3,4,5,6,7,8]],['A','E','N'],'Rt')\n",
    "\n",
    "test_x,test_y = split_x_and_y(database.iloc[[9,10,11]],['A','E','N'],'Rt')\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RFR = RandomForestRegressor(n_estimators=5000,random_state=100)\n",
    "RFR.fit(dataset_x,dataset_y)\n",
    "RFR.score(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21042855, 0.33216308, 0.45740836])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFR.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(RFR, open('Random_Forest_Regressor_Rt.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4359749662202925"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_x,dataset_y = split_x_and_y(database.iloc[[0,1,2,3,4,5,6,7,8]],['A','E','N'],'Rt')\n",
    "\n",
    "test_x,test_y = split_x_and_y(database.iloc[[9,10,11]],['A','E','N'],'Rt')\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "svr = svm.SVR(kernel='sigmoid',C=3,gamma='auto')\n",
    "\n",
    "svr.fit(dataset_x,dataset_y)\n",
    "svr.score(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(svr, open('Support_Vector_Machine_Rt.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.05892459425244634"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_x,dataset_y = split_x_and_y(database.iloc[[0,1,2,3,4,5,6,7,8]],['A','E','N'],'Rt')\n",
    "\n",
    "test_x,test_y = split_x_and_y(database.iloc[[9,10,11]],['A','E','N'],'Rt')\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "MLP = MLPRegressor(max_iter=1000,random_state=100)\n",
    "MLP.fit(dataset_x,dataset_y)\n",
    "MLP.score(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# pickle.dump(MLP, open('MLP_Rt.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/125\n",
      "1/1 [==============================] - 1s 562ms/step - loss: 1.7420 - mse: 1.7420 - val_loss: 34.7392 - val_mse: 34.7392\n",
      "Epoch 2/125\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 43.6279 - mse: 43.6279 - val_loss: 1.4723 - val_mse: 1.4723\n",
      "Epoch 3/125\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.5262 - mse: 4.5262 - val_loss: 14.1996 - val_mse: 14.1996\n",
      "Epoch 4/125\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 11.2312 - mse: 11.2312 - val_loss: 28.9999 - val_mse: 28.9999\n",
      "Epoch 5/125\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 24.0266 - mse: 24.0266 - val_loss: 19.3893 - val_mse: 19.3893\n",
      "Epoch 6/125\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 15.6050 - mse: 15.6050 - val_loss: 4.9523 - val_mse: 4.9523\n",
      "Epoch 7/125\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.8571 - mse: 3.8571 - val_loss: 0.1494 - val_mse: 0.1494\n",
      "Epoch 8/125\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.9897 - mse: 1.9897 - val_loss: 3.9393 - val_mse: 3.9393\n",
      "Epoch 9/125\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.9000 - mse: 7.9000 - val_loss: 7.0271 - val_mse: 7.0271\n",
      "Epoch 10/125\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 11.7852 - mse: 11.7852 - val_loss: 5.3419 - val_mse: 5.3419\n",
      "Epoch 11/125\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.6800 - mse: 9.6800 - val_loss: 1.6365 - val_mse: 1.6365\n",
      "Epoch 12/125\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.7045 - mse: 4.7045 - val_loss: 0.1367 - val_mse: 0.1367\n",
      "Epoch 13/125\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.5181 - mse: 1.5181 - val_loss: 2.3395 - val_mse: 2.3395\n",
      "Epoch 14/125\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.0770 - mse: 2.0770 - val_loss: 6.1177 - val_mse: 6.1177\n",
      "Epoch 15/125\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.6637 - mse: 4.6637 - val_loss: 8.2322 - val_mse: 8.2322\n",
      "Epoch 16/125\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.2759 - mse: 6.2759 - val_loss: 7.3218 - val_mse: 7.3218\n",
      "Epoch 17/125\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.5659 - mse: 5.5659 - val_loss: 4.4400 - val_mse: 4.4400\n",
      "Epoch 18/125\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4314 - mse: 3.4314 - val_loss: 1.6163 - val_mse: 1.6163\n",
      "Epoch 19/125\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.6580 - mse: 1.6580 - val_loss: 0.2287 - val_mse: 0.2287\n",
      "Epoch 20/125\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.3552 - mse: 1.3552 - val_loss: 0.2782 - val_mse: 0.2782\n",
      "Epoch 21/125\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.2876 - mse: 2.2876 - val_loss: 0.8224 - val_mse: 0.8224\n",
      "Epoch 22/125\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.3545 - mse: 3.3545 - val_loss: 0.9834 - val_mse: 0.9834\n",
      "Epoch 23/125\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.6189 - mse: 3.6189 - val_loss: 0.6062 - val_mse: 0.6062\n",
      "Epoch 24/125\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.9574 - mse: 2.9574 - val_loss: 0.1721 - val_mse: 0.1721\n",
      "Epoch 25/125\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.9508 - mse: 1.9508 - val_loss: 0.2534 - val_mse: 0.2534\n",
      "Epoch 26/125\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.3129 - mse: 1.3129 - val_loss: 1.0085 - val_mse: 1.0085\n",
      "Epoch 27/125\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.3585 - mse: 1.3585 - val_loss: 2.0657 - val_mse: 2.0657\n",
      "Epoch 28/125\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.8571 - mse: 1.8571 - val_loss: 2.8235 - val_mse: 2.8235\n",
      "Epoch 29/125\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.3042 - mse: 2.3042 - val_loss: 2.8845 - val_mse: 2.8845\n",
      "Epoch 30/125\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.3383 - mse: 2.3383 - val_loss: 2.2842 - val_mse: 2.2842\n",
      "Epoch 31/125\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.9689 - mse: 1.9689 - val_loss: 1.3949 - val_mse: 1.3949\n",
      "Epoch 32/125\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.4941 - mse: 1.4941 - val_loss: 0.6379 - val_mse: 0.6379\n",
      "Epoch 33/125\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2331 - mse: 1.2331 - val_loss: 0.2314 - val_mse: 0.2314\n",
      "Epoch 34/125\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.2968 - mse: 1.2968 - val_loss: 0.1284 - val_mse: 0.1284\n",
      "Epoch 35/125\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.5473 - mse: 1.5473 - val_loss: 0.1445 - val_mse: 0.1445\n",
      "Epoch 36/125\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.7418 - mse: 1.7418 - val_loss: 0.1433 - val_mse: 0.1433\n",
      "Epoch 37/125\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.7250 - mse: 1.7250 - val_loss: 0.1310 - val_mse: 0.1310\n",
      "Epoch 38/125\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.5240 - mse: 1.5240 - val_loss: 0.2114 - val_mse: 0.2114\n",
      "Epoch 39/125\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2951 - mse: 1.2951 - val_loss: 0.4634 - val_mse: 0.4634\n",
      "Epoch 40/125\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1882 - mse: 1.1882 - val_loss: 0.8480 - val_mse: 0.8480\n",
      "Epoch 41/125\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.2402 - mse: 1.2402 - val_loss: 1.2168 - val_mse: 1.2168\n",
      "Epoch 42/125\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.3668 - mse: 1.3668 - val_loss: 1.4067 - val_mse: 1.4067\n",
      "Epoch 43/125\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.4452 - mse: 1.4452 - val_loss: 1.3434 - val_mse: 1.3434\n",
      "Epoch 44/125\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.4109 - mse: 1.4109 - val_loss: 1.0783 - val_mse: 1.0783\n",
      "Epoch 45/125\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2952 - mse: 1.2952 - val_loss: 0.7421 - val_mse: 0.7421\n",
      "Epoch 46/125\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.1855 - mse: 1.1855 - val_loss: 0.4589 - val_mse: 0.4589\n",
      "Epoch 47/125\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1504 - mse: 1.1504 - val_loss: 0.2851 - val_mse: 0.2851\n",
      "Epoch 48/125\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1911 - mse: 1.1911 - val_loss: 0.2085 - val_mse: 0.2085\n",
      "Epoch 49/125\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2518 - mse: 1.2518 - val_loss: 0.1916 - val_mse: 0.1916\n",
      "Epoch 50/125\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2715 - mse: 1.2715 - val_loss: 0.2162 - val_mse: 0.2162\n",
      "Epoch 51/125\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.2319 - mse: 1.2319 - val_loss: 0.2924 - val_mse: 0.2924\n",
      "Epoch 52/125\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1640 - mse: 1.1640 - val_loss: 0.4316 - val_mse: 0.4316\n",
      "Epoch 53/125\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1161 - mse: 1.1161 - val_loss: 0.6156 - val_mse: 0.6156\n",
      "Epoch 54/125\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1130 - mse: 1.1130 - val_loss: 0.7901 - val_mse: 0.7901\n",
      "Epoch 55/125\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1401 - mse: 1.1401 - val_loss: 0.8913 - val_mse: 0.8913\n",
      "Epoch 56/125\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1615 - mse: 1.1615 - val_loss: 0.8839 - val_mse: 0.8839\n",
      "Epoch 57/125\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1521 - mse: 1.1521 - val_loss: 0.7802 - val_mse: 0.7802\n",
      "Epoch 58/125\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.1163 - mse: 1.1163 - val_loss: 0.6290 - val_mse: 0.6290\n",
      "Epoch 59/125\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0794 - mse: 1.0794 - val_loss: 0.4846 - val_mse: 0.4846\n",
      "Epoch 60/125\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.0635 - mse: 1.0635 - val_loss: 0.3809 - val_mse: 0.3809\n",
      "Epoch 61/125\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0697 - mse: 1.0697 - val_loss: 0.3266 - val_mse: 0.3266\n",
      "Epoch 62/125\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0807 - mse: 1.0807 - val_loss: 0.3166 - val_mse: 0.3166\n",
      "Epoch 63/125\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0779 - mse: 1.0779 - val_loss: 0.3461 - val_mse: 0.3461\n",
      "Epoch 64/125\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0578 - mse: 1.0578 - val_loss: 0.4123 - val_mse: 0.4123\n",
      "Epoch 65/125\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0322 - mse: 1.0322 - val_loss: 0.5061 - val_mse: 0.5061\n",
      "Epoch 66/125\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.6054 - val_mse: 0.6054\n",
      "Epoch 67/125\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.0126 - mse: 1.0126 - val_loss: 0.6800 - val_mse: 0.6800\n",
      "Epoch 68/125\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0148 - mse: 1.0148 - val_loss: 0.7053 - val_mse: 0.7053\n",
      "Epoch 69/125\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0107 - mse: 1.0107 - val_loss: 0.6761 - val_mse: 0.6761\n",
      "Epoch 70/125\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9964 - mse: 0.9964 - val_loss: 0.6083 - val_mse: 0.6083\n",
      "Epoch 71/125\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9776 - mse: 0.9776 - val_loss: 0.5287 - val_mse: 0.5287\n",
      "Epoch 72/125\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9633 - mse: 0.9633 - val_loss: 0.4614 - val_mse: 0.4614\n",
      "Epoch 73/125\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9566 - mse: 0.9566 - val_loss: 0.4199 - val_mse: 0.4199\n",
      "Epoch 74/125\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9533 - mse: 0.9533 - val_loss: 0.4082 - val_mse: 0.4082\n",
      "Epoch 75/125\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9464 - mse: 0.9464 - val_loss: 0.4250 - val_mse: 0.4250\n",
      "Epoch 76/125\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9337 - mse: 0.9337 - val_loss: 0.4659 - val_mse: 0.4659\n",
      "Epoch 77/125\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9185 - mse: 0.9185 - val_loss: 0.5214 - val_mse: 0.5214\n",
      "Epoch 78/125\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9060 - mse: 0.9060 - val_loss: 0.5768 - val_mse: 0.5768\n",
      "Epoch 79/125\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8979 - mse: 0.8979 - val_loss: 0.6153 - val_mse: 0.6153\n",
      "Epoch 80/125\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8912 - mse: 0.8912 - val_loss: 0.6252 - val_mse: 0.6252\n",
      "Epoch 81/125\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8821 - mse: 0.8821 - val_loss: 0.6058 - val_mse: 0.6058\n",
      "Epoch 82/125\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8697 - mse: 0.8697 - val_loss: 0.5671 - val_mse: 0.5671\n",
      "Epoch 83/125\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8564 - mse: 0.8564 - val_loss: 0.5240 - val_mse: 0.5240\n",
      "Epoch 84/125\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8451 - mse: 0.8451 - val_loss: 0.4899 - val_mse: 0.4899\n",
      "Epoch 85/125\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8362 - mse: 0.8362 - val_loss: 0.4727 - val_mse: 0.4727\n",
      "Epoch 86/125\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8274 - mse: 0.8274 - val_loss: 0.4747 - val_mse: 0.4747\n",
      "Epoch 87/125\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8169 - mse: 0.8169 - val_loss: 0.4942 - val_mse: 0.4942\n",
      "Epoch 88/125\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8046 - mse: 0.8046 - val_loss: 0.5255 - val_mse: 0.5255\n",
      "Epoch 89/125\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7926 - mse: 0.7926 - val_loss: 0.5596 - val_mse: 0.5596\n",
      "Epoch 90/125\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7821 - mse: 0.7821 - val_loss: 0.5861 - val_mse: 0.5861\n",
      "Epoch 91/125\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7727 - mse: 0.7727 - val_loss: 0.5970 - val_mse: 0.5970\n",
      "Epoch 92/125\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.7627 - mse: 0.7627 - val_loss: 0.5905 - val_mse: 0.5905\n",
      "Epoch 93/125\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7516 - mse: 0.7516 - val_loss: 0.5710 - val_mse: 0.5710\n",
      "Epoch 94/125\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7401 - mse: 0.7401 - val_loss: 0.5472 - val_mse: 0.5472\n",
      "Epoch 95/125\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7292 - mse: 0.7292 - val_loss: 0.5276 - val_mse: 0.5276\n",
      "Epoch 96/125\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7193 - mse: 0.7193 - val_loss: 0.5182 - val_mse: 0.5182\n",
      "Epoch 97/125\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7096 - mse: 0.7096 - val_loss: 0.5211 - val_mse: 0.5211\n",
      "Epoch 98/125\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6993 - mse: 0.6993 - val_loss: 0.5350 - val_mse: 0.5350\n",
      "Epoch 99/125\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6886 - mse: 0.6886 - val_loss: 0.5554 - val_mse: 0.5554\n",
      "Epoch 100/125\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6782 - mse: 0.6782 - val_loss: 0.5760 - val_mse: 0.5760\n",
      "Epoch 101/125\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6684 - mse: 0.6684 - val_loss: 0.5906 - val_mse: 0.5906\n",
      "Epoch 102/125\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6591 - mse: 0.6591 - val_loss: 0.5952 - val_mse: 0.5952\n",
      "Epoch 103/125\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6497 - mse: 0.6497 - val_loss: 0.5898 - val_mse: 0.5898\n",
      "Epoch 104/125\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6401 - mse: 0.6401 - val_loss: 0.5782 - val_mse: 0.5782\n",
      "Epoch 105/125\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6306 - mse: 0.6306 - val_loss: 0.5662 - val_mse: 0.5662\n",
      "Epoch 106/125\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6216 - mse: 0.6216 - val_loss: 0.5585 - val_mse: 0.5585\n",
      "Epoch 107/125\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6131 - mse: 0.6131 - val_loss: 0.5582 - val_mse: 0.5582\n",
      "Epoch 108/125\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6047 - mse: 0.6047 - val_loss: 0.5655 - val_mse: 0.5655\n",
      "Epoch 109/125\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5963 - mse: 0.5963 - val_loss: 0.5781 - val_mse: 0.5781\n",
      "Epoch 110/125\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5881 - mse: 0.5881 - val_loss: 0.5922 - val_mse: 0.5922\n",
      "Epoch 111/125\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5803 - mse: 0.5803 - val_loss: 0.6035 - val_mse: 0.6035\n",
      "Epoch 112/125\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5730 - mse: 0.5730 - val_loss: 0.6092 - val_mse: 0.6092\n",
      "Epoch 113/125\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5659 - mse: 0.5659 - val_loss: 0.6087 - val_mse: 0.6087\n",
      "Epoch 114/125\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5589 - mse: 0.5589 - val_loss: 0.6039 - val_mse: 0.6039\n",
      "Epoch 115/125\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5521 - mse: 0.5521 - val_loss: 0.5983 - val_mse: 0.5983\n",
      "Epoch 116/125\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5458 - mse: 0.5458 - val_loss: 0.5951 - val_mse: 0.5951\n",
      "Epoch 117/125\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5398 - mse: 0.5398 - val_loss: 0.5965 - val_mse: 0.5965\n",
      "Epoch 118/125\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5341 - mse: 0.5341 - val_loss: 0.6026 - val_mse: 0.6026\n",
      "Epoch 119/125\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5286 - mse: 0.5286 - val_loss: 0.6119 - val_mse: 0.6119\n",
      "Epoch 120/125\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5234 - mse: 0.5234 - val_loss: 0.6218 - val_mse: 0.6218\n",
      "Epoch 121/125\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5186 - mse: 0.5186 - val_loss: 0.6298 - val_mse: 0.6298\n",
      "Epoch 122/125\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5141 - mse: 0.5141 - val_loss: 0.6341 - val_mse: 0.6341\n",
      "Epoch 123/125\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5099 - mse: 0.5099 - val_loss: 0.6347 - val_mse: 0.6347\n",
      "Epoch 124/125\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5059 - mse: 0.5059 - val_loss: 0.6332 - val_mse: 0.6332\n",
      "Epoch 125/125\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5022 - mse: 0.5022 - val_loss: 0.6318 - val_mse: 0.6318\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# from tensorflow.python.keras.layers import Dense\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "variables,results = split_x_and_y(database.iloc[[0,1,2,3,4,5,6,7,8]],['A','E','N'],'Rt')\n",
    "test_x,test_y = split_x_and_y(database.iloc[[9,10,11]],['A','E','N'],'Rt')\n",
    "\n",
    "model = keras.Sequential([\n",
    "  layers.Dense(256*5, activation='sigmoid', input_shape=[len(variables.keys())]),\n",
    "  # layers.Dropout(0.1),\n",
    "  layers.Dense(256*5, activation='sigmoid'),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "# optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "model.compile(optimizer='adam',loss='mean_squared_error',metrics=['mse'])\n",
    "\n",
    "history = model.fit(variables.values,results.values,epochs=125,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Erro Médio Quadrado')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "# plt.ylim([0, 5])\n",
    "plt.legend(['Treino','Validacao'],prop={'size': 14})\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Erro Médio Quadrado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[25.        ,  1.        ,  8.        ,  2.00328989],\n",
       "       [25.        ,  2.        ,  5.        ,  2.62562428],\n",
       "       [35.        ,  3.        , 11.        ,  2.46215184]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guess = model.predict(test_x.values)\n",
    "desnormalizar = test_x.copy()\n",
    "desnormalizar['Rt'] = guess\n",
    "desnormalizado_teste = standardscaler.inverse_transform(desnormalizar)\n",
    "desnormalizado_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25.   ,  1.   ,  8.   ,  1.946],\n",
       "       [25.   ,  2.   ,  5.   ,  2.991],\n",
       "       [35.   ,  3.   , 11.   ,  2.896]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desnormalizar = test_x.copy()\n",
    "desnormalizar['Rt'] = test_y\n",
    "desnormalizado_resultado = standardscaler.inverse_transform(desnormalizar)\n",
    "desnormalizado_resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: 0.5133551356380042 meansquarederror: 0.10833525755471966 meanabsoluteerror: 0.28550459055169575 maxerror: 0.43384815857620085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5133551356380042,\n",
       " 0.10833525755471966,\n",
       " 0.28550459055169575,\n",
       " 0.43384815857620085)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores(desnormalizado_resultado[:,-1],desnormalizado_teste[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"keras_model_Rt.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KERAS BOXPLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "1/1 [==============================] - 1s 610ms/step - loss: 1.4196 - mse: 1.4196 - val_loss: 37.7577 - val_mse: 37.7577\n",
      "Epoch 2/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 46.9060 - mse: 46.9060 - val_loss: 1.4726 - val_mse: 1.4726\n",
      "Epoch 3/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5021 - mse: 4.5021 - val_loss: 15.3231 - val_mse: 15.3231\n",
      "Epoch 4/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 12.1534 - mse: 12.1534 - val_loss: 31.5325 - val_mse: 31.5325\n",
      "Epoch 5/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 26.2454 - mse: 26.2454 - val_loss: 22.2779 - val_mse: 22.2779\n",
      "Epoch 6/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 18.0769 - mse: 18.0769 - val_loss: 6.7164 - val_mse: 6.7164\n",
      "Epoch 7/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.1495 - mse: 5.1495 - val_loss: 0.1306 - val_mse: 0.1306\n",
      "Epoch 8/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.5564 - mse: 1.5564 - val_loss: 3.3304 - val_mse: 3.3304\n",
      "Epoch 9/120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.0724 - mse: 7.0724 - val_loss: 7.3673 - val_mse: 7.3673\n",
      "Epoch 10/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 12.1752 - mse: 12.1752 - val_loss: 6.6965 - val_mse: 6.6965\n",
      "Epoch 11/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 11.3422 - mse: 11.3422 - val_loss: 2.9098 - val_mse: 2.9098\n",
      "Epoch 12/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.4818 - mse: 6.4818 - val_loss: 0.2407 - val_mse: 0.2407\n",
      "Epoch 13/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.2195 - mse: 2.2195 - val_loss: 1.1904 - val_mse: 1.1904\n",
      "Epoch 14/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.4773 - mse: 1.4773 - val_loss: 4.7684 - val_mse: 4.7684\n",
      "Epoch 15/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6689 - mse: 3.6689 - val_loss: 7.9118 - val_mse: 7.9118\n",
      "Epoch 16/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.0177 - mse: 6.0177 - val_loss: 8.3965 - val_mse: 8.3965\n",
      "Epoch 17/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.3916 - mse: 6.3916 - val_loss: 6.2735 - val_mse: 6.2735\n",
      "Epoch 18/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7589 - mse: 4.7589 - val_loss: 3.1852 - val_mse: 3.1852\n",
      "Epoch 19/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.5712 - mse: 2.5712 - val_loss: 0.8841 - val_mse: 0.8841\n",
      "Epoch 20/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3430 - mse: 1.3430 - val_loss: 0.1240 - val_mse: 0.1240\n",
      "Epoch 21/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.5911 - mse: 1.5911 - val_loss: 0.4710 - val_mse: 0.4710\n",
      "Epoch 22/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.6910 - mse: 2.6910 - val_loss: 0.9631 - val_mse: 0.9631\n",
      "Epoch 23/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.5688 - mse: 3.5688 - val_loss: 0.9603 - val_mse: 0.9603\n",
      "Epoch 24/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.5588 - mse: 3.5588 - val_loss: 0.5148 - val_mse: 0.5148\n",
      "Epoch 25/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.7615 - mse: 2.7615 - val_loss: 0.1432 - val_mse: 0.1432\n",
      "Epoch 26/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.7952 - mse: 1.7952 - val_loss: 0.3243 - val_mse: 0.3243\n",
      "Epoch 27/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2720 - mse: 1.2720 - val_loss: 1.1174 - val_mse: 1.1174\n",
      "Epoch 28/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.3919 - mse: 1.3919 - val_loss: 2.1340 - val_mse: 2.1340\n",
      "Epoch 29/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.8897 - mse: 1.8897 - val_loss: 2.8310 - val_mse: 2.8310\n",
      "Epoch 30/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.3039 - mse: 2.3039 - val_loss: 2.8722 - val_mse: 2.8722\n",
      "Epoch 31/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.3260 - mse: 2.3260 - val_loss: 2.3007 - val_mse: 2.3007\n",
      "Epoch 32/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.9741 - mse: 1.9741 - val_loss: 1.4496 - val_mse: 1.4496\n",
      "Epoch 33/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.5148 - mse: 1.5148 - val_loss: 0.7010 - val_mse: 0.7010\n",
      "Epoch 34/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2395 - mse: 1.2395 - val_loss: 0.2697 - val_mse: 0.2697\n",
      "Epoch 35/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2663 - mse: 1.2663 - val_loss: 0.1365 - val_mse: 0.1365\n",
      "Epoch 36/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4920 - mse: 1.4920 - val_loss: 0.1428 - val_mse: 0.1428\n",
      "Epoch 37/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7007 - mse: 1.7007 - val_loss: 0.1490 - val_mse: 0.1490\n",
      "Epoch 38/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.7297 - mse: 1.7297 - val_loss: 0.1338 - val_mse: 0.1338\n",
      "Epoch 39/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.5699 - mse: 1.5699 - val_loss: 0.1783 - val_mse: 0.1783\n",
      "Epoch 40/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.3441 - mse: 1.3441 - val_loss: 0.3687 - val_mse: 0.3687\n",
      "Epoch 41/120\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1994 - mse: 1.1994 - val_loss: 0.7038 - val_mse: 0.7038\n",
      "Epoch 42/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.2031 - mse: 1.2031 - val_loss: 1.0760 - val_mse: 1.0760\n",
      "Epoch 43/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.3095 - mse: 1.3095 - val_loss: 1.3334 - val_mse: 1.3334\n",
      "Epoch 44/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4111 - mse: 1.4111 - val_loss: 1.3728 - val_mse: 1.3728\n",
      "Epoch 45/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4239 - mse: 1.4239 - val_loss: 1.1955 - val_mse: 1.1955\n",
      "Epoch 46/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3414 - mse: 1.3414 - val_loss: 0.8949 - val_mse: 0.8949\n",
      "Epoch 47/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2263 - mse: 1.2263 - val_loss: 0.5922 - val_mse: 0.5922\n",
      "Epoch 48/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.1544 - mse: 1.1544 - val_loss: 0.3712 - val_mse: 0.3712\n",
      "Epoch 49/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1582 - mse: 1.1582 - val_loss: 0.2505 - val_mse: 0.2505\n",
      "Epoch 50/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2112 - mse: 1.2112 - val_loss: 0.2043 - val_mse: 0.2043\n",
      "Epoch 51/120\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2562 - mse: 1.2562 - val_loss: 0.2040 - val_mse: 0.2040\n",
      "Epoch 52/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.2520 - mse: 1.2520 - val_loss: 0.2439 - val_mse: 0.2439\n",
      "Epoch 53/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.2011 - mse: 1.2011 - val_loss: 0.3363 - val_mse: 0.3363\n",
      "Epoch 54/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1406 - mse: 1.1406 - val_loss: 0.4837 - val_mse: 0.4837\n",
      "Epoch 55/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1085 - mse: 1.1085 - val_loss: 0.6586 - val_mse: 0.6586\n",
      "Epoch 56/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1156 - mse: 1.1156 - val_loss: 0.8077 - val_mse: 0.8077\n",
      "Epoch 57/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1415 - mse: 1.1415 - val_loss: 0.8792 - val_mse: 0.8792\n",
      "Epoch 58/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1551 - mse: 1.1551 - val_loss: 0.8518 - val_mse: 0.8518\n",
      "Epoch 59/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.1402 - mse: 1.1402 - val_loss: 0.7447 - val_mse: 0.7447\n",
      "Epoch 60/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1056 - mse: 1.1056 - val_loss: 0.6032 - val_mse: 0.6032\n",
      "Epoch 61/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0740 - mse: 1.0740 - val_loss: 0.4729 - val_mse: 0.4729\n",
      "Epoch 62/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0621 - mse: 1.0621 - val_loss: 0.3808 - val_mse: 0.3808\n",
      "Epoch 63/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0683 - mse: 1.0683 - val_loss: 0.3332 - val_mse: 0.3332\n",
      "Epoch 64/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0770 - mse: 1.0770 - val_loss: 0.3257 - val_mse: 0.3257\n",
      "Epoch 65/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0732 - mse: 1.0732 - val_loss: 0.3543 - val_mse: 0.3543\n",
      "Epoch 66/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0545 - mse: 1.0545 - val_loss: 0.4158 - val_mse: 0.4158\n",
      "Epoch 67/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0313 - mse: 1.0313 - val_loss: 0.5019 - val_mse: 0.5019\n",
      "Epoch 68/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0158 - mse: 1.0158 - val_loss: 0.5933 - val_mse: 0.5933\n",
      "Epoch 69/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0119 - mse: 1.0119 - val_loss: 0.6639 - val_mse: 0.6639\n",
      "Epoch 70/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0130 - mse: 1.0130 - val_loss: 0.6919 - val_mse: 0.6919\n",
      "Epoch 71/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0096 - mse: 1.0096 - val_loss: 0.6713 - val_mse: 0.6713\n",
      "Epoch 72/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9973 - mse: 0.9973 - val_loss: 0.6137 - val_mse: 0.6137\n",
      "Epoch 73/120\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9803 - mse: 0.9803 - val_loss: 0.5415 - val_mse: 0.5415\n",
      "Epoch 74/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9659 - mse: 0.9659 - val_loss: 0.4765 - val_mse: 0.4765\n",
      "Epoch 75/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9581 - mse: 0.9581 - val_loss: 0.4326 - val_mse: 0.4326\n",
      "Epoch 76/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9541 - mse: 0.9541 - val_loss: 0.4149 - val_mse: 0.4149\n",
      "Epoch 77/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9484 - mse: 0.9484 - val_loss: 0.4234 - val_mse: 0.4234\n",
      "Epoch 78/120\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9378 - mse: 0.9378 - val_loss: 0.4548 - val_mse: 0.4548\n",
      "Epoch 79/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9240 - mse: 0.9240 - val_loss: 0.5022 - val_mse: 0.5022\n",
      "Epoch 80/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9111 - mse: 0.9111 - val_loss: 0.5540 - val_mse: 0.5540\n",
      "Epoch 81/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9019 - mse: 0.9019 - val_loss: 0.5960 - val_mse: 0.5960\n",
      "Epoch 82/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8951 - mse: 0.8951 - val_loss: 0.6159 - val_mse: 0.6159\n",
      "Epoch 83/120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8873 - mse: 0.8873 - val_loss: 0.6093 - val_mse: 0.6093\n",
      "Epoch 84/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8767 - mse: 0.8767 - val_loss: 0.5811 - val_mse: 0.5811\n",
      "Epoch 85/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8642 - mse: 0.8642 - val_loss: 0.5429 - val_mse: 0.5429\n",
      "Epoch 86/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8524 - mse: 0.8524 - val_loss: 0.5071 - val_mse: 0.5071\n",
      "Epoch 87/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8428 - mse: 0.8428 - val_loss: 0.4831 - val_mse: 0.4831\n",
      "Epoch 88/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8343 - mse: 0.8343 - val_loss: 0.4754 - val_mse: 0.4754\n",
      "Epoch 89/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8251 - mse: 0.8251 - val_loss: 0.4844 - val_mse: 0.4844\n",
      "Epoch 90/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8142 - mse: 0.8142 - val_loss: 0.5069 - val_mse: 0.5069\n",
      "Epoch 91/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8025 - mse: 0.8025 - val_loss: 0.5369 - val_mse: 0.5369\n",
      "Epoch 92/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7915 - mse: 0.7915 - val_loss: 0.5659 - val_mse: 0.5659\n",
      "Epoch 93/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7817 - mse: 0.7817 - val_loss: 0.5857 - val_mse: 0.5857\n",
      "Epoch 94/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7724 - mse: 0.7724 - val_loss: 0.5909 - val_mse: 0.5909\n",
      "Epoch 95/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7624 - mse: 0.7624 - val_loss: 0.5817 - val_mse: 0.5817\n",
      "Epoch 96/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7516 - mse: 0.7516 - val_loss: 0.5631 - val_mse: 0.5631\n",
      "Epoch 97/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7406 - mse: 0.7406 - val_loss: 0.5425 - val_mse: 0.5425\n",
      "Epoch 98/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7303 - mse: 0.7303 - val_loss: 0.5268 - val_mse: 0.5268\n",
      "Epoch 99/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7207 - mse: 0.7207 - val_loss: 0.5205 - val_mse: 0.5205\n",
      "Epoch 100/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7111 - mse: 0.7111 - val_loss: 0.5247 - val_mse: 0.5247\n",
      "Epoch 101/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7011 - mse: 0.7011 - val_loss: 0.5380 - val_mse: 0.5380\n",
      "Epoch 102/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6908 - mse: 0.6908 - val_loss: 0.5564 - val_mse: 0.5564\n",
      "Epoch 103/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6808 - mse: 0.6808 - val_loss: 0.5746 - val_mse: 0.5746\n",
      "Epoch 104/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6713 - mse: 0.6713 - val_loss: 0.5873 - val_mse: 0.5873\n",
      "Epoch 105/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6622 - mse: 0.6622 - val_loss: 0.5915 - val_mse: 0.5915\n",
      "Epoch 106/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6530 - mse: 0.6530 - val_loss: 0.5872 - val_mse: 0.5872\n",
      "Epoch 107/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6436 - mse: 0.6436 - val_loss: 0.5776 - val_mse: 0.5776\n",
      "Epoch 108/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6344 - mse: 0.6344 - val_loss: 0.5672 - val_mse: 0.5672\n",
      "Epoch 109/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6257 - mse: 0.6257 - val_loss: 0.5604 - val_mse: 0.5604\n",
      "Epoch 110/120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6173 - mse: 0.6173 - val_loss: 0.5596 - val_mse: 0.5596\n",
      "Epoch 111/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6090 - mse: 0.6090 - val_loss: 0.5653 - val_mse: 0.5653\n",
      "Epoch 112/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6008 - mse: 0.6008 - val_loss: 0.5760 - val_mse: 0.5760\n",
      "Epoch 113/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5928 - mse: 0.5928 - val_loss: 0.5886 - val_mse: 0.5886\n",
      "Epoch 114/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5851 - mse: 0.5851 - val_loss: 0.5995 - val_mse: 0.5995\n",
      "Epoch 115/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5777 - mse: 0.5777 - val_loss: 0.6062 - val_mse: 0.6062\n",
      "Epoch 116/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5707 - mse: 0.5707 - val_loss: 0.6075 - val_mse: 0.6075\n",
      "Epoch 117/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5638 - mse: 0.5638 - val_loss: 0.6046 - val_mse: 0.6046\n",
      "Epoch 118/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5571 - mse: 0.5571 - val_loss: 0.6000 - val_mse: 0.6000\n",
      "Epoch 119/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5507 - mse: 0.5507 - val_loss: 0.5967 - val_mse: 0.5967\n",
      "Epoch 120/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5447 - mse: 0.5447 - val_loss: 0.5966 - val_mse: 0.5966\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "r2: 0.3569233799684979 meansquarederror: 0.14315957356267958 meanabsoluteerror: 0.3444483342737001 maxerror: 0.5123546928601157\n",
      "Epoch 1/120\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 1.5738 - mse: 1.5738 - val_loss: 53.7037 - val_mse: 53.7037\n",
      "Epoch 2/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 46.4230 - mse: 46.4230 - val_loss: 5.9643 - val_mse: 5.9643\n",
      "Epoch 3/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.6107 - mse: 4.6107 - val_loss: 7.2223 - val_mse: 7.2223\n",
      "Epoch 4/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 12.0416 - mse: 12.0416 - val_loss: 18.9226 - val_mse: 18.9226\n",
      "Epoch 5/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 25.7245 - mse: 25.7245 - val_loss: 11.2884 - val_mse: 11.2884\n",
      "Epoch 6/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 16.8808 - mse: 16.8808 - val_loss: 1.3510 - val_mse: 1.3510\n",
      "Epoch 7/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2636 - mse: 4.2636 - val_loss: 1.9485 - val_mse: 1.9485\n",
      "Epoch 8/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8683 - mse: 1.8683 - val_loss: 10.3112 - val_mse: 10.3112\n",
      "Epoch 9/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.9599 - mse: 7.9599 - val_loss: 15.6833 - val_mse: 15.6833\n",
      "Epoch 10/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 12.3863 - mse: 12.3863 - val_loss: 13.5210 - val_mse: 13.5210\n",
      "Epoch 11/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 10.5719 - mse: 10.5719 - val_loss: 7.0691 - val_mse: 7.0691\n",
      "Epoch 12/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.3901 - mse: 5.3901 - val_loss: 1.6513 - val_mse: 1.6513\n",
      "Epoch 13/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.6894 - mse: 1.6894 - val_loss: 0.1416 - val_mse: 0.1416\n",
      "Epoch 14/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8564 - mse: 1.8564 - val_loss: 1.5307 - val_mse: 1.5307\n",
      "Epoch 15/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4789 - mse: 4.4789 - val_loss: 2.9301 - val_mse: 2.9301\n",
      "Epoch 16/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.4483 - mse: 6.4483 - val_loss: 2.6451 - val_mse: 2.6451\n",
      "Epoch 17/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.0536 - mse: 6.0536 - val_loss: 1.1895 - val_mse: 1.1895\n",
      "Epoch 18/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9361 - mse: 3.9361 - val_loss: 0.1594 - val_mse: 0.1594\n",
      "Epoch 19/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8997 - mse: 1.8997 - val_loss: 0.6442 - val_mse: 0.6442\n",
      "Epoch 20/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2789 - mse: 1.2789 - val_loss: 2.4045 - val_mse: 2.4045\n",
      "Epoch 21/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0758 - mse: 2.0758 - val_loss: 4.2201 - val_mse: 4.2201\n",
      "Epoch 22/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2577 - mse: 3.2577 - val_loss: 4.9322 - val_mse: 4.9322\n",
      "Epoch 23/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.7585 - mse: 3.7585 - val_loss: 4.2299 - val_mse: 4.2299\n",
      "Epoch 24/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.2579 - mse: 3.2579 - val_loss: 2.6740 - val_mse: 2.6740\n",
      "Epoch 25/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.2246 - mse: 2.2246 - val_loss: 1.1582 - val_mse: 1.1582\n",
      "Epoch 26/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.4106 - mse: 1.4106 - val_loss: 0.2978 - val_mse: 0.2978\n",
      "Epoch 27/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2721 - mse: 1.2721 - val_loss: 0.1363 - val_mse: 0.1363\n",
      "Epoch 28/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.7088 - mse: 1.7088 - val_loss: 0.2955 - val_mse: 0.2955\n",
      "Epoch 29/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2395 - mse: 2.2395 - val_loss: 0.3751 - val_mse: 0.3751\n",
      "Epoch 30/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.4171 - mse: 2.4171 - val_loss: 0.2600 - val_mse: 0.2600\n",
      "Epoch 31/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.1364 - mse: 2.1364 - val_loss: 0.1333 - val_mse: 0.1333\n",
      "Epoch 32/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.6381 - mse: 1.6381 - val_loss: 0.2547 - val_mse: 0.2547\n",
      "Epoch 33/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2722 - mse: 1.2722 - val_loss: 0.7154 - val_mse: 0.7154\n",
      "Epoch 34/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2338 - mse: 1.2338 - val_loss: 1.3501 - val_mse: 1.3501\n",
      "Epoch 35/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4554 - mse: 1.4554 - val_loss: 1.8520 - val_mse: 1.8520\n",
      "Epoch 36/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7022 - mse: 1.7022 - val_loss: 1.9806 - val_mse: 1.9806\n",
      "Epoch 37/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.7683 - mse: 1.7683 - val_loss: 1.7049 - val_mse: 1.7049\n",
      "Epoch 38/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.6154 - mse: 1.6154 - val_loss: 1.1934 - val_mse: 1.1934\n",
      "Epoch 39/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3686 - mse: 1.3686 - val_loss: 0.6842 - val_mse: 0.6842\n",
      "Epoch 40/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1992 - mse: 1.1992 - val_loss: 0.3401 - val_mse: 0.3401\n",
      "Epoch 41/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.1948 - mse: 1.1948 - val_loss: 0.1852 - val_mse: 0.1852\n",
      "Epoch 42/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.3106 - mse: 1.3106 - val_loss: 0.1456 - val_mse: 0.1456\n",
      "Epoch 43/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4244 - mse: 1.4244 - val_loss: 0.1437 - val_mse: 0.1437\n",
      "Epoch 44/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.4379 - mse: 1.4379 - val_loss: 0.1646 - val_mse: 0.1646\n",
      "Epoch 45/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3444 - mse: 1.3444 - val_loss: 0.2486 - val_mse: 0.2486\n",
      "Epoch 46/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2180 - mse: 1.2180 - val_loss: 0.4318 - val_mse: 0.4318\n",
      "Epoch 47/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1451 - mse: 1.1451 - val_loss: 0.6911 - val_mse: 0.6911\n",
      "Epoch 48/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1580 - mse: 1.1580 - val_loss: 0.9407 - val_mse: 0.9407\n",
      "Epoch 49/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2204 - mse: 1.2204 - val_loss: 1.0811 - val_mse: 1.0811\n",
      "Epoch 50/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2652 - mse: 1.2652 - val_loss: 1.0599 - val_mse: 1.0599\n",
      "Epoch 51/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2512 - mse: 1.2512 - val_loss: 0.9002 - val_mse: 0.9002\n",
      "Epoch 52/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1892 - mse: 1.1892 - val_loss: 0.6787 - val_mse: 0.6787\n",
      "Epoch 53/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1255 - mse: 1.1255 - val_loss: 0.4764 - val_mse: 0.4764\n",
      "Epoch 54/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1005 - mse: 1.1005 - val_loss: 0.3386 - val_mse: 0.3386\n",
      "Epoch 55/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1177 - mse: 1.1177 - val_loss: 0.2689 - val_mse: 0.2689\n",
      "Epoch 56/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1473 - mse: 1.1473 - val_loss: 0.2514 - val_mse: 0.2514\n",
      "Epoch 57/120\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.1550 - mse: 1.1550 - val_loss: 0.2760 - val_mse: 0.2760\n",
      "Epoch 58/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1299 - mse: 1.1299 - val_loss: 0.3442 - val_mse: 0.3442\n",
      "Epoch 59/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0896 - mse: 1.0896 - val_loss: 0.4551 - val_mse: 0.4551\n",
      "Epoch 60/120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0611 - mse: 1.0611 - val_loss: 0.5892 - val_mse: 0.5892\n",
      "Epoch 61/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0575 - mse: 1.0575 - val_loss: 0.7071 - val_mse: 0.7071\n",
      "Epoch 62/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0692 - mse: 1.0692 - val_loss: 0.7682 - val_mse: 0.7682\n",
      "Epoch 63/120\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.0758 - mse: 1.0758 - val_loss: 0.7536 - val_mse: 0.7536\n",
      "Epoch 64/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0645 - mse: 1.0645 - val_loss: 0.6755 - val_mse: 0.6755\n",
      "Epoch 65/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0399 - mse: 1.0399 - val_loss: 0.5681 - val_mse: 0.5681\n",
      "Epoch 66/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0171 - mse: 1.0171 - val_loss: 0.4677 - val_mse: 0.4677\n",
      "Epoch 67/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0072 - mse: 1.0072 - val_loss: 0.3967 - val_mse: 0.3967\n",
      "Epoch 68/120\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0083 - mse: 1.0083 - val_loss: 0.3623 - val_mse: 0.3623\n",
      "Epoch 69/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0093 - mse: 1.0093 - val_loss: 0.3628 - val_mse: 0.3628\n",
      "Epoch 70/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0010 - mse: 1.0010 - val_loss: 0.3951 - val_mse: 0.3951\n",
      "Epoch 71/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9839 - mse: 0.9839 - val_loss: 0.4538 - val_mse: 0.4538\n",
      "Epoch 72/120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9664 - mse: 0.9664 - val_loss: 0.5270 - val_mse: 0.5270\n",
      "Epoch 73/120\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9555 - mse: 0.9555 - val_loss: 0.5949 - val_mse: 0.5949\n",
      "Epoch 74/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9514 - mse: 0.9514 - val_loss: 0.6365 - val_mse: 0.6365\n",
      "Epoch 75/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9477 - mse: 0.9477 - val_loss: 0.6391 - val_mse: 0.6391\n",
      "Epoch 76/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9389 - mse: 0.9389 - val_loss: 0.6055 - val_mse: 0.6055\n",
      "Epoch 77/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9249 - mse: 0.9249 - val_loss: 0.5510 - val_mse: 0.5510\n",
      "Epoch 78/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9105 - mse: 0.9105 - val_loss: 0.4952 - val_mse: 0.4952\n",
      "Epoch 79/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9001 - mse: 0.9001 - val_loss: 0.4532 - val_mse: 0.4532\n",
      "Epoch 80/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8934 - mse: 0.8934 - val_loss: 0.4327 - val_mse: 0.4327\n",
      "Epoch 81/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8866 - mse: 0.8866 - val_loss: 0.4354 - val_mse: 0.4354\n",
      "Epoch 82/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8765 - mse: 0.8765 - val_loss: 0.4588 - val_mse: 0.4588\n",
      "Epoch 83/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8638 - mse: 0.8638 - val_loss: 0.4969 - val_mse: 0.4969\n",
      "Epoch 84/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8513 - mse: 0.8513 - val_loss: 0.5394 - val_mse: 0.5394\n",
      "Epoch 85/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8413 - mse: 0.8413 - val_loss: 0.5739 - val_mse: 0.5739\n",
      "Epoch 86/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8331 - mse: 0.8331 - val_loss: 0.5897 - val_mse: 0.5897\n",
      "Epoch 87/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8243 - mse: 0.8243 - val_loss: 0.5833 - val_mse: 0.5833\n",
      "Epoch 88/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8134 - mse: 0.8134 - val_loss: 0.5594 - val_mse: 0.5594\n",
      "Epoch 89/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8014 - mse: 0.8014 - val_loss: 0.5280 - val_mse: 0.5280\n",
      "Epoch 90/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7901 - mse: 0.7901 - val_loss: 0.5002 - val_mse: 0.5002\n",
      "Epoch 91/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7804 - mse: 0.7804 - val_loss: 0.4835 - val_mse: 0.4835\n",
      "Epoch 92/120\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7713 - mse: 0.7713 - val_loss: 0.4814 - val_mse: 0.4814\n",
      "Epoch 93/120\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7614 - mse: 0.7614 - val_loss: 0.4933 - val_mse: 0.4933\n",
      "Epoch 94/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7504 - mse: 0.7504 - val_loss: 0.5153 - val_mse: 0.5153\n",
      "Epoch 95/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7392 - mse: 0.7392 - val_loss: 0.5409 - val_mse: 0.5409\n",
      "Epoch 96/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7289 - mse: 0.7289 - val_loss: 0.5622 - val_mse: 0.5622\n",
      "Epoch 97/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7195 - mse: 0.7195 - val_loss: 0.5729 - val_mse: 0.5729\n",
      "Epoch 98/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7099 - mse: 0.7099 - val_loss: 0.5706 - val_mse: 0.5706\n",
      "Epoch 99/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6998 - mse: 0.6998 - val_loss: 0.5579 - val_mse: 0.5579\n",
      "Epoch 100/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6894 - mse: 0.6894 - val_loss: 0.5410 - val_mse: 0.5410\n",
      "Epoch 101/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6793 - mse: 0.6793 - val_loss: 0.5264 - val_mse: 0.5264\n",
      "Epoch 102/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6700 - mse: 0.6700 - val_loss: 0.5191 - val_mse: 0.5191\n",
      "Epoch 103/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6609 - mse: 0.6609 - val_loss: 0.5210 - val_mse: 0.5210\n",
      "Epoch 104/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6517 - mse: 0.6517 - val_loss: 0.5313 - val_mse: 0.5313\n",
      "Epoch 105/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6422 - mse: 0.6422 - val_loss: 0.5466 - val_mse: 0.5466\n",
      "Epoch 106/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6330 - mse: 0.6330 - val_loss: 0.5623 - val_mse: 0.5623\n",
      "Epoch 107/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6243 - mse: 0.6243 - val_loss: 0.5736 - val_mse: 0.5736\n",
      "Epoch 108/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6159 - mse: 0.6159 - val_loss: 0.5775 - val_mse: 0.5775\n",
      "Epoch 109/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6077 - mse: 0.6077 - val_loss: 0.5742 - val_mse: 0.5742\n",
      "Epoch 110/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5994 - mse: 0.5994 - val_loss: 0.5664 - val_mse: 0.5664\n",
      "Epoch 111/120\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5913 - mse: 0.5913 - val_loss: 0.5584 - val_mse: 0.5584\n",
      "Epoch 112/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5836 - mse: 0.5836 - val_loss: 0.5538 - val_mse: 0.5538\n",
      "Epoch 113/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5764 - mse: 0.5764 - val_loss: 0.5547 - val_mse: 0.5547\n",
      "Epoch 114/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5693 - mse: 0.5693 - val_loss: 0.5611 - val_mse: 0.5611\n",
      "Epoch 115/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5623 - mse: 0.5623 - val_loss: 0.5713 - val_mse: 0.5713\n",
      "Epoch 116/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5556 - mse: 0.5556 - val_loss: 0.5822 - val_mse: 0.5822\n",
      "Epoch 117/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5493 - mse: 0.5493 - val_loss: 0.5907 - val_mse: 0.5907\n",
      "Epoch 118/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5434 - mse: 0.5434 - val_loss: 0.5950 - val_mse: 0.5950\n",
      "Epoch 119/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5376 - mse: 0.5376 - val_loss: 0.5949 - val_mse: 0.5949\n",
      "Epoch 120/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5321 - mse: 0.5321 - val_loss: 0.5920 - val_mse: 0.5920\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "r2: 0.36933152426015914 meansquarederror: 0.14039731384095092 meanabsoluteerror: 0.3428671305083642 maxerror: 0.5125770789397808\n",
      "Epoch 1/120\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 1.3994 - mse: 1.3994 - val_loss: 40.9755 - val_mse: 40.9755\n",
      "Epoch 2/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 50.3726 - mse: 50.3726 - val_loss: 1.6212 - val_mse: 1.6212\n",
      "Epoch 3/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.7249 - mse: 4.7249 - val_loss: 16.3602 - val_mse: 16.3602\n",
      "Epoch 4/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 13.0766 - mse: 13.0766 - val_loss: 33.7116 - val_mse: 33.7116\n",
      "Epoch 5/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 28.2433 - mse: 28.2433 - val_loss: 23.8543 - val_mse: 23.8543\n",
      "Epoch 6/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 19.4959 - mse: 19.4959 - val_loss: 7.2586 - val_mse: 7.2586\n",
      "Epoch 7/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.5947 - mse: 5.5947 - val_loss: 0.1370 - val_mse: 0.1370\n",
      "Epoch 8/120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.5364 - mse: 1.5364 - val_loss: 3.4730 - val_mse: 3.4730\n",
      "Epoch 9/120\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.2588 - mse: 7.2588 - val_loss: 7.9088 - val_mse: 7.9088\n",
      "Epoch 10/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 12.8233 - mse: 12.8233 - val_loss: 7.4146 - val_mse: 7.4146\n",
      "Epoch 11/120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 12.2136 - mse: 12.2136 - val_loss: 3.4350 - val_mse: 3.4350\n",
      "Epoch 12/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.1864 - mse: 7.1864 - val_loss: 0.3585 - val_mse: 0.3585\n",
      "Epoch 13/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.5180 - mse: 2.5180 - val_loss: 0.9705 - val_mse: 0.9705\n",
      "Epoch 14/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4095 - mse: 1.4095 - val_loss: 4.5196 - val_mse: 4.5196\n",
      "Epoch 15/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5131 - mse: 3.5131 - val_loss: 7.9576 - val_mse: 7.9576\n",
      "Epoch 16/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.0762 - mse: 6.0762 - val_loss: 8.8356 - val_mse: 8.8356\n",
      "Epoch 17/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6.7593 - mse: 6.7593 - val_loss: 6.9399 - val_mse: 6.9399\n",
      "Epoch 18/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.2831 - mse: 5.2831 - val_loss: 3.7919 - val_mse: 3.7919\n",
      "Epoch 19/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.9911 - mse: 2.9911 - val_loss: 1.2141 - val_mse: 1.2141\n",
      "Epoch 20/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4765 - mse: 1.4765 - val_loss: 0.1557 - val_mse: 0.1557\n",
      "Epoch 21/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4553 - mse: 1.4553 - val_loss: 0.3652 - val_mse: 0.3652\n",
      "Epoch 22/120\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.4817 - mse: 2.4817 - val_loss: 0.9208 - val_mse: 0.9208\n",
      "Epoch 23/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.5106 - mse: 3.5106 - val_loss: 1.0667 - val_mse: 1.0667\n",
      "Epoch 24/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.7447 - mse: 3.7447 - val_loss: 0.6905 - val_mse: 0.6905\n",
      "Epoch 25/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.1032 - mse: 3.1032 - val_loss: 0.2211 - val_mse: 0.2211\n",
      "Epoch 26/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.1016 - mse: 2.1016 - val_loss: 0.1844 - val_mse: 0.1844\n",
      "Epoch 27/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3863 - mse: 1.3863 - val_loss: 0.7847 - val_mse: 0.7847\n",
      "Epoch 28/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2962 - mse: 1.2962 - val_loss: 1.7729 - val_mse: 1.7729\n",
      "Epoch 29/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7064 - mse: 1.7064 - val_loss: 2.6398 - val_mse: 2.6398\n",
      "Epoch 30/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.2002 - mse: 2.2002 - val_loss: 2.9583 - val_mse: 2.9583\n",
      "Epoch 31/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.3956 - mse: 2.3956 - val_loss: 2.6232 - val_mse: 2.6232\n",
      "Epoch 32/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.1823 - mse: 2.1823 - val_loss: 1.8584 - val_mse: 1.8584\n",
      "Epoch 33/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.7358 - mse: 1.7358 - val_loss: 1.0349 - val_mse: 1.0349\n",
      "Epoch 34/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3497 - mse: 1.3497 - val_loss: 0.4459 - val_mse: 0.4459\n",
      "Epoch 35/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2271 - mse: 1.2271 - val_loss: 0.1774 - val_mse: 0.1774\n",
      "Epoch 36/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3682 - mse: 1.3682 - val_loss: 0.1302 - val_mse: 0.1302\n",
      "Epoch 37/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.6064 - mse: 1.6064 - val_loss: 0.1469 - val_mse: 0.1469\n",
      "Epoch 38/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.7457 - mse: 1.7457 - val_loss: 0.1399 - val_mse: 0.1399\n",
      "Epoch 39/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6921 - mse: 1.6921 - val_loss: 0.1356 - val_mse: 0.1356\n",
      "Epoch 40/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.4953 - mse: 1.4953 - val_loss: 0.2224 - val_mse: 0.2224\n",
      "Epoch 41/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2906 - mse: 1.2906 - val_loss: 0.4577 - val_mse: 0.4577\n",
      "Epoch 42/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1957 - mse: 1.1957 - val_loss: 0.8058 - val_mse: 0.8058\n",
      "Epoch 43/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2369 - mse: 1.2369 - val_loss: 1.1470 - val_mse: 1.1470\n",
      "Epoch 44/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.3478 - mse: 1.3478 - val_loss: 1.3471 - val_mse: 1.3471\n",
      "Epoch 45/120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4283 - mse: 1.4283 - val_loss: 1.3339 - val_mse: 1.3339\n",
      "Epoch 46/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4174 - mse: 1.4174 - val_loss: 1.1315 - val_mse: 1.1315\n",
      "Epoch 47/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3267 - mse: 1.3267 - val_loss: 0.8357 - val_mse: 0.8357\n",
      "Epoch 48/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2201 - mse: 1.2201 - val_loss: 0.5543 - val_mse: 0.5543\n",
      "Epoch 49/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1620 - mse: 1.1620 - val_loss: 0.3543 - val_mse: 0.3543\n",
      "Epoch 50/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1734 - mse: 1.1734 - val_loss: 0.2462 - val_mse: 0.2462\n",
      "Epoch 51/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2245 - mse: 1.2245 - val_loss: 0.2051 - val_mse: 0.2051\n",
      "Epoch 52/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.2638 - mse: 1.2638 - val_loss: 0.2065 - val_mse: 0.2065\n",
      "Epoch 53/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2573 - mse: 1.2573 - val_loss: 0.2466 - val_mse: 0.2466\n",
      "Epoch 54/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2091 - mse: 1.2091 - val_loss: 0.3355 - val_mse: 0.3355\n",
      "Epoch 55/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1525 - mse: 1.1525 - val_loss: 0.4749 - val_mse: 0.4749\n",
      "Epoch 56/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1214 - mse: 1.1214 - val_loss: 0.6402 - val_mse: 0.6402\n",
      "Epoch 57/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1259 - mse: 1.1259 - val_loss: 0.7845 - val_mse: 0.7845\n",
      "Epoch 58/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1491 - mse: 1.1491 - val_loss: 0.8609 - val_mse: 0.8609\n",
      "Epoch 59/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1636 - mse: 1.1636 - val_loss: 0.8471 - val_mse: 0.8471\n",
      "Epoch 60/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1531 - mse: 1.1531 - val_loss: 0.7559 - val_mse: 0.7559\n",
      "Epoch 61/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1227 - mse: 1.1227 - val_loss: 0.6255 - val_mse: 0.6255\n",
      "Epoch 62/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0915 - mse: 1.0915 - val_loss: 0.4980 - val_mse: 0.4980\n",
      "Epoch 63/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0761 - mse: 1.0761 - val_loss: 0.4016 - val_mse: 0.4016\n",
      "Epoch 64/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0785 - mse: 1.0785 - val_loss: 0.3457 - val_mse: 0.3457\n",
      "Epoch 65/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0870 - mse: 1.0870 - val_loss: 0.3283 - val_mse: 0.3283\n",
      "Epoch 66/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0870 - mse: 1.0870 - val_loss: 0.3454 - val_mse: 0.3454\n",
      "Epoch 67/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0733 - mse: 1.0733 - val_loss: 0.3939 - val_mse: 0.3939\n",
      "Epoch 68/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.0520 - mse: 1.0520 - val_loss: 0.4683 - val_mse: 0.4683\n",
      "Epoch 69/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0342 - mse: 1.0342 - val_loss: 0.5546 - val_mse: 0.5546\n",
      "Epoch 70/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0264 - mse: 1.0264 - val_loss: 0.6311 - val_mse: 0.6311\n",
      "Epoch 71/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0261 - mse: 1.0261 - val_loss: 0.6758 - val_mse: 0.6758\n",
      "Epoch 72/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0250 - mse: 1.0250 - val_loss: 0.6769 - val_mse: 0.6769\n",
      "Epoch 73/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0171 - mse: 1.0171 - val_loss: 0.6380 - val_mse: 0.6380\n",
      "Epoch 74/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0026 - mse: 1.0026 - val_loss: 0.5754 - val_mse: 0.5754\n",
      "Epoch 75/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9873 - mse: 0.9873 - val_loss: 0.5094 - val_mse: 0.5094\n",
      "Epoch 76/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9765 - mse: 0.9765 - val_loss: 0.4566 - val_mse: 0.4566\n",
      "Epoch 77/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9709 - mse: 0.9709 - val_loss: 0.4257 - val_mse: 0.4257\n",
      "Epoch 78/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9665 - mse: 0.9665 - val_loss: 0.4192 - val_mse: 0.4192\n",
      "Epoch 79/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9591 - mse: 0.9591 - val_loss: 0.4356 - val_mse: 0.4356\n",
      "Epoch 80/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9476 - mse: 0.9476 - val_loss: 0.4710 - val_mse: 0.4710\n",
      "Epoch 81/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9345 - mse: 0.9345 - val_loss: 0.5176 - val_mse: 0.5176\n",
      "Epoch 82/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9233 - mse: 0.9233 - val_loss: 0.5641 - val_mse: 0.5641\n",
      "Epoch 83/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9151 - mse: 0.9151 - val_loss: 0.5980 - val_mse: 0.5980\n",
      "Epoch 84/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9082 - mse: 0.9082 - val_loss: 0.6103 - val_mse: 0.6103\n",
      "Epoch 85/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8999 - mse: 0.8999 - val_loss: 0.5993 - val_mse: 0.5993\n",
      "Epoch 86/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8891 - mse: 0.8891 - val_loss: 0.5708 - val_mse: 0.5708\n",
      "Epoch 87/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8772 - mse: 0.8772 - val_loss: 0.5356 - val_mse: 0.5356\n",
      "Epoch 88/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8662 - mse: 0.8662 - val_loss: 0.5041 - val_mse: 0.5041\n",
      "Epoch 89/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8570 - mse: 0.8570 - val_loss: 0.4839 - val_mse: 0.4839\n",
      "Epoch 90/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8485 - mse: 0.8485 - val_loss: 0.4785 - val_mse: 0.4785\n",
      "Epoch 91/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8392 - mse: 0.8392 - val_loss: 0.4880 - val_mse: 0.4880\n",
      "Epoch 92/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8285 - mse: 0.8285 - val_loss: 0.5093 - val_mse: 0.5093\n",
      "Epoch 93/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8172 - mse: 0.8172 - val_loss: 0.5369 - val_mse: 0.5369\n",
      "Epoch 94/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8065 - mse: 0.8065 - val_loss: 0.5634 - val_mse: 0.5634\n",
      "Epoch 95/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7968 - mse: 0.7968 - val_loss: 0.5816 - val_mse: 0.5816\n",
      "Epoch 96/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7875 - mse: 0.7875 - val_loss: 0.5870 - val_mse: 0.5870\n",
      "Epoch 97/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7776 - mse: 0.7776 - val_loss: 0.5796 - val_mse: 0.5796\n",
      "Epoch 98/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7669 - mse: 0.7669 - val_loss: 0.5634 - val_mse: 0.5634\n",
      "Epoch 99/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7561 - mse: 0.7561 - val_loss: 0.5447 - val_mse: 0.5447\n",
      "Epoch 100/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7459 - mse: 0.7459 - val_loss: 0.5297 - val_mse: 0.5297\n",
      "Epoch 101/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7362 - mse: 0.7362 - val_loss: 0.5226 - val_mse: 0.5226\n",
      "Epoch 102/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7266 - mse: 0.7266 - val_loss: 0.5249 - val_mse: 0.5249\n",
      "Epoch 103/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7166 - mse: 0.7166 - val_loss: 0.5357 - val_mse: 0.5357\n",
      "Epoch 104/120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7064 - mse: 0.7064 - val_loss: 0.5519 - val_mse: 0.5519\n",
      "Epoch 105/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6963 - mse: 0.6963 - val_loss: 0.5689 - val_mse: 0.5689\n",
      "Epoch 106/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6867 - mse: 0.6867 - val_loss: 0.5822 - val_mse: 0.5822\n",
      "Epoch 107/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6774 - mse: 0.6774 - val_loss: 0.5885 - val_mse: 0.5885\n",
      "Epoch 108/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6681 - mse: 0.6681 - val_loss: 0.5871 - val_mse: 0.5871\n",
      "Epoch 109/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6587 - mse: 0.6587 - val_loss: 0.5799 - val_mse: 0.5799\n",
      "Epoch 110/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6493 - mse: 0.6493 - val_loss: 0.5706 - val_mse: 0.5706\n",
      "Epoch 111/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6403 - mse: 0.6403 - val_loss: 0.5630 - val_mse: 0.5630\n",
      "Epoch 112/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6316 - mse: 0.6316 - val_loss: 0.5601 - val_mse: 0.5601\n",
      "Epoch 113/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6231 - mse: 0.6231 - val_loss: 0.5630 - val_mse: 0.5630\n",
      "Epoch 114/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6147 - mse: 0.6147 - val_loss: 0.5711 - val_mse: 0.5711\n",
      "Epoch 115/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6064 - mse: 0.6064 - val_loss: 0.5822 - val_mse: 0.5822\n",
      "Epoch 116/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5983 - mse: 0.5983 - val_loss: 0.5933 - val_mse: 0.5933\n",
      "Epoch 117/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5906 - mse: 0.5906 - val_loss: 0.6017 - val_mse: 0.6017\n",
      "Epoch 118/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5832 - mse: 0.5832 - val_loss: 0.6056 - val_mse: 0.6056\n",
      "Epoch 119/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5760 - mse: 0.5760 - val_loss: 0.6052 - val_mse: 0.6052\n",
      "Epoch 120/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5689 - mse: 0.5689 - val_loss: 0.6019 - val_mse: 0.6019\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "r2: 0.35067641532431393 meansquarederror: 0.14455025200855232 meanabsoluteerror: 0.3517386647605742 maxerror: 0.5069971411057326\n",
      "Epoch 1/120\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 1.5209 - mse: 1.5209 - val_loss: 53.6185 - val_mse: 53.6185\n",
      "Epoch 2/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 46.3709 - mse: 46.3709 - val_loss: 5.8630 - val_mse: 5.8630\n",
      "Epoch 3/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5308 - mse: 4.5308 - val_loss: 7.0719 - val_mse: 7.0719\n",
      "Epoch 4/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 11.9431 - mse: 11.9431 - val_loss: 18.8283 - val_mse: 18.8283\n",
      "Epoch 5/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 25.7558 - mse: 25.7558 - val_loss: 11.6853 - val_mse: 11.6853\n",
      "Epoch 6/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 17.4544 - mse: 17.4544 - val_loss: 1.6503 - val_mse: 1.6503\n",
      "Epoch 7/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.7642 - mse: 4.7642 - val_loss: 1.5533 - val_mse: 1.5533\n",
      "Epoch 8/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.6661 - mse: 1.6661 - val_loss: 9.6027 - val_mse: 9.6027\n",
      "Epoch 9/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.3848 - mse: 7.3848 - val_loss: 15.4430 - val_mse: 15.4430\n",
      "Epoch 10/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 12.1780 - mse: 12.1780 - val_loss: 13.9482 - val_mse: 13.9482\n",
      "Epoch 11/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 10.9191 - mse: 10.9191 - val_loss: 7.7924 - val_mse: 7.7924\n",
      "Epoch 12/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.9392 - mse: 5.9392 - val_loss: 2.1393 - val_mse: 2.1393\n",
      "Epoch 13/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.9523 - mse: 1.9523 - val_loss: 0.1185 - val_mse: 0.1185\n",
      "Epoch 14/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.6187 - mse: 1.6187 - val_loss: 1.1835 - val_mse: 1.1835\n",
      "Epoch 15/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.9874 - mse: 3.9874 - val_loss: 2.6800 - val_mse: 2.6800\n",
      "Epoch 16/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.1626 - mse: 6.1626 - val_loss: 2.7208 - val_mse: 2.7208\n",
      "Epoch 17/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.2116 - mse: 6.2116 - val_loss: 1.4516 - val_mse: 1.4516\n",
      "Epoch 18/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3839 - mse: 4.3839 - val_loss: 0.2680 - val_mse: 0.2680\n",
      "Epoch 19/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.2638 - mse: 2.2638 - val_loss: 0.3717 - val_mse: 0.3717\n",
      "Epoch 20/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2835 - mse: 1.2835 - val_loss: 1.8397 - val_mse: 1.8397\n",
      "Epoch 21/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.7537 - mse: 1.7537 - val_loss: 3.6975 - val_mse: 3.6975\n",
      "Epoch 22/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.8919 - mse: 2.8919 - val_loss: 4.7653 - val_mse: 4.7653\n",
      "Epoch 23/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.6295 - mse: 3.6295 - val_loss: 4.4942 - val_mse: 4.4942\n",
      "Epoch 24/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4339 - mse: 3.4339 - val_loss: 3.1892 - val_mse: 3.1892\n",
      "Epoch 25/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.5447 - mse: 2.5447 - val_loss: 1.6382 - val_mse: 1.6382\n",
      "Epoch 26/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6293 - mse: 1.6293 - val_loss: 0.5427 - val_mse: 0.5427\n",
      "Epoch 27/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2434 - mse: 1.2434 - val_loss: 0.1391 - val_mse: 0.1391\n",
      "Epoch 28/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4807 - mse: 1.4807 - val_loss: 0.1989 - val_mse: 0.1989\n",
      "Epoch 29/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.9997 - mse: 1.9997 - val_loss: 0.3285 - val_mse: 0.3285\n",
      "Epoch 30/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.3407 - mse: 2.3407 - val_loss: 0.2981 - val_mse: 0.2981\n",
      "Epoch 31/120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.2611 - mse: 2.2611 - val_loss: 0.1647 - val_mse: 0.1647\n",
      "Epoch 32/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.8536 - mse: 1.8536 - val_loss: 0.1545 - val_mse: 0.1545\n",
      "Epoch 33/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4163 - mse: 1.4163 - val_loss: 0.4398 - val_mse: 0.4398\n",
      "Epoch 34/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2142 - mse: 1.2142 - val_loss: 0.9857 - val_mse: 0.9857\n",
      "Epoch 35/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3080 - mse: 1.3080 - val_loss: 1.5640 - val_mse: 1.5640\n",
      "Epoch 36/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5501 - mse: 1.5501 - val_loss: 1.9049 - val_mse: 1.9049\n",
      "Epoch 37/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7223 - mse: 1.7223 - val_loss: 1.8656 - val_mse: 1.8656\n",
      "Epoch 38/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.6966 - mse: 1.6966 - val_loss: 1.4992 - val_mse: 1.4992\n",
      "Epoch 39/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5048 - mse: 1.5048 - val_loss: 0.9961 - val_mse: 0.9961\n",
      "Epoch 40/120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2879 - mse: 1.2879 - val_loss: 0.5569 - val_mse: 0.5569\n",
      "Epoch 41/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1805 - mse: 1.1805 - val_loss: 0.2868 - val_mse: 0.2868\n",
      "Epoch 42/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2196 - mse: 1.2196 - val_loss: 0.1743 - val_mse: 0.1743\n",
      "Epoch 43/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3355 - mse: 1.3355 - val_loss: 0.1470 - val_mse: 0.1470\n",
      "Epoch 44/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4186 - mse: 1.4186 - val_loss: 0.1500 - val_mse: 0.1500\n",
      "Epoch 45/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4023 - mse: 1.4023 - val_loss: 0.1849 - val_mse: 0.1849\n",
      "Epoch 46/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3029 - mse: 1.3029 - val_loss: 0.2892 - val_mse: 0.2892\n",
      "Epoch 47/120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.1931 - mse: 1.1931 - val_loss: 0.4832 - val_mse: 0.4832\n",
      "Epoch 48/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1414 - mse: 1.1414 - val_loss: 0.7323 - val_mse: 0.7323\n",
      "Epoch 49/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.1635 - mse: 1.1635 - val_loss: 0.9543 - val_mse: 0.9543\n",
      "Epoch 50/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.2198 - mse: 1.2198 - val_loss: 1.0654 - val_mse: 1.0654\n",
      "Epoch 51/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2533 - mse: 1.2533 - val_loss: 1.0288 - val_mse: 1.0288\n",
      "Epoch 52/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2337 - mse: 1.2337 - val_loss: 0.8721 - val_mse: 0.8721\n",
      "Epoch 53/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1756 - mse: 1.1756 - val_loss: 0.6652 - val_mse: 0.6652\n",
      "Epoch 54/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1199 - mse: 1.1199 - val_loss: 0.4781 - val_mse: 0.4781\n",
      "Epoch 55/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0991 - mse: 1.0991 - val_loss: 0.3494 - val_mse: 0.3494\n",
      "Epoch 56/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1144 - mse: 1.1144 - val_loss: 0.2827 - val_mse: 0.2827\n",
      "Epoch 57/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1395 - mse: 1.1395 - val_loss: 0.2654 - val_mse: 0.2654\n",
      "Epoch 58/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1454 - mse: 1.1454 - val_loss: 0.2888 - val_mse: 0.2888\n",
      "Epoch 59/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1229 - mse: 1.1229 - val_loss: 0.3532 - val_mse: 0.3532\n",
      "Epoch 60/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0865 - mse: 1.0865 - val_loss: 0.4565 - val_mse: 0.4565\n",
      "Epoch 61/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0594 - mse: 1.0594 - val_loss: 0.5814 - val_mse: 0.5814\n",
      "Epoch 62/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0536 - mse: 1.0536 - val_loss: 0.6937 - val_mse: 0.6937\n",
      "Epoch 63/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0622 - mse: 1.0622 - val_loss: 0.7574 - val_mse: 0.7574\n",
      "Epoch 64/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0682 - mse: 1.0682 - val_loss: 0.7532 - val_mse: 0.7532\n",
      "Epoch 65/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0594 - mse: 1.0594 - val_loss: 0.6886 - val_mse: 0.6886\n",
      "Epoch 66/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0379 - mse: 1.0379 - val_loss: 0.5917 - val_mse: 0.5917\n",
      "Epoch 67/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.4951 - val_mse: 0.4951\n",
      "Epoch 68/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0036 - mse: 1.0036 - val_loss: 0.4220 - val_mse: 0.4220\n",
      "Epoch 69/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0020 - mse: 1.0020 - val_loss: 0.3817 - val_mse: 0.3817\n",
      "Epoch 70/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0025 - mse: 1.0025 - val_loss: 0.3744 - val_mse: 0.3744\n",
      "Epoch 71/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9963 - mse: 0.9963 - val_loss: 0.3976 - val_mse: 0.3976\n",
      "Epoch 72/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9817 - mse: 0.9817 - val_loss: 0.4467 - val_mse: 0.4467\n",
      "Epoch 73/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9646 - mse: 0.9646 - val_loss: 0.5126 - val_mse: 0.5126\n",
      "Epoch 74/120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9519 - mse: 0.9519 - val_loss: 0.5790 - val_mse: 0.5790\n",
      "Epoch 75/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9456 - mse: 0.9456 - val_loss: 0.6270 - val_mse: 0.6270\n",
      "Epoch 76/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9415 - mse: 0.9415 - val_loss: 0.6423 - val_mse: 0.6423\n",
      "Epoch 77/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9343 - mse: 0.9343 - val_loss: 0.6227 - val_mse: 0.6227\n",
      "Epoch 78/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9222 - mse: 0.9222 - val_loss: 0.5781 - val_mse: 0.5781\n",
      "Epoch 79/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9080 - mse: 0.9080 - val_loss: 0.5254 - val_mse: 0.5254\n",
      "Epoch 80/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8961 - mse: 0.8961 - val_loss: 0.4801 - val_mse: 0.4801\n",
      "Epoch 81/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8878 - mse: 0.8878 - val_loss: 0.4520 - val_mse: 0.4520\n",
      "Epoch 82/120\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8809 - mse: 0.8809 - val_loss: 0.4449 - val_mse: 0.4449\n",
      "Epoch 83/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8722 - mse: 0.8722 - val_loss: 0.4581 - val_mse: 0.4581\n",
      "Epoch 84/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8606 - mse: 0.8606 - val_loss: 0.4878 - val_mse: 0.4878\n",
      "Epoch 85/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8480 - mse: 0.8480 - val_loss: 0.5263 - val_mse: 0.5263\n",
      "Epoch 86/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8368 - mse: 0.8368 - val_loss: 0.5632 - val_mse: 0.5632\n",
      "Epoch 87/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8276 - mse: 0.8276 - val_loss: 0.5876 - val_mse: 0.5876\n",
      "Epoch 88/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8190 - mse: 0.8190 - val_loss: 0.5930 - val_mse: 0.5930\n",
      "Epoch 89/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8092 - mse: 0.8092 - val_loss: 0.5795 - val_mse: 0.5795\n",
      "Epoch 90/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7978 - mse: 0.7978 - val_loss: 0.5538 - val_mse: 0.5538\n",
      "Epoch 91/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7861 - mse: 0.7861 - val_loss: 0.5255 - val_mse: 0.5255\n",
      "Epoch 92/120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7755 - mse: 0.7755 - val_loss: 0.5035 - val_mse: 0.5035\n",
      "Epoch 93/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7660 - mse: 0.7660 - val_loss: 0.4931 - val_mse: 0.4931\n",
      "Epoch 94/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7566 - mse: 0.7566 - val_loss: 0.4960 - val_mse: 0.4960\n",
      "Epoch 95/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7463 - mse: 0.7463 - val_loss: 0.5106 - val_mse: 0.5106\n",
      "Epoch 96/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7352 - mse: 0.7352 - val_loss: 0.5326 - val_mse: 0.5326\n",
      "Epoch 97/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7245 - mse: 0.7245 - val_loss: 0.5555 - val_mse: 0.5555\n",
      "Epoch 98/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7145 - mse: 0.7145 - val_loss: 0.5725 - val_mse: 0.5725\n",
      "Epoch 99/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7051 - mse: 0.7051 - val_loss: 0.5791 - val_mse: 0.5791\n",
      "Epoch 100/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6955 - mse: 0.6955 - val_loss: 0.5744 - val_mse: 0.5744\n",
      "Epoch 101/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6853 - mse: 0.6853 - val_loss: 0.5616 - val_mse: 0.5616\n",
      "Epoch 102/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6752 - mse: 0.6752 - val_loss: 0.5466 - val_mse: 0.5466\n",
      "Epoch 103/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6655 - mse: 0.6655 - val_loss: 0.5347 - val_mse: 0.5347\n",
      "Epoch 104/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6563 - mse: 0.6563 - val_loss: 0.5298 - val_mse: 0.5298\n",
      "Epoch 105/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6473 - mse: 0.6473 - val_loss: 0.5332 - val_mse: 0.5332\n",
      "Epoch 106/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6382 - mse: 0.6382 - val_loss: 0.5437 - val_mse: 0.5437\n",
      "Epoch 107/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6290 - mse: 0.6290 - val_loss: 0.5580 - val_mse: 0.5580\n",
      "Epoch 108/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6201 - mse: 0.6201 - val_loss: 0.5720 - val_mse: 0.5720\n",
      "Epoch 109/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6117 - mse: 0.6117 - val_loss: 0.5815 - val_mse: 0.5815\n",
      "Epoch 110/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6036 - mse: 0.6036 - val_loss: 0.5845 - val_mse: 0.5845\n",
      "Epoch 111/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5956 - mse: 0.5956 - val_loss: 0.5813 - val_mse: 0.5813\n",
      "Epoch 112/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5876 - mse: 0.5876 - val_loss: 0.5745 - val_mse: 0.5745\n",
      "Epoch 113/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5799 - mse: 0.5799 - val_loss: 0.5677 - val_mse: 0.5677\n",
      "Epoch 114/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5726 - mse: 0.5726 - val_loss: 0.5640 - val_mse: 0.5640\n",
      "Epoch 115/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5657 - mse: 0.5657 - val_loss: 0.5653 - val_mse: 0.5653\n",
      "Epoch 116/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5589 - mse: 0.5589 - val_loss: 0.5714 - val_mse: 0.5714\n",
      "Epoch 117/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5524 - mse: 0.5524 - val_loss: 0.5807 - val_mse: 0.5807\n",
      "Epoch 118/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5460 - mse: 0.5460 - val_loss: 0.5906 - val_mse: 0.5906\n",
      "Epoch 119/120\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5401 - mse: 0.5401 - val_loss: 0.5986 - val_mse: 0.5986\n",
      "Epoch 120/120\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5345 - mse: 0.5345 - val_loss: 0.6029 - val_mse: 0.6029\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "r2: 0.38387026205194164 meansquarederror: 0.1371607484962036 meanabsoluteerror: 0.34057780132725407 maxerror: 0.5035399126651932\n",
      "Epoch 1/120\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 1.8159 - mse: 1.8159 - val_loss: 34.2396 - val_mse: 34.2396\n",
      "Epoch 2/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 42.9440 - mse: 42.9440 - val_loss: 1.5262 - val_mse: 1.5262\n",
      "Epoch 3/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5553 - mse: 4.5553 - val_loss: 13.9314 - val_mse: 13.9314\n",
      "Epoch 4/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 11.0534 - mse: 11.0534 - val_loss: 28.4282 - val_mse: 28.4282\n",
      "Epoch 5/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 23.5982 - mse: 23.5982 - val_loss: 18.5766 - val_mse: 18.5766\n",
      "Epoch 6/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 14.9649 - mse: 14.9649 - val_loss: 4.3996 - val_mse: 4.3996\n",
      "Epoch 7/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4762 - mse: 3.4762 - val_loss: 0.2210 - val_mse: 0.2210\n",
      "Epoch 8/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.1854 - mse: 2.1854 - val_loss: 4.2676 - val_mse: 4.2676\n",
      "Epoch 9/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.2613 - mse: 8.2613 - val_loss: 7.0653 - val_mse: 7.0653\n",
      "Epoch 10/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 11.7569 - mse: 11.7569 - val_loss: 5.0478 - val_mse: 5.0478\n",
      "Epoch 11/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 9.2395 - mse: 9.2395 - val_loss: 1.3489 - val_mse: 1.3489\n",
      "Epoch 12/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.2192 - mse: 4.2192 - val_loss: 0.2119 - val_mse: 0.2119\n",
      "Epoch 13/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3796 - mse: 1.3796 - val_loss: 2.8169 - val_mse: 2.8169\n",
      "Epoch 14/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.3705 - mse: 2.3705 - val_loss: 6.6211 - val_mse: 6.6211\n",
      "Epoch 15/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.0632 - mse: 5.0632 - val_loss: 8.3008 - val_mse: 8.3008\n",
      "Epoch 16/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6.3567 - mse: 6.3567 - val_loss: 6.8388 - val_mse: 6.8388\n",
      "Epoch 17/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.2186 - mse: 5.2186 - val_loss: 3.7091 - val_mse: 3.7091\n",
      "Epoch 18/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.9363 - mse: 2.9363 - val_loss: 1.0856 - val_mse: 1.0856\n",
      "Epoch 19/120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4134 - mse: 1.4134 - val_loss: 0.1280 - val_mse: 0.1280\n",
      "Epoch 20/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5262 - mse: 1.5262 - val_loss: 0.4743 - val_mse: 0.4743\n",
      "Epoch 21/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.6787 - mse: 2.6787 - val_loss: 1.0040 - val_mse: 1.0040\n",
      "Epoch 22/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.6115 - mse: 3.6115 - val_loss: 0.9631 - val_mse: 0.9631\n",
      "Epoch 23/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.5386 - mse: 3.5386 - val_loss: 0.4557 - val_mse: 0.4557\n",
      "Epoch 24/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.6228 - mse: 2.6228 - val_loss: 0.1244 - val_mse: 0.1244\n",
      "Epoch 25/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.6295 - mse: 1.6295 - val_loss: 0.4885 - val_mse: 0.4885\n",
      "Epoch 26/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2377 - mse: 1.2377 - val_loss: 1.4882 - val_mse: 1.4882\n",
      "Epoch 27/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.5538 - mse: 1.5538 - val_loss: 2.5427 - val_mse: 2.5427\n",
      "Epoch 28/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.1359 - mse: 2.1359 - val_loss: 3.0186 - val_mse: 3.0186\n",
      "Epoch 29/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.4303 - mse: 2.4303 - val_loss: 2.6871 - val_mse: 2.6871\n",
      "Epoch 30/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.2159 - mse: 2.2159 - val_loss: 1.8166 - val_mse: 1.8166\n",
      "Epoch 31/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.7032 - mse: 1.7032 - val_loss: 0.9073 - val_mse: 0.9073\n",
      "Epoch 32/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2902 - mse: 1.2902 - val_loss: 0.3296 - val_mse: 0.3296\n",
      "Epoch 33/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2278 - mse: 1.2278 - val_loss: 0.1379 - val_mse: 0.1379\n",
      "Epoch 34/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4599 - mse: 1.4599 - val_loss: 0.1482 - val_mse: 0.1482\n",
      "Epoch 35/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7232 - mse: 1.7232 - val_loss: 0.1625 - val_mse: 0.1625\n",
      "Epoch 36/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7836 - mse: 1.7836 - val_loss: 0.1355 - val_mse: 0.1355\n",
      "Epoch 37/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.6055 - mse: 1.6055 - val_loss: 0.1712 - val_mse: 0.1712\n",
      "Epoch 38/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3413 - mse: 1.3413 - val_loss: 0.3875 - val_mse: 0.3875\n",
      "Epoch 39/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.1836 - mse: 1.1836 - val_loss: 0.7797 - val_mse: 0.7797\n",
      "Epoch 40/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2123 - mse: 1.2123 - val_loss: 1.1961 - val_mse: 1.1961\n",
      "Epoch 41/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3518 - mse: 1.3518 - val_loss: 1.4382 - val_mse: 1.4382\n",
      "Epoch 42/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.4551 - mse: 1.4551 - val_loss: 1.3973 - val_mse: 1.3973\n",
      "Epoch 43/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4301 - mse: 1.4301 - val_loss: 1.1186 - val_mse: 1.1186\n",
      "Epoch 44/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3030 - mse: 1.3030 - val_loss: 0.7525 - val_mse: 0.7525\n",
      "Epoch 45/120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.1769 - mse: 1.1769 - val_loss: 0.4471 - val_mse: 0.4471\n",
      "Epoch 46/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1371 - mse: 1.1371 - val_loss: 0.2677 - val_mse: 0.2677\n",
      "Epoch 47/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1860 - mse: 1.1860 - val_loss: 0.1949 - val_mse: 0.1949\n",
      "Epoch 48/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2556 - mse: 1.2556 - val_loss: 0.1822 - val_mse: 0.1822\n",
      "Epoch 49/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2738 - mse: 1.2738 - val_loss: 0.2105 - val_mse: 0.2105\n",
      "Epoch 50/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2229 - mse: 1.2229 - val_loss: 0.2963 - val_mse: 0.2963\n",
      "Epoch 51/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1453 - mse: 1.1453 - val_loss: 0.4540 - val_mse: 0.4540\n",
      "Epoch 52/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0985 - mse: 1.0985 - val_loss: 0.6574 - val_mse: 0.6574\n",
      "Epoch 53/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1053 - mse: 1.1053 - val_loss: 0.8373 - val_mse: 0.8373\n",
      "Epoch 54/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1404 - mse: 1.1404 - val_loss: 0.9210 - val_mse: 0.9210\n",
      "Epoch 55/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1590 - mse: 1.1590 - val_loss: 0.8788 - val_mse: 0.8788\n",
      "Epoch 56/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1382 - mse: 1.1382 - val_loss: 0.7403 - val_mse: 0.7403\n",
      "Epoch 57/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0930 - mse: 1.0930 - val_loss: 0.5703 - val_mse: 0.5703\n",
      "Epoch 58/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0572 - mse: 1.0572 - val_loss: 0.4270 - val_mse: 0.4270\n",
      "Epoch 59/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0508 - mse: 1.0508 - val_loss: 0.3376 - val_mse: 0.3376\n",
      "Epoch 60/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0649 - mse: 1.0649 - val_loss: 0.3015 - val_mse: 0.3015\n",
      "Epoch 61/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0741 - mse: 1.0741 - val_loss: 0.3103 - val_mse: 0.3103\n",
      "Epoch 62/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0619 - mse: 1.0619 - val_loss: 0.3607 - val_mse: 0.3607\n",
      "Epoch 63/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0336 - mse: 1.0336 - val_loss: 0.4491 - val_mse: 0.4491\n",
      "Epoch 64/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0083 - mse: 1.0083 - val_loss: 0.5591 - val_mse: 0.5591\n",
      "Epoch 65/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.6579 - val_mse: 0.6579\n",
      "Epoch 66/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0025 - mse: 1.0025 - val_loss: 0.7105 - val_mse: 0.7105\n",
      "Epoch 67/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0035 - mse: 1.0035 - val_loss: 0.6995 - val_mse: 0.6995\n",
      "Epoch 68/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9922 - mse: 0.9922 - val_loss: 0.6352 - val_mse: 0.6352\n",
      "Epoch 69/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9717 - mse: 0.9717 - val_loss: 0.5472 - val_mse: 0.5472\n",
      "Epoch 70/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9534 - mse: 0.9534 - val_loss: 0.4668 - val_mse: 0.4668\n",
      "Epoch 71/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9446 - mse: 0.9446 - val_loss: 0.4133 - val_mse: 0.4133\n",
      "Epoch 72/120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9423 - mse: 0.9423 - val_loss: 0.3930 - val_mse: 0.3930\n",
      "Epoch 73/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9374 - mse: 0.9374 - val_loss: 0.4051 - val_mse: 0.4051\n",
      "Epoch 74/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9251 - mse: 0.9251 - val_loss: 0.4453 - val_mse: 0.4453\n",
      "Epoch 75/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9085 - mse: 0.9085 - val_loss: 0.5049 - val_mse: 0.5049\n",
      "Epoch 76/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8944 - mse: 0.8944 - val_loss: 0.5676 - val_mse: 0.5676\n",
      "Epoch 77/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8860 - mse: 0.8860 - val_loss: 0.6133 - val_mse: 0.6133\n",
      "Epoch 78/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8801 - mse: 0.8801 - val_loss: 0.6268 - val_mse: 0.6268\n",
      "Epoch 79/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8714 - mse: 0.8714 - val_loss: 0.6060 - val_mse: 0.6060\n",
      "Epoch 80/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8584 - mse: 0.8584 - val_loss: 0.5624 - val_mse: 0.5624\n",
      "Epoch 81/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8442 - mse: 0.8442 - val_loss: 0.5140 - val_mse: 0.5140\n",
      "Epoch 82/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8326 - mse: 0.8326 - val_loss: 0.4764 - val_mse: 0.4764\n",
      "Epoch 83/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8241 - mse: 0.8241 - val_loss: 0.4585 - val_mse: 0.4585\n",
      "Epoch 84/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8156 - mse: 0.8156 - val_loss: 0.4625 - val_mse: 0.4625\n",
      "Epoch 85/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8047 - mse: 0.8047 - val_loss: 0.4858 - val_mse: 0.4858\n",
      "Epoch 86/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7918 - mse: 0.7918 - val_loss: 0.5217 - val_mse: 0.5217\n",
      "Epoch 87/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7796 - mse: 0.7796 - val_loss: 0.5592 - val_mse: 0.5592\n",
      "Epoch 88/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7694 - mse: 0.7694 - val_loss: 0.5861 - val_mse: 0.5861\n",
      "Epoch 89/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7602 - mse: 0.7602 - val_loss: 0.5939 - val_mse: 0.5939\n",
      "Epoch 90/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7500 - mse: 0.7500 - val_loss: 0.5819 - val_mse: 0.5819\n",
      "Epoch 91/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7384 - mse: 0.7384 - val_loss: 0.5571 - val_mse: 0.5571\n",
      "Epoch 92/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7266 - mse: 0.7266 - val_loss: 0.5304 - val_mse: 0.5304\n",
      "Epoch 93/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7160 - mse: 0.7160 - val_loss: 0.5113 - val_mse: 0.5113\n",
      "Epoch 94/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7065 - mse: 0.7065 - val_loss: 0.5052 - val_mse: 0.5052\n",
      "Epoch 95/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6967 - mse: 0.6967 - val_loss: 0.5131 - val_mse: 0.5131\n",
      "Epoch 96/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6861 - mse: 0.6861 - val_loss: 0.5321 - val_mse: 0.5321\n",
      "Epoch 97/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6753 - mse: 0.6753 - val_loss: 0.5559 - val_mse: 0.5559\n",
      "Epoch 98/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6651 - mse: 0.6651 - val_loss: 0.5769 - val_mse: 0.5769\n",
      "Epoch 99/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6558 - mse: 0.6558 - val_loss: 0.5881 - val_mse: 0.5881\n",
      "Epoch 100/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6466 - mse: 0.6466 - val_loss: 0.5870 - val_mse: 0.5870\n",
      "Epoch 101/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6370 - mse: 0.6370 - val_loss: 0.5761 - val_mse: 0.5761\n",
      "Epoch 102/120\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6273 - mse: 0.6273 - val_loss: 0.5615 - val_mse: 0.5615\n",
      "Epoch 103/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6181 - mse: 0.6181 - val_loss: 0.5497 - val_mse: 0.5497\n",
      "Epoch 104/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6095 - mse: 0.6095 - val_loss: 0.5454 - val_mse: 0.5454\n",
      "Epoch 105/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6013 - mse: 0.6013 - val_loss: 0.5502 - val_mse: 0.5502\n",
      "Epoch 106/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5929 - mse: 0.5929 - val_loss: 0.5623 - val_mse: 0.5623\n",
      "Epoch 107/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5846 - mse: 0.5846 - val_loss: 0.5780 - val_mse: 0.5780\n",
      "Epoch 108/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5767 - mse: 0.5767 - val_loss: 0.5921 - val_mse: 0.5921\n",
      "Epoch 109/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5693 - mse: 0.5693 - val_loss: 0.6003 - val_mse: 0.6003\n",
      "Epoch 110/120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5623 - mse: 0.5623 - val_loss: 0.6010 - val_mse: 0.6010\n",
      "Epoch 111/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5553 - mse: 0.5553 - val_loss: 0.5959 - val_mse: 0.5959\n",
      "Epoch 112/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5485 - mse: 0.5485 - val_loss: 0.5889 - val_mse: 0.5889\n",
      "Epoch 113/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5422 - mse: 0.5422 - val_loss: 0.5841 - val_mse: 0.5841\n",
      "Epoch 114/120\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5363 - mse: 0.5363 - val_loss: 0.5843 - val_mse: 0.5843\n",
      "Epoch 115/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5307 - mse: 0.5307 - val_loss: 0.5901 - val_mse: 0.5901\n",
      "Epoch 116/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5252 - mse: 0.5252 - val_loss: 0.5999 - val_mse: 0.5999\n",
      "Epoch 117/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5200 - mse: 0.5200 - val_loss: 0.6110 - val_mse: 0.6110\n",
      "Epoch 118/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5152 - mse: 0.5152 - val_loss: 0.6199 - val_mse: 0.6199\n",
      "Epoch 119/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5108 - mse: 0.5108 - val_loss: 0.6247 - val_mse: 0.6247\n",
      "Epoch 120/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5067 - mse: 0.5067 - val_loss: 0.6251 - val_mse: 0.6251\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001BD245D4550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "r2: 0.4319848659334775 meansquarederror: 0.12644963576210902 meanabsoluteerror: 0.32212730771716963 maxerror: 0.4903057068779968\n",
      "Epoch 1/120\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 2.2495 - mse: 2.2495 - val_loss: 45.5129 - val_mse: 45.5129\n",
      "Epoch 2/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 38.8883 - mse: 38.8883 - val_loss: 5.9473 - val_mse: 5.9473\n",
      "Epoch 3/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5838 - mse: 4.5838 - val_loss: 5.2202 - val_mse: 5.2202\n",
      "Epoch 4/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 9.6214 - mse: 9.6214 - val_loss: 14.6551 - val_mse: 14.6551\n",
      "Epoch 5/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 20.9416 - mse: 20.9416 - val_loss: 7.9108 - val_mse: 7.9108\n",
      "Epoch 6/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 12.9309 - mse: 12.9309 - val_loss: 0.4986 - val_mse: 0.4986\n",
      "Epoch 7/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.8544 - mse: 2.8544 - val_loss: 2.8784 - val_mse: 2.8784\n",
      "Epoch 8/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.4160 - mse: 2.4160 - val_loss: 10.4279 - val_mse: 10.4279\n",
      "Epoch 9/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.0320 - mse: 8.0320 - val_loss: 13.5624 - val_mse: 13.5624\n",
      "Epoch 10/120\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 10.5886 - mse: 10.5886 - val_loss: 10.1068 - val_mse: 10.1068\n",
      "Epoch 11/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.7610 - mse: 7.7610 - val_loss: 4.2112 - val_mse: 4.2112\n",
      "Epoch 12/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2800 - mse: 3.2800 - val_loss: 0.5312 - val_mse: 0.5312\n",
      "Epoch 13/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.3020 - mse: 1.3020 - val_loss: 0.4607 - val_mse: 0.4607\n",
      "Epoch 14/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.7258 - mse: 2.7258 - val_loss: 1.9351 - val_mse: 1.9351\n",
      "Epoch 15/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.1149 - mse: 5.1149 - val_loss: 2.4075 - val_mse: 2.4075\n",
      "Epoch 16/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.7780 - mse: 5.7780 - val_loss: 1.4052 - val_mse: 1.4052\n",
      "Epoch 17/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3127 - mse: 4.3127 - val_loss: 0.2675 - val_mse: 0.2675\n",
      "Epoch 18/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.2618 - mse: 2.2618 - val_loss: 0.3865 - val_mse: 0.3865\n",
      "Epoch 19/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2834 - mse: 1.2834 - val_loss: 1.8984 - val_mse: 1.8984\n",
      "Epoch 20/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7870 - mse: 1.7870 - val_loss: 3.7103 - val_mse: 3.7103\n",
      "Epoch 21/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.9019 - mse: 2.9019 - val_loss: 4.5584 - val_mse: 4.5584\n",
      "Epoch 22/120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.4840 - mse: 3.4840 - val_loss: 3.9923 - val_mse: 3.9923\n",
      "Epoch 23/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.0864 - mse: 3.0864 - val_loss: 2.5217 - val_mse: 2.5217\n",
      "Epoch 24/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.1281 - mse: 2.1281 - val_loss: 1.0653 - val_mse: 1.0653\n",
      "Epoch 25/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3767 - mse: 1.3767 - val_loss: 0.2634 - val_mse: 0.2634\n",
      "Epoch 26/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.2988 - mse: 1.2988 - val_loss: 0.1403 - val_mse: 0.1403\n",
      "Epoch 27/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.7595 - mse: 1.7595 - val_loss: 0.2849 - val_mse: 0.2849\n",
      "Epoch 28/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.2355 - mse: 2.2355 - val_loss: 0.3135 - val_mse: 0.3135\n",
      "Epoch 29/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.2983 - mse: 2.2983 - val_loss: 0.1847 - val_mse: 0.1847\n",
      "Epoch 30/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.9303 - mse: 1.9303 - val_loss: 0.1436 - val_mse: 0.1436\n",
      "Epoch 31/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.4548 - mse: 1.4548 - val_loss: 0.4260 - val_mse: 0.4260\n",
      "Epoch 32/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2186 - mse: 1.2186 - val_loss: 1.0134 - val_mse: 1.0134\n",
      "Epoch 33/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3217 - mse: 1.3217 - val_loss: 1.6285 - val_mse: 1.6285\n",
      "Epoch 34/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.5870 - mse: 1.5870 - val_loss: 1.9450 - val_mse: 1.9450\n",
      "Epoch 35/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.7492 - mse: 1.7492 - val_loss: 1.8164 - val_mse: 1.8164\n",
      "Epoch 36/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.6751 - mse: 1.6751 - val_loss: 1.3512 - val_mse: 1.3512\n",
      "Epoch 37/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4398 - mse: 1.4398 - val_loss: 0.8053 - val_mse: 0.8053\n",
      "Epoch 38/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2318 - mse: 1.2318 - val_loss: 0.3994 - val_mse: 0.3994\n",
      "Epoch 39/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1871 - mse: 1.1871 - val_loss: 0.2020 - val_mse: 0.2020\n",
      "Epoch 40/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2919 - mse: 1.2919 - val_loss: 0.1470 - val_mse: 0.1470\n",
      "Epoch 41/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4174 - mse: 1.4174 - val_loss: 0.1428 - val_mse: 0.1428\n",
      "Epoch 42/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4420 - mse: 1.4420 - val_loss: 0.1649 - val_mse: 0.1649\n",
      "Epoch 43/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3475 - mse: 1.3475 - val_loss: 0.2576 - val_mse: 0.2576\n",
      "Epoch 44/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2161 - mse: 1.2161 - val_loss: 0.4605 - val_mse: 0.4605\n",
      "Epoch 45/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1466 - mse: 1.1466 - val_loss: 0.7405 - val_mse: 0.7405\n",
      "Epoch 46/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1707 - mse: 1.1707 - val_loss: 0.9925 - val_mse: 0.9925\n",
      "Epoch 47/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2390 - mse: 1.2390 - val_loss: 1.1055 - val_mse: 1.1055\n",
      "Epoch 48/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2748 - mse: 1.2748 - val_loss: 1.0368 - val_mse: 1.0368\n",
      "Epoch 49/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2424 - mse: 1.2424 - val_loss: 0.8342 - val_mse: 0.8342\n",
      "Epoch 50/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1693 - mse: 1.1693 - val_loss: 0.5955 - val_mse: 0.5955\n",
      "Epoch 51/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1131 - mse: 1.1131 - val_loss: 0.4044 - val_mse: 0.4044\n",
      "Epoch 52/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1079 - mse: 1.1079 - val_loss: 0.2926 - val_mse: 0.2926\n",
      "Epoch 53/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.1389 - mse: 1.1389 - val_loss: 0.2493 - val_mse: 0.2493\n",
      "Epoch 54/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1627 - mse: 1.1627 - val_loss: 0.2566 - val_mse: 0.2566\n",
      "Epoch 55/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1499 - mse: 1.1499 - val_loss: 0.3115 - val_mse: 0.3115\n",
      "Epoch 56/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1083 - mse: 1.1083 - val_loss: 0.4174 - val_mse: 0.4174\n",
      "Epoch 57/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0699 - mse: 1.0699 - val_loss: 0.5602 - val_mse: 0.5602\n",
      "Epoch 58/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0588 - mse: 1.0588 - val_loss: 0.6977 - val_mse: 0.6977\n",
      "Epoch 59/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0707 - mse: 1.0707 - val_loss: 0.7787 - val_mse: 0.7787\n",
      "Epoch 60/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0812 - mse: 1.0812 - val_loss: 0.7732 - val_mse: 0.7732\n",
      "Epoch 61/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0717 - mse: 1.0717 - val_loss: 0.6910 - val_mse: 0.6910\n",
      "Epoch 62/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0448 - mse: 1.0448 - val_loss: 0.5723 - val_mse: 0.5723\n",
      "Epoch 63/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0190 - mse: 1.0190 - val_loss: 0.4615 - val_mse: 0.4615\n",
      "Epoch 64/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0086 - mse: 1.0086 - val_loss: 0.3858 - val_mse: 0.3858\n",
      "Epoch 65/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0111 - mse: 1.0111 - val_loss: 0.3523 - val_mse: 0.3523\n",
      "Epoch 66/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0122 - mse: 1.0122 - val_loss: 0.3586 - val_mse: 0.3586\n",
      "Epoch 67/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0013 - mse: 1.0013 - val_loss: 0.4007 - val_mse: 0.4007\n",
      "Epoch 68/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9811 - mse: 0.9811 - val_loss: 0.4715 - val_mse: 0.4715\n",
      "Epoch 69/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9628 - mse: 0.9628 - val_loss: 0.5541 - val_mse: 0.5541\n",
      "Epoch 70/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9540 - mse: 0.9540 - val_loss: 0.6224 - val_mse: 0.6224\n",
      "Epoch 71/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9514 - mse: 0.9514 - val_loss: 0.6522 - val_mse: 0.6522\n",
      "Epoch 72/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9462 - mse: 0.9462 - val_loss: 0.6349 - val_mse: 0.6349\n",
      "Epoch 73/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9335 - mse: 0.9335 - val_loss: 0.5817 - val_mse: 0.5817\n",
      "Epoch 74/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9168 - mse: 0.9168 - val_loss: 0.5162 - val_mse: 0.5162\n",
      "Epoch 75/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9030 - mse: 0.9030 - val_loss: 0.4605 - val_mse: 0.4605\n",
      "Epoch 76/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8948 - mse: 0.8948 - val_loss: 0.4280 - val_mse: 0.4280\n",
      "Epoch 77/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8886 - mse: 0.8886 - val_loss: 0.4228 - val_mse: 0.4228\n",
      "Epoch 78/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8792 - mse: 0.8792 - val_loss: 0.4434 - val_mse: 0.4434\n",
      "Epoch 79/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8656 - mse: 0.8656 - val_loss: 0.4836 - val_mse: 0.4836\n",
      "Epoch 80/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8514 - mse: 0.8514 - val_loss: 0.5321 - val_mse: 0.5321\n",
      "Epoch 81/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8402 - mse: 0.8402 - val_loss: 0.5734 - val_mse: 0.5734\n",
      "Epoch 82/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8317 - mse: 0.8317 - val_loss: 0.5932 - val_mse: 0.5932\n",
      "Epoch 83/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8226 - mse: 0.8226 - val_loss: 0.5859 - val_mse: 0.5859\n",
      "Epoch 84/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8109 - mse: 0.8109 - val_loss: 0.5572 - val_mse: 0.5572\n",
      "Epoch 85/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7977 - mse: 0.7977 - val_loss: 0.5204 - val_mse: 0.5204\n",
      "Epoch 86/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7856 - mse: 0.7856 - val_loss: 0.4890 - val_mse: 0.4890\n",
      "Epoch 87/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7756 - mse: 0.7756 - val_loss: 0.4721 - val_mse: 0.4721\n",
      "Epoch 88/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7660 - mse: 0.7660 - val_loss: 0.4730 - val_mse: 0.4730\n",
      "Epoch 89/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7552 - mse: 0.7552 - val_loss: 0.4901 - val_mse: 0.4901\n",
      "Epoch 90/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7430 - mse: 0.7430 - val_loss: 0.5176 - val_mse: 0.5176\n",
      "Epoch 91/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7312 - mse: 0.7312 - val_loss: 0.5465 - val_mse: 0.5465\n",
      "Epoch 92/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7207 - mse: 0.7207 - val_loss: 0.5668 - val_mse: 0.5668\n",
      "Epoch 93/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7109 - mse: 0.7109 - val_loss: 0.5719 - val_mse: 0.5719\n",
      "Epoch 94/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7006 - mse: 0.7006 - val_loss: 0.5618 - val_mse: 0.5618\n",
      "Epoch 95/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6894 - mse: 0.6894 - val_loss: 0.5425 - val_mse: 0.5425\n",
      "Epoch 96/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6784 - mse: 0.6784 - val_loss: 0.5229 - val_mse: 0.5229\n",
      "Epoch 97/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6682 - mse: 0.6682 - val_loss: 0.5103 - val_mse: 0.5103\n",
      "Epoch 98/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6587 - mse: 0.6587 - val_loss: 0.5088 - val_mse: 0.5088\n",
      "Epoch 99/120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6491 - mse: 0.6491 - val_loss: 0.5181 - val_mse: 0.5181\n",
      "Epoch 100/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6390 - mse: 0.6390 - val_loss: 0.5351 - val_mse: 0.5351\n",
      "Epoch 101/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6291 - mse: 0.6291 - val_loss: 0.5537 - val_mse: 0.5537\n",
      "Epoch 102/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6199 - mse: 0.6199 - val_loss: 0.5676 - val_mse: 0.5676\n",
      "Epoch 103/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6112 - mse: 0.6112 - val_loss: 0.5725 - val_mse: 0.5725\n",
      "Epoch 104/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6026 - mse: 0.6026 - val_loss: 0.5681 - val_mse: 0.5681\n",
      "Epoch 105/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5938 - mse: 0.5938 - val_loss: 0.5581 - val_mse: 0.5581\n",
      "Epoch 106/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5853 - mse: 0.5853 - val_loss: 0.5481 - val_mse: 0.5481\n",
      "Epoch 107/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5775 - mse: 0.5775 - val_loss: 0.5428 - val_mse: 0.5428\n",
      "Epoch 108/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5700 - mse: 0.5700 - val_loss: 0.5446 - val_mse: 0.5446\n",
      "Epoch 109/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5627 - mse: 0.5627 - val_loss: 0.5531 - val_mse: 0.5531\n",
      "Epoch 110/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5555 - mse: 0.5555 - val_loss: 0.5655 - val_mse: 0.5655\n",
      "Epoch 111/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5486 - mse: 0.5486 - val_loss: 0.5777 - val_mse: 0.5777\n",
      "Epoch 112/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5423 - mse: 0.5423 - val_loss: 0.5859 - val_mse: 0.5859\n",
      "Epoch 113/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5364 - mse: 0.5364 - val_loss: 0.5883 - val_mse: 0.5883\n",
      "Epoch 114/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5306 - mse: 0.5306 - val_loss: 0.5858 - val_mse: 0.5858\n",
      "Epoch 115/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5250 - mse: 0.5250 - val_loss: 0.5813 - val_mse: 0.5813\n",
      "Epoch 116/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5199 - mse: 0.5199 - val_loss: 0.5783 - val_mse: 0.5783\n",
      "Epoch 117/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5152 - mse: 0.5152 - val_loss: 0.5792 - val_mse: 0.5792\n",
      "Epoch 118/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5108 - mse: 0.5108 - val_loss: 0.5845 - val_mse: 0.5845\n",
      "Epoch 119/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5066 - mse: 0.5066 - val_loss: 0.5932 - val_mse: 0.5932\n",
      "Epoch 120/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5026 - mse: 0.5026 - val_loss: 0.6026 - val_mse: 0.6026\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001BD2BC198B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "r2: 0.408280940288691 meansquarederror: 0.1317265246760659 meanabsoluteerror: 0.32824902705913145 maxerror: 0.5074451022805189\n",
      "Epoch 1/120\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 2.0553 - mse: 2.0553 - val_loss: 49.7289 - val_mse: 49.7289\n",
      "Epoch 2/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 42.9223 - mse: 42.9223 - val_loss: 5.9821 - val_mse: 5.9821\n",
      "Epoch 3/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.6628 - mse: 4.6628 - val_loss: 6.1718 - val_mse: 6.1718\n",
      "Epoch 4/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 10.7286 - mse: 10.7286 - val_loss: 16.8584 - val_mse: 16.8584\n",
      "Epoch 5/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 23.3493 - mse: 23.3493 - val_loss: 9.6601 - val_mse: 9.6601\n",
      "Epoch 6/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 14.9331 - mse: 14.9331 - val_loss: 0.8661 - val_mse: 0.8661\n",
      "Epoch 7/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.4787 - mse: 3.4787 - val_loss: 2.4896 - val_mse: 2.4896\n",
      "Epoch 8/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.2006 - mse: 2.2006 - val_loss: 10.6962 - val_mse: 10.6962\n",
      "Epoch 9/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.3189 - mse: 8.3189 - val_loss: 14.8126 - val_mse: 14.8126\n",
      "Epoch 10/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 11.7136 - mse: 11.7136 - val_loss: 11.5549 - val_mse: 11.5549\n",
      "Epoch 11/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.0018 - mse: 9.0018 - val_loss: 5.1019 - val_mse: 5.1019\n",
      "Epoch 12/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.9486 - mse: 3.9486 - val_loss: 0.7386 - val_mse: 0.7386\n",
      "Epoch 13/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.3298 - mse: 1.3298 - val_loss: 0.4064 - val_mse: 0.4064\n",
      "Epoch 14/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.5760 - mse: 2.5760 - val_loss: 2.0970 - val_mse: 2.0970\n",
      "Epoch 15/120\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.2874 - mse: 5.2874 - val_loss: 2.8881 - val_mse: 2.8881\n",
      "Epoch 16/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.3731 - mse: 6.3731 - val_loss: 1.9234 - val_mse: 1.9234\n",
      "Epoch 17/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.0245 - mse: 5.0245 - val_loss: 0.4849 - val_mse: 0.4849\n",
      "Epoch 18/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.7077 - mse: 2.7077 - val_loss: 0.2321 - val_mse: 0.2321\n",
      "Epoch 19/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.3372 - mse: 1.3372 - val_loss: 1.6260 - val_mse: 1.6260\n",
      "Epoch 20/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.6521 - mse: 1.6521 - val_loss: 3.6536 - val_mse: 3.6536\n",
      "Epoch 21/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.8841 - mse: 2.8841 - val_loss: 4.8416 - val_mse: 4.8416\n",
      "Epoch 22/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.7105 - mse: 3.7105 - val_loss: 4.4734 - val_mse: 4.4734\n",
      "Epoch 23/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.4433 - mse: 3.4433 - val_loss: 2.9586 - val_mse: 2.9586\n",
      "Epoch 24/120\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 2.4122 - mse: 2.4122 - val_loss: 1.3072 - val_mse: 1.3072\n",
      "Epoch 25/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.4755 - mse: 1.4755 - val_loss: 0.3245 - val_mse: 0.3245\n",
      "Epoch 26/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.2561 - mse: 1.2561 - val_loss: 0.1377 - val_mse: 0.1377\n",
      "Epoch 27/120\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.7098 - mse: 1.7098 - val_loss: 0.3201 - val_mse: 0.3201\n",
      "Epoch 28/120\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.2850 - mse: 2.2850 - val_loss: 0.3974 - val_mse: 0.3974\n",
      "Epoch 29/120\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.4502 - mse: 2.4502 - val_loss: 0.2526 - val_mse: 0.2526\n",
      "Epoch 30/120\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.1017 - mse: 2.1017 - val_loss: 0.1308 - val_mse: 0.1308\n",
      "Epoch 31/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.5556 - mse: 1.5556 - val_loss: 0.3345 - val_mse: 0.3345\n",
      "Epoch 32/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.2242 - mse: 1.2242 - val_loss: 0.9145 - val_mse: 0.9145\n",
      "Epoch 33/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2820 - mse: 1.2820 - val_loss: 1.6045 - val_mse: 1.6045\n",
      "Epoch 34/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.5739 - mse: 1.5739 - val_loss: 2.0245 - val_mse: 2.0245\n",
      "Epoch 35/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.7946 - mse: 1.7946 - val_loss: 1.9603 - val_mse: 1.9603\n",
      "Epoch 36/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.7536 - mse: 1.7536 - val_loss: 1.4910 - val_mse: 1.4910\n",
      "Epoch 37/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.5019 - mse: 1.5019 - val_loss: 0.8932 - val_mse: 0.8932\n",
      "Epoch 38/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2485 - mse: 1.2485 - val_loss: 0.4315 - val_mse: 0.4315\n",
      "Epoch 39/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1687 - mse: 1.1687 - val_loss: 0.2043 - val_mse: 0.2043\n",
      "Epoch 40/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2718 - mse: 1.2718 - val_loss: 0.1445 - val_mse: 0.1445\n",
      "Epoch 41/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4214 - mse: 1.4214 - val_loss: 0.1407 - val_mse: 0.1407\n",
      "Epoch 42/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4696 - mse: 1.4696 - val_loss: 0.1521 - val_mse: 0.1521\n",
      "Epoch 43/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3772 - mse: 1.3772 - val_loss: 0.2254 - val_mse: 0.2254\n",
      "Epoch 44/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.2268 - mse: 1.2268 - val_loss: 0.4176 - val_mse: 0.4176\n",
      "Epoch 45/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1350 - mse: 1.1350 - val_loss: 0.7096 - val_mse: 0.7096\n",
      "Epoch 46/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1514 - mse: 1.1514 - val_loss: 0.9927 - val_mse: 0.9927\n",
      "Epoch 47/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2288 - mse: 1.2288 - val_loss: 1.1377 - val_mse: 1.1377\n",
      "Epoch 48/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2782 - mse: 1.2782 - val_loss: 1.0837 - val_mse: 1.0837\n",
      "Epoch 49/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2500 - mse: 1.2500 - val_loss: 0.8744 - val_mse: 0.8744\n",
      "Epoch 50/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1690 - mse: 1.1690 - val_loss: 0.6168 - val_mse: 0.6168\n",
      "Epoch 51/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1012 - mse: 1.1012 - val_loss: 0.4078 - val_mse: 0.4078\n",
      "Epoch 52/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0904 - mse: 1.0904 - val_loss: 0.2857 - val_mse: 0.2857\n",
      "Epoch 53/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.1247 - mse: 1.1247 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 54/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1554 - mse: 1.1554 - val_loss: 0.2411 - val_mse: 0.2411\n",
      "Epoch 55/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.1455 - mse: 1.1455 - val_loss: 0.2918 - val_mse: 0.2918\n",
      "Epoch 56/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1003 - mse: 1.1003 - val_loss: 0.3967 - val_mse: 0.3967\n",
      "Epoch 57/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0558 - mse: 1.0558 - val_loss: 0.5454 - val_mse: 0.5454\n",
      "Epoch 58/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0415 - mse: 1.0415 - val_loss: 0.6949 - val_mse: 0.6949\n",
      "Epoch 59/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0549 - mse: 1.0549 - val_loss: 0.7879 - val_mse: 0.7879\n",
      "Epoch 60/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0691 - mse: 1.0691 - val_loss: 0.7883 - val_mse: 0.7883\n",
      "Epoch 61/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0610 - mse: 1.0610 - val_loss: 0.7038 - val_mse: 0.7038\n",
      "Epoch 62/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0320 - mse: 1.0320 - val_loss: 0.5776 - val_mse: 0.5776\n",
      "Epoch 63/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0030 - mse: 1.0030 - val_loss: 0.4590 - val_mse: 0.4590\n",
      "Epoch 64/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9912 - mse: 0.9912 - val_loss: 0.3779 - val_mse: 0.3779\n",
      "Epoch 65/120\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9950 - mse: 0.9950 - val_loss: 0.3415 - val_mse: 0.3415\n",
      "Epoch 66/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9980 - mse: 0.9980 - val_loss: 0.3462 - val_mse: 0.3462\n",
      "Epoch 67/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9876 - mse: 0.9876 - val_loss: 0.3882 - val_mse: 0.3882\n",
      "Epoch 68/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9660 - mse: 0.9660 - val_loss: 0.4611 - val_mse: 0.4611\n",
      "Epoch 69/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9462 - mse: 0.9462 - val_loss: 0.5484 - val_mse: 0.5484\n",
      "Epoch 70/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9371 - mse: 0.9371 - val_loss: 0.6224 - val_mse: 0.6224\n",
      "Epoch 71/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9355 - mse: 0.9355 - val_loss: 0.6562 - val_mse: 0.6562\n",
      "Epoch 72/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9314 - mse: 0.9314 - val_loss: 0.6394 - val_mse: 0.6394\n",
      "Epoch 73/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9187 - mse: 0.9187 - val_loss: 0.5837 - val_mse: 0.5837\n",
      "Epoch 74/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9012 - mse: 0.9012 - val_loss: 0.5142 - val_mse: 0.5142\n",
      "Epoch 75/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8869 - mse: 0.8869 - val_loss: 0.4552 - val_mse: 0.4552\n",
      "Epoch 76/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8791 - mse: 0.8791 - val_loss: 0.4206 - val_mse: 0.4206\n",
      "Epoch 77/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8737 - mse: 0.8737 - val_loss: 0.4144 - val_mse: 0.4144\n",
      "Epoch 78/120\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8649 - mse: 0.8649 - val_loss: 0.4351 - val_mse: 0.4351\n",
      "Epoch 79/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8513 - mse: 0.8513 - val_loss: 0.4768 - val_mse: 0.4768\n",
      "Epoch 80/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8368 - mse: 0.8368 - val_loss: 0.5279 - val_mse: 0.5279\n",
      "Epoch 81/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8257 - mse: 0.8257 - val_loss: 0.5720 - val_mse: 0.5720\n",
      "Epoch 82/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8178 - mse: 0.8178 - val_loss: 0.5938 - val_mse: 0.5938\n",
      "Epoch 83/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8095 - mse: 0.8095 - val_loss: 0.5869 - val_mse: 0.5869\n",
      "Epoch 84/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7981 - mse: 0.7981 - val_loss: 0.5571 - val_mse: 0.5571\n",
      "Epoch 85/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7850 - mse: 0.7850 - val_loss: 0.5183 - val_mse: 0.5183\n",
      "Epoch 86/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7731 - mse: 0.7731 - val_loss: 0.4851 - val_mse: 0.4851\n",
      "Epoch 87/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7636 - mse: 0.7636 - val_loss: 0.4669 - val_mse: 0.4669\n",
      "Epoch 88/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7547 - mse: 0.7547 - val_loss: 0.4672 - val_mse: 0.4672\n",
      "Epoch 89/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7444 - mse: 0.7444 - val_loss: 0.4845 - val_mse: 0.4845\n",
      "Epoch 90/120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7326 - mse: 0.7326 - val_loss: 0.5130 - val_mse: 0.5130\n",
      "Epoch 91/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7211 - mse: 0.7211 - val_loss: 0.5434 - val_mse: 0.5434\n",
      "Epoch 92/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7111 - mse: 0.7111 - val_loss: 0.5654 - val_mse: 0.5654\n",
      "Epoch 93/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7020 - mse: 0.7020 - val_loss: 0.5716 - val_mse: 0.5716\n",
      "Epoch 94/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6923 - mse: 0.6923 - val_loss: 0.5617 - val_mse: 0.5617\n",
      "Epoch 95/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6816 - mse: 0.6816 - val_loss: 0.5417 - val_mse: 0.5417\n",
      "Epoch 96/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6710 - mse: 0.6710 - val_loss: 0.5209 - val_mse: 0.5209\n",
      "Epoch 97/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6613 - mse: 0.6613 - val_loss: 0.5072 - val_mse: 0.5072\n",
      "Epoch 98/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6524 - mse: 0.6524 - val_loss: 0.5047 - val_mse: 0.5047\n",
      "Epoch 99/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6434 - mse: 0.6434 - val_loss: 0.5137 - val_mse: 0.5137\n",
      "Epoch 100/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6338 - mse: 0.6338 - val_loss: 0.5308 - val_mse: 0.5308\n",
      "Epoch 101/120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6244 - mse: 0.6244 - val_loss: 0.5503 - val_mse: 0.5503\n",
      "Epoch 102/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6156 - mse: 0.6156 - val_loss: 0.5653 - val_mse: 0.5653\n",
      "Epoch 103/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6075 - mse: 0.6075 - val_loss: 0.5713 - val_mse: 0.5713\n",
      "Epoch 104/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5994 - mse: 0.5994 - val_loss: 0.5675 - val_mse: 0.5675\n",
      "Epoch 105/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5911 - mse: 0.5911 - val_loss: 0.5573 - val_mse: 0.5573\n",
      "Epoch 106/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5830 - mse: 0.5830 - val_loss: 0.5465 - val_mse: 0.5465\n",
      "Epoch 107/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5755 - mse: 0.5755 - val_loss: 0.5402 - val_mse: 0.5402\n",
      "Epoch 108/120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5685 - mse: 0.5685 - val_loss: 0.5409 - val_mse: 0.5409\n",
      "Epoch 109/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5616 - mse: 0.5616 - val_loss: 0.5487 - val_mse: 0.5487\n",
      "Epoch 110/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5547 - mse: 0.5547 - val_loss: 0.5610 - val_mse: 0.5610\n",
      "Epoch 111/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5482 - mse: 0.5482 - val_loss: 0.5738 - val_mse: 0.5738\n",
      "Epoch 112/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5421 - mse: 0.5421 - val_loss: 0.5830 - val_mse: 0.5830\n",
      "Epoch 113/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5364 - mse: 0.5364 - val_loss: 0.5863 - val_mse: 0.5863\n",
      "Epoch 114/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5309 - mse: 0.5309 - val_loss: 0.5841 - val_mse: 0.5841\n",
      "Epoch 115/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5255 - mse: 0.5255 - val_loss: 0.5793 - val_mse: 0.5793\n",
      "Epoch 116/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5205 - mse: 0.5205 - val_loss: 0.5754 - val_mse: 0.5754\n",
      "Epoch 117/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5159 - mse: 0.5159 - val_loss: 0.5752 - val_mse: 0.5752\n",
      "Epoch 118/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5117 - mse: 0.5117 - val_loss: 0.5795 - val_mse: 0.5795\n",
      "Epoch 119/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5076 - mse: 0.5076 - val_loss: 0.5875 - val_mse: 0.5875\n",
      "Epoch 120/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5037 - mse: 0.5037 - val_loss: 0.5970 - val_mse: 0.5970\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "r2: 0.3977582462222208 meansquarederror: 0.13406905175349662 meanabsoluteerror: 0.33100736723211477 maxerror: 0.5087051916746113\n",
      "Epoch 1/120\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 1.4014 - mse: 1.4014 - val_loss: 53.7794 - val_mse: 53.7794\n",
      "Epoch 2/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 46.4789 - mse: 46.4789 - val_loss: 5.7539 - val_mse: 5.7539\n",
      "Epoch 3/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.4643 - mse: 4.4643 - val_loss: 7.2892 - val_mse: 7.2892\n",
      "Epoch 4/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 12.1348 - mse: 12.1348 - val_loss: 19.2370 - val_mse: 19.2370\n",
      "Epoch 5/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 26.0875 - mse: 26.0875 - val_loss: 12.1720 - val_mse: 12.1720\n",
      "Epoch 6/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 17.9276 - mse: 17.9276 - val_loss: 1.9092 - val_mse: 1.9092\n",
      "Epoch 7/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.1091 - mse: 5.1091 - val_loss: 1.3016 - val_mse: 1.3016\n",
      "Epoch 8/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5553 - mse: 1.5553 - val_loss: 9.1110 - val_mse: 9.1110\n",
      "Epoch 9/120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.0078 - mse: 7.0078 - val_loss: 15.2975 - val_mse: 15.2975\n",
      "Epoch 10/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 12.0671 - mse: 12.0671 - val_loss: 14.3633 - val_mse: 14.3633\n",
      "Epoch 11/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 11.2776 - mse: 11.2776 - val_loss: 8.4810 - val_mse: 8.4810\n",
      "Epoch 12/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.4919 - mse: 6.4919 - val_loss: 2.6283 - val_mse: 2.6283\n",
      "Epoch 13/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.2516 - mse: 2.2516 - val_loss: 0.1604 - val_mse: 0.1604\n",
      "Epoch 14/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4556 - mse: 1.4556 - val_loss: 0.9462 - val_mse: 0.9462\n",
      "Epoch 15/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.5774 - mse: 3.5774 - val_loss: 2.5280 - val_mse: 2.5280\n",
      "Epoch 16/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.9137 - mse: 5.9137 - val_loss: 2.8460 - val_mse: 2.8460\n",
      "Epoch 17/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.3420 - mse: 6.3420 - val_loss: 1.7381 - val_mse: 1.7381\n",
      "Epoch 18/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.7809 - mse: 4.7809 - val_loss: 0.4331 - val_mse: 0.4331\n",
      "Epoch 19/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.6242 - mse: 2.6242 - val_loss: 0.2134 - val_mse: 0.2134\n",
      "Epoch 20/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3638 - mse: 1.3638 - val_loss: 1.4018 - val_mse: 1.4018\n",
      "Epoch 21/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5447 - mse: 1.5447 - val_loss: 3.2349 - val_mse: 3.2349\n",
      "Epoch 22/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.5992 - mse: 2.5992 - val_loss: 4.5488 - val_mse: 4.5488\n",
      "Epoch 23/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4914 - mse: 3.4914 - val_loss: 4.6271 - val_mse: 4.6271\n",
      "Epoch 24/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.5436 - mse: 3.5436 - val_loss: 3.5661 - val_mse: 3.5661\n",
      "Epoch 25/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.8075 - mse: 2.8075 - val_loss: 2.0427 - val_mse: 2.0427\n",
      "Epoch 26/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.8559 - mse: 1.8559 - val_loss: 0.7962 - val_mse: 0.7962\n",
      "Epoch 27/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.2924 - mse: 1.2924 - val_loss: 0.1995 - val_mse: 0.1995\n",
      "Epoch 28/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.3509 - mse: 1.3509 - val_loss: 0.1517 - val_mse: 0.1517\n",
      "Epoch 29/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.8136 - mse: 1.8136 - val_loss: 0.2921 - val_mse: 0.2921\n",
      "Epoch 30/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2430 - mse: 2.2430 - val_loss: 0.3250 - val_mse: 0.3250\n",
      "Epoch 31/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.3157 - mse: 2.3157 - val_loss: 0.2114 - val_mse: 0.2114\n",
      "Epoch 32/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.0114 - mse: 2.0114 - val_loss: 0.1291 - val_mse: 0.1291\n",
      "Epoch 33/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.5640 - mse: 1.5640 - val_loss: 0.2837 - val_mse: 0.2837\n",
      "Epoch 34/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2602 - mse: 1.2602 - val_loss: 0.7264 - val_mse: 0.7264\n",
      "Epoch 35/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2420 - mse: 1.2420 - val_loss: 1.3039 - val_mse: 1.3039\n",
      "Epoch 36/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.4399 - mse: 1.4399 - val_loss: 1.7573 - val_mse: 1.7573\n",
      "Epoch 37/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.6566 - mse: 1.6566 - val_loss: 1.8858 - val_mse: 1.8858\n",
      "Epoch 38/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.7210 - mse: 1.7210 - val_loss: 1.6587 - val_mse: 1.6587\n",
      "Epoch 39/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.5966 - mse: 1.5966 - val_loss: 1.2096 - val_mse: 1.2096\n",
      "Epoch 40/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3811 - mse: 1.3811 - val_loss: 0.7380 - val_mse: 0.7380\n",
      "Epoch 41/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2170 - mse: 1.2170 - val_loss: 0.3933 - val_mse: 0.3933\n",
      "Epoch 42/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1886 - mse: 1.1886 - val_loss: 0.2154 - val_mse: 0.2154\n",
      "Epoch 43/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2749 - mse: 1.2749 - val_loss: 0.1555 - val_mse: 0.1555\n",
      "Epoch 44/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.3818 - mse: 1.3818 - val_loss: 0.1462 - val_mse: 0.1462\n",
      "Epoch 45/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4187 - mse: 1.4187 - val_loss: 0.1605 - val_mse: 0.1605\n",
      "Epoch 46/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.3599 - mse: 1.3599 - val_loss: 0.2206 - val_mse: 0.2206\n",
      "Epoch 47/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2512 - mse: 1.2512 - val_loss: 0.3600 - val_mse: 0.3600\n",
      "Epoch 48/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1656 - mse: 1.1656 - val_loss: 0.5766 - val_mse: 0.5766\n",
      "Epoch 49/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1483 - mse: 1.1483 - val_loss: 0.8150 - val_mse: 0.8150\n",
      "Epoch 50/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1893 - mse: 1.1893 - val_loss: 0.9916 - val_mse: 0.9916\n",
      "Epoch 51/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2393 - mse: 1.2393 - val_loss: 1.0418 - val_mse: 1.0418\n",
      "Epoch 52/120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2517 - mse: 1.2517 - val_loss: 0.9559 - val_mse: 0.9559\n",
      "Epoch 53/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2152 - mse: 1.2152 - val_loss: 0.7794 - val_mse: 0.7794\n",
      "Epoch 54/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1562 - mse: 1.1562 - val_loss: 0.5821 - val_mse: 0.5821\n",
      "Epoch 55/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1134 - mse: 1.1134 - val_loss: 0.4208 - val_mse: 0.4208\n",
      "Epoch 56/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1074 - mse: 1.1074 - val_loss: 0.3187 - val_mse: 0.3187\n",
      "Epoch 57/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1282 - mse: 1.1282 - val_loss: 0.2720 - val_mse: 0.2720\n",
      "Epoch 58/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1478 - mse: 1.1478 - val_loss: 0.2686 - val_mse: 0.2686\n",
      "Epoch 59/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1441 - mse: 1.1441 - val_loss: 0.3036 - val_mse: 0.3036\n",
      "Epoch 60/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1164 - mse: 1.1164 - val_loss: 0.3777 - val_mse: 0.3777\n",
      "Epoch 61/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0827 - mse: 1.0827 - val_loss: 0.4853 - val_mse: 0.4853\n",
      "Epoch 62/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0625 - mse: 1.0625 - val_loss: 0.6046 - val_mse: 0.6046\n",
      "Epoch 63/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0620 - mse: 1.0620 - val_loss: 0.7017 - val_mse: 0.7017\n",
      "Epoch 64/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0707 - mse: 1.0707 - val_loss: 0.7458 - val_mse: 0.7458\n",
      "Epoch 65/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0729 - mse: 1.0729 - val_loss: 0.7254 - val_mse: 0.7254\n",
      "Epoch 66/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0606 - mse: 1.0606 - val_loss: 0.6536 - val_mse: 0.6536\n",
      "Epoch 67/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0389 - mse: 1.0389 - val_loss: 0.5590 - val_mse: 0.5590\n",
      "Epoch 68/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0195 - mse: 1.0195 - val_loss: 0.4708 - val_mse: 0.4708\n",
      "Epoch 69/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0104 - mse: 1.0104 - val_loss: 0.4074 - val_mse: 0.4074\n",
      "Epoch 70/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0098 - mse: 1.0098 - val_loss: 0.3756 - val_mse: 0.3756\n",
      "Epoch 71/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0091 - mse: 1.0091 - val_loss: 0.3747 - val_mse: 0.3747\n",
      "Epoch 72/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0012 - mse: 1.0012 - val_loss: 0.4019 - val_mse: 0.4019\n",
      "Epoch 73/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9863 - mse: 0.9863 - val_loss: 0.4525 - val_mse: 0.4525\n",
      "Epoch 74/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9704 - mse: 0.9704 - val_loss: 0.5164 - val_mse: 0.5164\n",
      "Epoch 75/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9592 - mse: 0.9592 - val_loss: 0.5778 - val_mse: 0.5778\n",
      "Epoch 76/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9535 - mse: 0.9535 - val_loss: 0.6193 - val_mse: 0.6193\n",
      "Epoch 77/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9491 - mse: 0.9491 - val_loss: 0.6290 - val_mse: 0.6290\n",
      "Epoch 78/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9413 - mse: 0.9413 - val_loss: 0.6068 - val_mse: 0.6068\n",
      "Epoch 79/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9291 - mse: 0.9291 - val_loss: 0.5629 - val_mse: 0.5629\n",
      "Epoch 80/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9156 - mse: 0.9156 - val_loss: 0.5132 - val_mse: 0.5132\n",
      "Epoch 81/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9044 - mse: 0.9044 - val_loss: 0.4716 - val_mse: 0.4716\n",
      "Epoch 82/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8964 - mse: 0.8964 - val_loss: 0.4467 - val_mse: 0.4467\n",
      "Epoch 83/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8894 - mse: 0.8894 - val_loss: 0.4416 - val_mse: 0.4416\n",
      "Epoch 84/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8805 - mse: 0.8805 - val_loss: 0.4555 - val_mse: 0.4555\n",
      "Epoch 85/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8691 - mse: 0.8691 - val_loss: 0.4844 - val_mse: 0.4844\n",
      "Epoch 86/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8569 - mse: 0.8569 - val_loss: 0.5211 - val_mse: 0.5211\n",
      "Epoch 87/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8460 - mse: 0.8460 - val_loss: 0.5556 - val_mse: 0.5556\n",
      "Epoch 88/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8369 - mse: 0.8369 - val_loss: 0.5782 - val_mse: 0.5782\n",
      "Epoch 89/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8283 - mse: 0.8283 - val_loss: 0.5829 - val_mse: 0.5829\n",
      "Epoch 90/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8186 - mse: 0.8186 - val_loss: 0.5701 - val_mse: 0.5701\n",
      "Epoch 91/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8074 - mse: 0.8074 - val_loss: 0.5459 - val_mse: 0.5459\n",
      "Epoch 92/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7959 - mse: 0.7959 - val_loss: 0.5194 - val_mse: 0.5194\n",
      "Epoch 93/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7855 - mse: 0.7855 - val_loss: 0.4985 - val_mse: 0.4985\n",
      "Epoch 94/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7760 - mse: 0.7760 - val_loss: 0.4884 - val_mse: 0.4884\n",
      "Epoch 95/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7665 - mse: 0.7665 - val_loss: 0.4908 - val_mse: 0.4908\n",
      "Epoch 96/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7563 - mse: 0.7563 - val_loss: 0.5042 - val_mse: 0.5042\n",
      "Epoch 97/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7454 - mse: 0.7454 - val_loss: 0.5248 - val_mse: 0.5248\n",
      "Epoch 98/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7347 - mse: 0.7347 - val_loss: 0.5465 - val_mse: 0.5465\n",
      "Epoch 99/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7248 - mse: 0.7248 - val_loss: 0.5632 - val_mse: 0.5632\n",
      "Epoch 100/120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7153 - mse: 0.7153 - val_loss: 0.5704 - val_mse: 0.5704\n",
      "Epoch 101/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7056 - mse: 0.7056 - val_loss: 0.5670 - val_mse: 0.5670\n",
      "Epoch 102/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6956 - mse: 0.6956 - val_loss: 0.5557 - val_mse: 0.5557\n",
      "Epoch 103/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6854 - mse: 0.6854 - val_loss: 0.5416 - val_mse: 0.5416\n",
      "Epoch 104/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6756 - mse: 0.6756 - val_loss: 0.5300 - val_mse: 0.5300\n",
      "Epoch 105/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6664 - mse: 0.6664 - val_loss: 0.5245 - val_mse: 0.5245\n",
      "Epoch 106/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6573 - mse: 0.6573 - val_loss: 0.5267 - val_mse: 0.5267\n",
      "Epoch 107/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6481 - mse: 0.6481 - val_loss: 0.5358 - val_mse: 0.5358\n",
      "Epoch 108/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6388 - mse: 0.6388 - val_loss: 0.5491 - val_mse: 0.5491\n",
      "Epoch 109/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6298 - mse: 0.6298 - val_loss: 0.5627 - val_mse: 0.5627\n",
      "Epoch 110/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6212 - mse: 0.6212 - val_loss: 0.5727 - val_mse: 0.5727\n",
      "Epoch 111/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6130 - mse: 0.6130 - val_loss: 0.5769 - val_mse: 0.5769\n",
      "Epoch 112/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6048 - mse: 0.6048 - val_loss: 0.5750 - val_mse: 0.5750\n",
      "Epoch 113/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5967 - mse: 0.5967 - val_loss: 0.5692 - val_mse: 0.5692\n",
      "Epoch 114/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5887 - mse: 0.5887 - val_loss: 0.5627 - val_mse: 0.5627\n",
      "Epoch 115/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5812 - mse: 0.5812 - val_loss: 0.5586 - val_mse: 0.5586\n",
      "Epoch 116/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5740 - mse: 0.5740 - val_loss: 0.5588 - val_mse: 0.5588\n",
      "Epoch 117/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5671 - mse: 0.5671 - val_loss: 0.5636 - val_mse: 0.5636\n",
      "Epoch 118/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5603 - mse: 0.5603 - val_loss: 0.5719 - val_mse: 0.5719\n",
      "Epoch 119/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5537 - mse: 0.5537 - val_loss: 0.5815 - val_mse: 0.5815\n",
      "Epoch 120/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5474 - mse: 0.5474 - val_loss: 0.5899 - val_mse: 0.5899\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "r2: 0.3565676786487699 meansquarederror: 0.14323875860480634 meanabsoluteerror: 0.3490838373669684 maxerror: 0.5132626130845366\n",
      "Epoch 1/120\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 1.4993 - mse: 1.4993 - val_loss: 50.9569 - val_mse: 50.9569\n",
      "Epoch 2/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 43.8163 - mse: 43.8163 - val_loss: 5.6183 - val_mse: 5.6183\n",
      "Epoch 3/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.3464 - mse: 4.3464 - val_loss: 6.6134 - val_mse: 6.6134\n",
      "Epoch 4/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 11.3559 - mse: 11.3559 - val_loss: 17.6846 - val_mse: 17.6846\n",
      "Epoch 5/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 24.3929 - mse: 24.3929 - val_loss: 10.9869 - val_mse: 10.9869\n",
      "Epoch 6/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.5947 - mse: 16.5947 - val_loss: 1.5519 - val_mse: 1.5519\n",
      "Epoch 7/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6151 - mse: 4.6151 - val_loss: 1.4827 - val_mse: 1.4827\n",
      "Epoch 8/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.6377 - mse: 1.6377 - val_loss: 9.1365 - val_mse: 9.1365\n",
      "Epoch 9/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.0076 - mse: 7.0076 - val_loss: 14.7299 - val_mse: 14.7299\n",
      "Epoch 10/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 11.5638 - mse: 11.5638 - val_loss: 13.3643 - val_mse: 13.3643\n",
      "Epoch 11/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 10.4229 - mse: 10.4229 - val_loss: 7.5239 - val_mse: 7.5239\n",
      "Epoch 12/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.7325 - mse: 5.7325 - val_loss: 2.1023 - val_mse: 2.1023\n",
      "Epoch 13/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9394 - mse: 1.9394 - val_loss: 0.1182 - val_mse: 0.1182\n",
      "Epoch 14/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.5995 - mse: 1.5995 - val_loss: 1.0963 - val_mse: 1.0963\n",
      "Epoch 15/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.8443 - mse: 3.8443 - val_loss: 2.5116 - val_mse: 2.5116\n",
      "Epoch 16/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.9170 - mse: 5.9170 - val_loss: 2.5484 - val_mse: 2.5484\n",
      "Epoch 17/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.9603 - mse: 5.9603 - val_loss: 1.3436 - val_mse: 1.3436\n",
      "Epoch 18/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2113 - mse: 4.2113 - val_loss: 0.2400 - val_mse: 0.2400\n",
      "Epoch 19/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.1949 - mse: 2.1949 - val_loss: 0.3884 - val_mse: 0.3884\n",
      "Epoch 20/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2854 - mse: 1.2854 - val_loss: 1.8409 - val_mse: 1.8409\n",
      "Epoch 21/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.7648 - mse: 1.7648 - val_loss: 3.6341 - val_mse: 3.6341\n",
      "Epoch 22/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.8607 - mse: 2.8607 - val_loss: 4.6280 - val_mse: 4.6280\n",
      "Epoch 23/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.5434 - mse: 3.5434 - val_loss: 4.3159 - val_mse: 4.3159\n",
      "Epoch 24/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3209 - mse: 3.3209 - val_loss: 3.0209 - val_mse: 3.0209\n",
      "Epoch 25/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.4488 - mse: 2.4488 - val_loss: 1.5204 - val_mse: 1.5204\n",
      "Epoch 26/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.5824 - mse: 1.5824 - val_loss: 0.4879 - val_mse: 0.4879\n",
      "Epoch 27/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2486 - mse: 1.2486 - val_loss: 0.1304 - val_mse: 0.1304\n",
      "Epoch 28/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5125 - mse: 1.5125 - val_loss: 0.2031 - val_mse: 0.2031\n",
      "Epoch 29/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.0193 - mse: 2.0193 - val_loss: 0.3192 - val_mse: 0.3192\n",
      "Epoch 30/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.3202 - mse: 2.3202 - val_loss: 0.2734 - val_mse: 0.2734\n",
      "Epoch 31/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.2015 - mse: 2.2015 - val_loss: 0.1471 - val_mse: 0.1471\n",
      "Epoch 32/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.7844 - mse: 1.7844 - val_loss: 0.1714 - val_mse: 0.1714\n",
      "Epoch 33/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.3745 - mse: 1.3745 - val_loss: 0.4981 - val_mse: 0.4981\n",
      "Epoch 34/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2184 - mse: 1.2184 - val_loss: 1.0607 - val_mse: 1.0607\n",
      "Epoch 35/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3453 - mse: 1.3453 - val_loss: 1.6118 - val_mse: 1.6118\n",
      "Epoch 36/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5863 - mse: 1.5863 - val_loss: 1.8902 - val_mse: 1.8902\n",
      "Epoch 37/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.7277 - mse: 1.7277 - val_loss: 1.7838 - val_mse: 1.7838\n",
      "Epoch 38/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.6662 - mse: 1.6662 - val_loss: 1.3779 - val_mse: 1.3779\n",
      "Epoch 39/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.4601 - mse: 1.4601 - val_loss: 0.8772 - val_mse: 0.8772\n",
      "Epoch 40/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2593 - mse: 1.2593 - val_loss: 0.4720 - val_mse: 0.4720\n",
      "Epoch 41/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.1854 - mse: 1.1854 - val_loss: 0.2432 - val_mse: 0.2432\n",
      "Epoch 42/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2508 - mse: 1.2508 - val_loss: 0.1587 - val_mse: 0.1587\n",
      "Epoch 43/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.3680 - mse: 1.3680 - val_loss: 0.1424 - val_mse: 0.1424\n",
      "Epoch 44/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.4289 - mse: 1.4289 - val_loss: 0.1513 - val_mse: 0.1513\n",
      "Epoch 45/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.3856 - mse: 1.3856 - val_loss: 0.2013 - val_mse: 0.2013\n",
      "Epoch 46/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2751 - mse: 1.2751 - val_loss: 0.3318 - val_mse: 0.3318\n",
      "Epoch 47/120\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1772 - mse: 1.1772 - val_loss: 0.5495 - val_mse: 0.5495\n",
      "Epoch 48/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.1497 - mse: 1.1497 - val_loss: 0.8006 - val_mse: 0.8006\n",
      "Epoch 49/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.1893 - mse: 1.1893 - val_loss: 0.9939 - val_mse: 0.9939\n",
      "Epoch 50/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.2441 - mse: 1.2441 - val_loss: 1.0547 - val_mse: 1.0547\n",
      "Epoch 51/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.2604 - mse: 1.2604 - val_loss: 0.9681 - val_mse: 0.9681\n",
      "Epoch 52/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.2230 - mse: 1.2230 - val_loss: 0.7825 - val_mse: 0.7825\n",
      "Epoch 53/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.1603 - mse: 1.1603 - val_loss: 0.5751 - val_mse: 0.5751\n",
      "Epoch 54/120\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1154 - mse: 1.1154 - val_loss: 0.4080 - val_mse: 0.4080\n",
      "Epoch 55/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.1108 - mse: 1.1108 - val_loss: 0.3057 - val_mse: 0.3057\n",
      "Epoch 56/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1346 - mse: 1.1346 - val_loss: 0.2617 - val_mse: 0.2617\n",
      "Epoch 57/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.1546 - mse: 1.1546 - val_loss: 0.2626 - val_mse: 0.2626\n",
      "Epoch 58/120\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1476 - mse: 1.1476 - val_loss: 0.3042 - val_mse: 0.3042\n",
      "Epoch 59/120\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1155 - mse: 1.1155 - val_loss: 0.3879 - val_mse: 0.3879\n",
      "Epoch 60/120\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0804 - mse: 1.0804 - val_loss: 0.5057 - val_mse: 0.5057\n",
      "Epoch 61/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0630 - mse: 1.0630 - val_loss: 0.6303 - val_mse: 0.6303\n",
      "Epoch 62/120\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0663 - mse: 1.0663 - val_loss: 0.7229 - val_mse: 0.7229\n",
      "Epoch 63/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0761 - mse: 1.0761 - val_loss: 0.7523 - val_mse: 0.7523\n",
      "Epoch 64/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.0752 - mse: 1.0752 - val_loss: 0.7128 - val_mse: 0.7128\n",
      "Epoch 65/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0583 - mse: 1.0583 - val_loss: 0.6251 - val_mse: 0.6251\n",
      "Epoch 66/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.0342 - mse: 1.0342 - val_loss: 0.5233 - val_mse: 0.5233\n",
      "Epoch 67/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0165 - mse: 1.0165 - val_loss: 0.4372 - val_mse: 0.4372\n",
      "Epoch 68/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0111 - mse: 1.0111 - val_loss: 0.3823 - val_mse: 0.3823\n",
      "Epoch 69/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0122 - mse: 1.0122 - val_loss: 0.3617 - val_mse: 0.3617\n",
      "Epoch 70/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0095 - mse: 1.0095 - val_loss: 0.3733 - val_mse: 0.3733\n",
      "Epoch 71/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9976 - mse: 0.9976 - val_loss: 0.4136 - val_mse: 0.4136\n",
      "Epoch 72/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9801 - mse: 0.9801 - val_loss: 0.4754 - val_mse: 0.4754\n",
      "Epoch 73/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9649 - mse: 0.9649 - val_loss: 0.5447 - val_mse: 0.5447\n",
      "Epoch 74/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.9564 - mse: 0.9564 - val_loss: 0.6017 - val_mse: 0.6017\n",
      "Epoch 75/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9523 - mse: 0.9523 - val_loss: 0.6290 - val_mse: 0.6290\n",
      "Epoch 76/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9466 - mse: 0.9466 - val_loss: 0.6194 - val_mse: 0.6194\n",
      "Epoch 77/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9357 - mse: 0.9357 - val_loss: 0.5800 - val_mse: 0.5800\n",
      "Epoch 78/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9213 - mse: 0.9213 - val_loss: 0.5268 - val_mse: 0.5268\n",
      "Epoch 79/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9081 - mse: 0.9081 - val_loss: 0.4772 - val_mse: 0.4772\n",
      "Epoch 80/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8987 - mse: 0.8987 - val_loss: 0.4433 - val_mse: 0.4433\n",
      "Epoch 81/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8917 - mse: 0.8917 - val_loss: 0.4305 - val_mse: 0.4305\n",
      "Epoch 82/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8836 - mse: 0.8836 - val_loss: 0.4391 - val_mse: 0.4391\n",
      "Epoch 83/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8724 - mse: 0.8724 - val_loss: 0.4658 - val_mse: 0.4658\n",
      "Epoch 84/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8594 - mse: 0.8594 - val_loss: 0.5037 - val_mse: 0.5037\n",
      "Epoch 85/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8474 - mse: 0.8474 - val_loss: 0.5424 - val_mse: 0.5424\n",
      "Epoch 86/120\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8377 - mse: 0.8377 - val_loss: 0.5703 - val_mse: 0.5703\n",
      "Epoch 87/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8291 - mse: 0.8291 - val_loss: 0.5794 - val_mse: 0.5794\n",
      "Epoch 88/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8193 - mse: 0.8193 - val_loss: 0.5684 - val_mse: 0.5684\n",
      "Epoch 89/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8079 - mse: 0.8079 - val_loss: 0.5433 - val_mse: 0.5433\n",
      "Epoch 90/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7958 - mse: 0.7958 - val_loss: 0.5141 - val_mse: 0.5141\n",
      "Epoch 91/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7847 - mse: 0.7847 - val_loss: 0.4902 - val_mse: 0.4902\n",
      "Epoch 92/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7749 - mse: 0.7749 - val_loss: 0.4779 - val_mse: 0.4779\n",
      "Epoch 93/120\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7653 - mse: 0.7653 - val_loss: 0.4792 - val_mse: 0.4792\n",
      "Epoch 94/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7548 - mse: 0.7548 - val_loss: 0.4930 - val_mse: 0.4930\n",
      "Epoch 95/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7435 - mse: 0.7435 - val_loss: 0.5148 - val_mse: 0.5148\n",
      "Epoch 96/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7323 - mse: 0.7323 - val_loss: 0.5383 - val_mse: 0.5383\n",
      "Epoch 97/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7220 - mse: 0.7220 - val_loss: 0.5562 - val_mse: 0.5562\n",
      "Epoch 98/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7123 - mse: 0.7123 - val_loss: 0.5634 - val_mse: 0.5634\n",
      "Epoch 99/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7024 - mse: 0.7024 - val_loss: 0.5589 - val_mse: 0.5589\n",
      "Epoch 100/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6920 - mse: 0.6920 - val_loss: 0.5459 - val_mse: 0.5459\n",
      "Epoch 101/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6814 - mse: 0.6814 - val_loss: 0.5303 - val_mse: 0.5303\n",
      "Epoch 102/120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6714 - mse: 0.6714 - val_loss: 0.5180 - val_mse: 0.5180\n",
      "Epoch 103/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6620 - mse: 0.6620 - val_loss: 0.5130 - val_mse: 0.5130\n",
      "Epoch 104/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6527 - mse: 0.6527 - val_loss: 0.5165 - val_mse: 0.5165\n",
      "Epoch 105/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6433 - mse: 0.6433 - val_loss: 0.5272 - val_mse: 0.5272\n",
      "Epoch 106/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6337 - mse: 0.6337 - val_loss: 0.5419 - val_mse: 0.5419\n",
      "Epoch 107/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6246 - mse: 0.6246 - val_loss: 0.5560 - val_mse: 0.5560\n",
      "Epoch 108/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6159 - mse: 0.6159 - val_loss: 0.5654 - val_mse: 0.5654\n",
      "Epoch 109/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6075 - mse: 0.6075 - val_loss: 0.5679 - val_mse: 0.5679\n",
      "Epoch 110/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5992 - mse: 0.5992 - val_loss: 0.5641 - val_mse: 0.5641\n",
      "Epoch 111/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5909 - mse: 0.5909 - val_loss: 0.5568 - val_mse: 0.5568\n",
      "Epoch 112/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5830 - mse: 0.5830 - val_loss: 0.5500 - val_mse: 0.5500\n",
      "Epoch 113/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5754 - mse: 0.5754 - val_loss: 0.5468 - val_mse: 0.5468\n",
      "Epoch 114/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5683 - mse: 0.5683 - val_loss: 0.5487 - val_mse: 0.5487\n",
      "Epoch 115/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5613 - mse: 0.5613 - val_loss: 0.5555 - val_mse: 0.5555\n",
      "Epoch 116/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5544 - mse: 0.5544 - val_loss: 0.5653 - val_mse: 0.5653\n",
      "Epoch 117/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5479 - mse: 0.5479 - val_loss: 0.5754 - val_mse: 0.5754\n",
      "Epoch 118/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5418 - mse: 0.5418 - val_loss: 0.5830 - val_mse: 0.5830\n",
      "Epoch 119/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5360 - mse: 0.5360 - val_loss: 0.5866 - val_mse: 0.5866\n",
      "Epoch 120/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5305 - mse: 0.5305 - val_loss: 0.5864 - val_mse: 0.5864\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "r2: 0.36669740193507383 meansquarederror: 0.14098371337255367 meanabsoluteerror: 0.34433405639677467 maxerror: 0.5170496470727448\n",
      "Epoch 1/120\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 1.3631 - mse: 1.3631 - val_loss: 29.5973 - val_mse: 29.5973\n",
      "Epoch 2/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 24.5336 - mse: 24.5336 - val_loss: 0.1521 - val_mse: 0.1521\n",
      "Epoch 3/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4216 - mse: 1.4216 - val_loss: 11.9838 - val_mse: 11.9838\n",
      "Epoch 4/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 17.5858 - mse: 17.5858 - val_loss: 9.2561 - val_mse: 9.2561\n",
      "Epoch 5/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 14.3339 - mse: 14.3339 - val_loss: 0.8675 - val_mse: 0.8675\n",
      "Epoch 6/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3427 - mse: 3.3427 - val_loss: 2.8439 - val_mse: 2.8439\n",
      "Epoch 7/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.2919 - mse: 2.2919 - val_loss: 10.9125 - val_mse: 10.9125\n",
      "Epoch 8/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.3642 - mse: 8.3642 - val_loss: 12.5419 - val_mse: 12.5419\n",
      "Epoch 9/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 9.6925 - mse: 9.6925 - val_loss: 7.1405 - val_mse: 7.1405\n",
      "Epoch 10/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.3538 - mse: 5.3538 - val_loss: 1.5367 - val_mse: 1.5367\n",
      "Epoch 11/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5221 - mse: 1.5221 - val_loss: 0.2215 - val_mse: 0.2215\n",
      "Epoch 12/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.9829 - mse: 1.9829 - val_loss: 1.7998 - val_mse: 1.7998\n",
      "Epoch 13/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.7409 - mse: 4.7409 - val_loss: 2.5431 - val_mse: 2.5431\n",
      "Epoch 14/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.7864 - mse: 5.7864 - val_loss: 1.4063 - val_mse: 1.4063\n",
      "Epoch 15/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1386 - mse: 4.1386 - val_loss: 0.1977 - val_mse: 0.1977\n",
      "Epoch 16/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.8738 - mse: 1.8738 - val_loss: 0.7543 - val_mse: 0.7543\n",
      "Epoch 17/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1897 - mse: 1.1897 - val_loss: 2.8576 - val_mse: 2.8576\n",
      "Epoch 18/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.2436 - mse: 2.2436 - val_loss: 4.6186 - val_mse: 4.6186\n",
      "Epoch 19/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.4317 - mse: 3.4317 - val_loss: 4.5759 - val_mse: 4.5759\n",
      "Epoch 20/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.3966 - mse: 3.3966 - val_loss: 2.9728 - val_mse: 2.9728\n",
      "Epoch 21/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.3022 - mse: 2.3022 - val_loss: 1.1615 - val_mse: 1.1615\n",
      "Epoch 22/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2980 - mse: 1.2980 - val_loss: 0.2303 - val_mse: 0.2303\n",
      "Epoch 23/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2176 - mse: 1.2176 - val_loss: 0.2143 - val_mse: 0.2143\n",
      "Epoch 24/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.8605 - mse: 1.8605 - val_loss: 0.4292 - val_mse: 0.4292\n",
      "Epoch 25/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.3865 - mse: 2.3865 - val_loss: 0.3685 - val_mse: 0.3685\n",
      "Epoch 26/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.2456 - mse: 2.2456 - val_loss: 0.1648 - val_mse: 0.1648\n",
      "Epoch 27/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.6326 - mse: 1.6326 - val_loss: 0.2829 - val_mse: 0.2829\n",
      "Epoch 28/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1502 - mse: 1.1502 - val_loss: 0.9211 - val_mse: 0.9211\n",
      "Epoch 29/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1714 - mse: 1.1714 - val_loss: 1.7487 - val_mse: 1.7487\n",
      "Epoch 30/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.5312 - mse: 1.5312 - val_loss: 2.2032 - val_mse: 2.2032\n",
      "Epoch 31/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.7781 - mse: 1.7781 - val_loss: 1.9992 - val_mse: 1.9992\n",
      "Epoch 32/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.6557 - mse: 1.6557 - val_loss: 1.3349 - val_mse: 1.3349\n",
      "Epoch 33/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3096 - mse: 1.3096 - val_loss: 0.6558 - val_mse: 0.6558\n",
      "Epoch 34/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0741 - mse: 1.0741 - val_loss: 0.2674 - val_mse: 0.2674\n",
      "Epoch 35/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1211 - mse: 1.1211 - val_loss: 0.1615 - val_mse: 0.1615\n",
      "Epoch 36/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.3230 - mse: 1.3230 - val_loss: 0.1594 - val_mse: 0.1594\n",
      "Epoch 37/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.4281 - mse: 1.4281 - val_loss: 0.1622 - val_mse: 0.1622\n",
      "Epoch 38/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.3251 - mse: 1.3251 - val_loss: 0.2359 - val_mse: 0.2359\n",
      "Epoch 39/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1265 - mse: 1.1265 - val_loss: 0.4810 - val_mse: 0.4810\n",
      "Epoch 40/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0204 - mse: 1.0204 - val_loss: 0.8609 - val_mse: 0.8609\n",
      "Epoch 41/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0731 - mse: 1.0731 - val_loss: 1.1857 - val_mse: 1.1857\n",
      "Epoch 42/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1831 - mse: 1.1831 - val_loss: 1.2659 - val_mse: 1.2659\n",
      "Epoch 43/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2099 - mse: 1.2099 - val_loss: 1.0714 - val_mse: 1.0714\n",
      "Epoch 44/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1221 - mse: 1.1221 - val_loss: 0.7412 - val_mse: 0.7412\n",
      "Epoch 45/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0108 - mse: 1.0108 - val_loss: 0.4518 - val_mse: 0.4518\n",
      "Epoch 46/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9766 - mse: 0.9766 - val_loss: 0.2889 - val_mse: 0.2889\n",
      "Epoch 47/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0244 - mse: 1.0244 - val_loss: 0.2327 - val_mse: 0.2327\n",
      "Epoch 48/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0740 - mse: 1.0740 - val_loss: 0.2401 - val_mse: 0.2401\n",
      "Epoch 49/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0572 - mse: 1.0572 - val_loss: 0.3090 - val_mse: 0.3090\n",
      "Epoch 50/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9880 - mse: 0.9880 - val_loss: 0.4583 - val_mse: 0.4583\n",
      "Epoch 51/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9341 - mse: 0.9341 - val_loss: 0.6638 - val_mse: 0.6638\n",
      "Epoch 52/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9359 - mse: 0.9359 - val_loss: 0.8392 - val_mse: 0.8392\n",
      "Epoch 53/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9674 - mse: 0.9674 - val_loss: 0.8941 - val_mse: 0.8941\n",
      "Epoch 54/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8069 - val_mse: 0.8069\n",
      "Epoch 55/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9399 - mse: 0.9399 - val_loss: 0.6382 - val_mse: 0.6382\n",
      "Epoch 56/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8949 - mse: 0.8949 - val_loss: 0.4755 - val_mse: 0.4755\n",
      "Epoch 57/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8781 - mse: 0.8781 - val_loss: 0.3717 - val_mse: 0.3717\n",
      "Epoch 58/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8898 - mse: 0.8898 - val_loss: 0.3333 - val_mse: 0.3333\n",
      "Epoch 59/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8981 - mse: 0.8981 - val_loss: 0.3504 - val_mse: 0.3504\n",
      "Epoch 60/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8803 - mse: 0.8803 - val_loss: 0.4194 - val_mse: 0.4194\n",
      "Epoch 61/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8480 - mse: 0.8480 - val_loss: 0.5307 - val_mse: 0.5307\n",
      "Epoch 62/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8277 - mse: 0.8277 - val_loss: 0.6489 - val_mse: 0.6489\n",
      "Epoch 63/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8277 - mse: 0.8277 - val_loss: 0.7213 - val_mse: 0.7213\n",
      "Epoch 64/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8309 - mse: 0.8309 - val_loss: 0.7140 - val_mse: 0.7140\n",
      "Epoch 65/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8191 - mse: 0.8191 - val_loss: 0.6383 - val_mse: 0.6383\n",
      "Epoch 66/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7956 - mse: 0.7956 - val_loss: 0.5385 - val_mse: 0.5385\n",
      "Epoch 67/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7773 - mse: 0.7773 - val_loss: 0.4582 - val_mse: 0.4582\n",
      "Epoch 68/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7722 - mse: 0.7722 - val_loss: 0.4183 - val_mse: 0.4183\n",
      "Epoch 69/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7705 - mse: 0.7705 - val_loss: 0.4214 - val_mse: 0.4214\n",
      "Epoch 70/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7600 - mse: 0.7600 - val_loss: 0.4629 - val_mse: 0.4629\n",
      "Epoch 71/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7417 - mse: 0.7417 - val_loss: 0.5318 - val_mse: 0.5318\n",
      "Epoch 72/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7265 - mse: 0.7265 - val_loss: 0.6040 - val_mse: 0.6040\n",
      "Epoch 73/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7196 - mse: 0.7196 - val_loss: 0.6480 - val_mse: 0.6480\n",
      "Epoch 74/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7148 - mse: 0.7148 - val_loss: 0.6446 - val_mse: 0.6446\n",
      "Epoch 75/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7042 - mse: 0.7042 - val_loss: 0.6005 - val_mse: 0.6005\n",
      "Epoch 76/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6891 - mse: 0.6891 - val_loss: 0.5418 - val_mse: 0.5418\n",
      "Epoch 77/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6767 - mse: 0.6767 - val_loss: 0.4955 - val_mse: 0.4955\n",
      "Epoch 78/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6696 - mse: 0.6696 - val_loss: 0.4760 - val_mse: 0.4760\n",
      "Epoch 79/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6630 - mse: 0.6630 - val_loss: 0.4862 - val_mse: 0.4862\n",
      "Epoch 80/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6524 - mse: 0.6524 - val_loss: 0.5210 - val_mse: 0.5210\n",
      "Epoch 81/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6399 - mse: 0.6399 - val_loss: 0.5679 - val_mse: 0.5679\n",
      "Epoch 82/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6300 - mse: 0.6300 - val_loss: 0.6076 - val_mse: 0.6076\n",
      "Epoch 83/120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6233 - mse: 0.6233 - val_loss: 0.6223 - val_mse: 0.6223\n",
      "Epoch 84/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6158 - mse: 0.6158 - val_loss: 0.6079 - val_mse: 0.6079\n",
      "Epoch 85/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6059 - mse: 0.6059 - val_loss: 0.5755 - val_mse: 0.5755\n",
      "Epoch 86/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5958 - mse: 0.5958 - val_loss: 0.5434 - val_mse: 0.5434\n",
      "Epoch 87/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5881 - mse: 0.5881 - val_loss: 0.5257 - val_mse: 0.5257\n",
      "Epoch 88/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5818 - mse: 0.5818 - val_loss: 0.5279 - val_mse: 0.5279\n",
      "Epoch 89/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5744 - mse: 0.5744 - val_loss: 0.5482 - val_mse: 0.5482\n",
      "Epoch 90/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5659 - mse: 0.5659 - val_loss: 0.5783 - val_mse: 0.5783\n",
      "Epoch 91/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5583 - mse: 0.5583 - val_loss: 0.6055 - val_mse: 0.6055\n",
      "Epoch 92/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5524 - mse: 0.5524 - val_loss: 0.6180 - val_mse: 0.6180\n",
      "Epoch 93/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5467 - mse: 0.5467 - val_loss: 0.6121 - val_mse: 0.6121\n",
      "Epoch 94/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5401 - mse: 0.5401 - val_loss: 0.5942 - val_mse: 0.5942\n",
      "Epoch 95/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5335 - mse: 0.5335 - val_loss: 0.5759 - val_mse: 0.5759\n",
      "Epoch 96/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5282 - mse: 0.5282 - val_loss: 0.5668 - val_mse: 0.5668\n",
      "Epoch 97/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5236 - mse: 0.5236 - val_loss: 0.5710 - val_mse: 0.5710\n",
      "Epoch 98/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5187 - mse: 0.5187 - val_loss: 0.5866 - val_mse: 0.5866\n",
      "Epoch 99/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5136 - mse: 0.5136 - val_loss: 0.6072 - val_mse: 0.6072\n",
      "Epoch 100/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5092 - mse: 0.5092 - val_loss: 0.6241 - val_mse: 0.6241\n",
      "Epoch 101/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5056 - mse: 0.5056 - val_loss: 0.6305 - val_mse: 0.6305\n",
      "Epoch 102/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5020 - mse: 0.5020 - val_loss: 0.6258 - val_mse: 0.6258\n",
      "Epoch 103/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4983 - mse: 0.4983 - val_loss: 0.6155 - val_mse: 0.6155\n",
      "Epoch 104/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4949 - mse: 0.4949 - val_loss: 0.6073 - val_mse: 0.6073\n",
      "Epoch 105/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4922 - mse: 0.4922 - val_loss: 0.6064 - val_mse: 0.6064\n",
      "Epoch 106/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4898 - mse: 0.4898 - val_loss: 0.6140 - val_mse: 0.6140\n",
      "Epoch 107/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4872 - mse: 0.4872 - val_loss: 0.6274 - val_mse: 0.6274\n",
      "Epoch 108/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4849 - mse: 0.4849 - val_loss: 0.6411 - val_mse: 0.6411\n",
      "Epoch 109/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4830 - mse: 0.4830 - val_loss: 0.6497 - val_mse: 0.6497\n",
      "Epoch 110/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4814 - mse: 0.4814 - val_loss: 0.6509 - val_mse: 0.6509\n",
      "Epoch 111/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4798 - mse: 0.4798 - val_loss: 0.6467 - val_mse: 0.6467\n",
      "Epoch 112/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4783 - mse: 0.4783 - val_loss: 0.6418 - val_mse: 0.6418\n",
      "Epoch 113/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4771 - mse: 0.4771 - val_loss: 0.6406 - val_mse: 0.6406\n",
      "Epoch 114/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4762 - mse: 0.4762 - val_loss: 0.6449 - val_mse: 0.6449\n",
      "Epoch 115/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4752 - mse: 0.4752 - val_loss: 0.6536 - val_mse: 0.6536\n",
      "Epoch 116/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4744 - mse: 0.4744 - val_loss: 0.6634 - val_mse: 0.6634\n",
      "Epoch 117/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4737 - mse: 0.4737 - val_loss: 0.6705 - val_mse: 0.6705\n",
      "Epoch 118/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4732 - mse: 0.4732 - val_loss: 0.6729 - val_mse: 0.6729\n",
      "Epoch 119/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4727 - mse: 0.4727 - val_loss: 0.6713 - val_mse: 0.6713\n",
      "Epoch 120/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4723 - mse: 0.4723 - val_loss: 0.6686 - val_mse: 0.6686\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "r2: 0.5035751321197375 meansquarederror: 0.11051244933794446 meanabsoluteerror: 0.2894093075059285 maxerror: 0.4555667660296523\n",
      "Epoch 1/120\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 2.9337 - mse: 2.9337 - val_loss: 42.0300 - val_mse: 42.0300\n",
      "Epoch 2/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 35.8347 - mse: 35.8347 - val_loss: 6.2598 - val_mse: 6.2598\n",
      "Epoch 3/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8549 - mse: 4.8549 - val_loss: 4.1458 - val_mse: 4.1458\n",
      "Epoch 4/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.1906 - mse: 8.1906 - val_loss: 12.9683 - val_mse: 12.9683\n",
      "Epoch 5/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 18.9037 - mse: 18.9037 - val_loss: 6.8386 - val_mse: 6.8386\n",
      "Epoch 6/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 11.5619 - mse: 11.5619 - val_loss: 0.3147 - val_mse: 0.3147\n",
      "Epoch 7/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.4446 - mse: 2.4446 - val_loss: 3.2395 - val_mse: 3.2395\n",
      "Epoch 8/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.6673 - mse: 2.6673 - val_loss: 10.3549 - val_mse: 10.3549\n",
      "Epoch 9/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.0186 - mse: 8.0186 - val_loss: 12.4849 - val_mse: 12.4849\n",
      "Epoch 10/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.7492 - mse: 9.7492 - val_loss: 8.4578 - val_mse: 8.4578\n",
      "Epoch 11/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.4912 - mse: 6.4912 - val_loss: 2.9139 - val_mse: 2.9139\n",
      "Epoch 12/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.4353 - mse: 2.4353 - val_loss: 0.1999 - val_mse: 0.1999\n",
      "Epoch 13/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3999 - mse: 1.3999 - val_loss: 0.8290 - val_mse: 0.8290\n",
      "Epoch 14/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3863 - mse: 3.3863 - val_loss: 2.1528 - val_mse: 2.1528\n",
      "Epoch 15/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.3981 - mse: 5.3981 - val_loss: 2.0161 - val_mse: 2.0161\n",
      "Epoch 16/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.1959 - mse: 5.1959 - val_loss: 0.7741 - val_mse: 0.7741\n",
      "Epoch 17/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2704 - mse: 3.2704 - val_loss: 0.1228 - val_mse: 0.1228\n",
      "Epoch 18/120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.5748 - mse: 1.5748 - val_loss: 1.0485 - val_mse: 1.0485\n",
      "Epoch 19/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3994 - mse: 1.3994 - val_loss: 2.9358 - val_mse: 2.9358\n",
      "Epoch 20/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.4119 - mse: 2.4119 - val_loss: 4.3160 - val_mse: 4.3160\n",
      "Epoch 21/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.3347 - mse: 3.3347 - val_loss: 4.2429 - val_mse: 4.2429\n",
      "Epoch 22/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.2795 - mse: 3.2795 - val_loss: 2.9305 - val_mse: 2.9305\n",
      "Epoch 23/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.3959 - mse: 2.3959 - val_loss: 1.3434 - val_mse: 1.3434\n",
      "Epoch 24/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4984 - mse: 1.4984 - val_loss: 0.3466 - val_mse: 0.3466\n",
      "Epoch 25/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2605 - mse: 1.2605 - val_loss: 0.1295 - val_mse: 0.1295\n",
      "Epoch 26/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.6839 - mse: 1.6839 - val_loss: 0.2796 - val_mse: 0.2796\n",
      "Epoch 27/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.2155 - mse: 2.2155 - val_loss: 0.3266 - val_mse: 0.3266\n",
      "Epoch 28/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.3219 - mse: 2.3219 - val_loss: 0.1888 - val_mse: 0.1888\n",
      "Epoch 29/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.9410 - mse: 1.9410 - val_loss: 0.1448 - val_mse: 0.1448\n",
      "Epoch 30/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4385 - mse: 1.4385 - val_loss: 0.4673 - val_mse: 0.4673\n",
      "Epoch 31/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2147 - mse: 1.2147 - val_loss: 1.1142 - val_mse: 1.1142\n",
      "Epoch 32/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3633 - mse: 1.3633 - val_loss: 1.7414 - val_mse: 1.7414\n",
      "Epoch 33/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.6519 - mse: 1.6519 - val_loss: 1.9842 - val_mse: 1.9842\n",
      "Epoch 34/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.7788 - mse: 1.7788 - val_loss: 1.7318 - val_mse: 1.7318\n",
      "Epoch 35/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.6371 - mse: 1.6371 - val_loss: 1.1735 - val_mse: 1.1735\n",
      "Epoch 36/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.3669 - mse: 1.3669 - val_loss: 0.6207 - val_mse: 0.6207\n",
      "Epoch 37/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.1934 - mse: 1.1934 - val_loss: 0.2798 - val_mse: 0.2798\n",
      "Epoch 38/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2230 - mse: 1.2230 - val_loss: 0.1564 - val_mse: 0.1564\n",
      "Epoch 39/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3718 - mse: 1.3718 - val_loss: 0.1376 - val_mse: 0.1376\n",
      "Epoch 40/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4686 - mse: 1.4686 - val_loss: 0.1437 - val_mse: 0.1437\n",
      "Epoch 41/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4189 - mse: 1.4189 - val_loss: 0.1982 - val_mse: 0.1982\n",
      "Epoch 42/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2740 - mse: 1.2740 - val_loss: 0.3677 - val_mse: 0.3677\n",
      "Epoch 43/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1611 - mse: 1.1611 - val_loss: 0.6539 - val_mse: 0.6539\n",
      "Epoch 44/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.1576 - mse: 1.1576 - val_loss: 0.9536 - val_mse: 0.9536\n",
      "Epoch 45/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2317 - mse: 1.2317 - val_loss: 1.1234 - val_mse: 1.1234\n",
      "Epoch 46/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2889 - mse: 1.2889 - val_loss: 1.0847 - val_mse: 1.0847\n",
      "Epoch 47/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2671 - mse: 1.2671 - val_loss: 0.8753 - val_mse: 0.8753\n",
      "Epoch 48/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1866 - mse: 1.1866 - val_loss: 0.6104 - val_mse: 0.6104\n",
      "Epoch 49/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1178 - mse: 1.1178 - val_loss: 0.3968 - val_mse: 0.3968\n",
      "Epoch 50/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.1094 - mse: 1.1094 - val_loss: 0.2757 - val_mse: 0.2757\n",
      "Epoch 51/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1466 - mse: 1.1466 - val_loss: 0.2321 - val_mse: 0.2321\n",
      "Epoch 52/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1749 - mse: 1.1749 - val_loss: 0.2429 - val_mse: 0.2429\n",
      "Epoch 53/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1577 - mse: 1.1577 - val_loss: 0.3068 - val_mse: 0.3068\n",
      "Epoch 54/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1080 - mse: 1.1080 - val_loss: 0.4297 - val_mse: 0.4297\n",
      "Epoch 55/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0677 - mse: 1.0677 - val_loss: 0.5913 - val_mse: 0.5913\n",
      "Epoch 56/120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0630 - mse: 1.0630 - val_loss: 0.7356 - val_mse: 0.7356\n",
      "Epoch 57/120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0812 - mse: 1.0812 - val_loss: 0.8012 - val_mse: 0.8012\n",
      "Epoch 58/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0899 - mse: 1.0899 - val_loss: 0.7630 - val_mse: 0.7630\n",
      "Epoch 59/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0714 - mse: 1.0714 - val_loss: 0.6482 - val_mse: 0.6482\n",
      "Epoch 60/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0379 - mse: 1.0379 - val_loss: 0.5127 - val_mse: 0.5127\n",
      "Epoch 61/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0148 - mse: 1.0148 - val_loss: 0.4047 - val_mse: 0.4047\n",
      "Epoch 62/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0126 - mse: 1.0126 - val_loss: 0.3444 - val_mse: 0.3444\n",
      "Epoch 63/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0192 - mse: 1.0192 - val_loss: 0.3314 - val_mse: 0.3314\n",
      "Epoch 64/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.0152 - mse: 1.0152 - val_loss: 0.3611 - val_mse: 0.3611\n",
      "Epoch 65/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9955 - mse: 0.9955 - val_loss: 0.4286 - val_mse: 0.4286\n",
      "Epoch 66/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9723 - mse: 0.9723 - val_loss: 0.5197 - val_mse: 0.5197\n",
      "Epoch 67/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9591 - mse: 0.9591 - val_loss: 0.6058 - val_mse: 0.6058\n",
      "Epoch 68/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9569 - mse: 0.9569 - val_loss: 0.6535 - val_mse: 0.6535\n",
      "Epoch 69/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9544 - mse: 0.9544 - val_loss: 0.6449 - val_mse: 0.6449\n",
      "Epoch 70/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9427 - mse: 0.9427 - val_loss: 0.5890 - val_mse: 0.5890\n",
      "Epoch 71/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9242 - mse: 0.9242 - val_loss: 0.5138 - val_mse: 0.5138\n",
      "Epoch 72/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9083 - mse: 0.9083 - val_loss: 0.4482 - val_mse: 0.4482\n",
      "Epoch 73/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8998 - mse: 0.8998 - val_loss: 0.4096 - val_mse: 0.4096\n",
      "Epoch 74/120\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8946 - mse: 0.8946 - val_loss: 0.4029 - val_mse: 0.4029\n",
      "Epoch 75/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8854 - mse: 0.8854 - val_loss: 0.4263 - val_mse: 0.4263\n",
      "Epoch 76/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8705 - mse: 0.8705 - val_loss: 0.4727 - val_mse: 0.4727\n",
      "Epoch 77/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8551 - mse: 0.8551 - val_loss: 0.5283 - val_mse: 0.5283\n",
      "Epoch 78/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8439 - mse: 0.8439 - val_loss: 0.5734 - val_mse: 0.5734\n",
      "Epoch 79/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8360 - mse: 0.8360 - val_loss: 0.5907 - val_mse: 0.5907\n",
      "Epoch 80/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8266 - mse: 0.8266 - val_loss: 0.5753 - val_mse: 0.5753\n",
      "Epoch 81/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8137 - mse: 0.8137 - val_loss: 0.5373 - val_mse: 0.5373\n",
      "Epoch 82/120\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7994 - mse: 0.7994 - val_loss: 0.4945 - val_mse: 0.4945\n",
      "Epoch 83/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7875 - mse: 0.7875 - val_loss: 0.4627 - val_mse: 0.4627\n",
      "Epoch 84/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7780 - mse: 0.7780 - val_loss: 0.4505 - val_mse: 0.4505\n",
      "Epoch 85/120\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.7681 - mse: 0.7681 - val_loss: 0.4594 - val_mse: 0.4594\n",
      "Epoch 86/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7560 - mse: 0.7560 - val_loss: 0.4854 - val_mse: 0.4854\n",
      "Epoch 87/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7429 - mse: 0.7429 - val_loss: 0.5194 - val_mse: 0.5194\n",
      "Epoch 88/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7312 - mse: 0.7312 - val_loss: 0.5490 - val_mse: 0.5490\n",
      "Epoch 89/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7212 - mse: 0.7212 - val_loss: 0.5629 - val_mse: 0.5629\n",
      "Epoch 90/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7110 - mse: 0.7110 - val_loss: 0.5570 - val_mse: 0.5570\n",
      "Epoch 91/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6996 - mse: 0.6996 - val_loss: 0.5363 - val_mse: 0.5363\n",
      "Epoch 92/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6877 - mse: 0.6877 - val_loss: 0.5117 - val_mse: 0.5117\n",
      "Epoch 93/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6768 - mse: 0.6768 - val_loss: 0.4935 - val_mse: 0.4935\n",
      "Epoch 94/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6670 - mse: 0.6670 - val_loss: 0.4880 - val_mse: 0.4880\n",
      "Epoch 95/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6571 - mse: 0.6571 - val_loss: 0.4963 - val_mse: 0.4963\n",
      "Epoch 96/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6466 - mse: 0.6466 - val_loss: 0.5148 - val_mse: 0.5148\n",
      "Epoch 97/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6360 - mse: 0.6360 - val_loss: 0.5366 - val_mse: 0.5366\n",
      "Epoch 98/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6263 - mse: 0.6263 - val_loss: 0.5534 - val_mse: 0.5534\n",
      "Epoch 99/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6173 - mse: 0.6173 - val_loss: 0.5593 - val_mse: 0.5593\n",
      "Epoch 100/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6083 - mse: 0.6083 - val_loss: 0.5534 - val_mse: 0.5534\n",
      "Epoch 101/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5990 - mse: 0.5990 - val_loss: 0.5408 - val_mse: 0.5408\n",
      "Epoch 102/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5900 - mse: 0.5900 - val_loss: 0.5285 - val_mse: 0.5285\n",
      "Epoch 103/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5818 - mse: 0.5818 - val_loss: 0.5225 - val_mse: 0.5225\n",
      "Epoch 104/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5740 - mse: 0.5740 - val_loss: 0.5254 - val_mse: 0.5254\n",
      "Epoch 105/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5663 - mse: 0.5663 - val_loss: 0.5362 - val_mse: 0.5362\n",
      "Epoch 106/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5586 - mse: 0.5586 - val_loss: 0.5509 - val_mse: 0.5509\n",
      "Epoch 107/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5515 - mse: 0.5515 - val_loss: 0.5642 - val_mse: 0.5642\n",
      "Epoch 108/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5449 - mse: 0.5449 - val_loss: 0.5716 - val_mse: 0.5716\n",
      "Epoch 109/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5387 - mse: 0.5387 - val_loss: 0.5715 - val_mse: 0.5715\n",
      "Epoch 110/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5325 - mse: 0.5325 - val_loss: 0.5663 - val_mse: 0.5663\n",
      "Epoch 111/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5267 - mse: 0.5267 - val_loss: 0.5605 - val_mse: 0.5605\n",
      "Epoch 112/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5214 - mse: 0.5214 - val_loss: 0.5582 - val_mse: 0.5582\n",
      "Epoch 113/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5165 - mse: 0.5165 - val_loss: 0.5615 - val_mse: 0.5615\n",
      "Epoch 114/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5118 - mse: 0.5118 - val_loss: 0.5698 - val_mse: 0.5698\n",
      "Epoch 115/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5074 - mse: 0.5074 - val_loss: 0.5807 - val_mse: 0.5807\n",
      "Epoch 116/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5034 - mse: 0.5034 - val_loss: 0.5907 - val_mse: 0.5907\n",
      "Epoch 117/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4998 - mse: 0.4998 - val_loss: 0.5967 - val_mse: 0.5967\n",
      "Epoch 118/120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4964 - mse: 0.4964 - val_loss: 0.5983 - val_mse: 0.5983\n",
      "Epoch 119/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4933 - mse: 0.4933 - val_loss: 0.5970 - val_mse: 0.5970\n",
      "Epoch 120/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4905 - mse: 0.4905 - val_loss: 0.5957 - val_mse: 0.5957\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "r2: 0.40443443386366695 meansquarederror: 0.13258282111471667 meanabsoluteerror: 0.32555378231899756 maxerror: 0.5150268678804508\n",
      "Epoch 1/120\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 2.1737 - mse: 2.1737 - val_loss: 30.8115 - val_mse: 30.8115\n",
      "Epoch 2/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 39.1669 - mse: 39.1669 - val_loss: 1.4950 - val_mse: 1.4950\n",
      "Epoch 3/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.5567 - mse: 4.5567 - val_loss: 12.5266 - val_mse: 12.5266\n",
      "Epoch 4/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.8041 - mse: 9.8041 - val_loss: 25.8848 - val_mse: 25.8848\n",
      "Epoch 5/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 21.2028 - mse: 21.2028 - val_loss: 16.5148 - val_mse: 16.5148\n",
      "Epoch 6/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 13.1075 - mse: 13.1075 - val_loss: 3.5871 - val_mse: 3.5871\n",
      "Epoch 7/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.8976 - mse: 2.8976 - val_loss: 0.3010 - val_mse: 0.3010\n",
      "Epoch 8/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.4261 - mse: 2.4261 - val_loss: 4.1289 - val_mse: 4.1289\n",
      "Epoch 9/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.1266 - mse: 8.1266 - val_loss: 6.2135 - val_mse: 6.2135\n",
      "Epoch 10/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 10.7526 - mse: 10.7526 - val_loss: 3.9741 - val_mse: 3.9741\n",
      "Epoch 11/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 7.9049 - mse: 7.9049 - val_loss: 0.7855 - val_mse: 0.7855\n",
      "Epoch 12/120\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.3419 - mse: 3.3419 - val_loss: 0.4441 - val_mse: 0.4441\n",
      "Epoch 13/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3058 - mse: 1.3058 - val_loss: 3.4232 - val_mse: 3.4232\n",
      "Epoch 14/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.7496 - mse: 2.7496 - val_loss: 6.8339 - val_mse: 6.8339\n",
      "Epoch 15/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.1927 - mse: 5.1927 - val_loss: 7.7201 - val_mse: 7.7201\n",
      "Epoch 16/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.8668 - mse: 5.8668 - val_loss: 5.7322 - val_mse: 5.7322\n",
      "Epoch 17/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3590 - mse: 4.3590 - val_loss: 2.6917 - val_mse: 2.6917\n",
      "Epoch 18/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.2626 - mse: 2.2626 - val_loss: 0.5972 - val_mse: 0.5972\n",
      "Epoch 19/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2813 - mse: 1.2813 - val_loss: 0.1377 - val_mse: 0.1377\n",
      "Epoch 20/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.8194 - mse: 1.8194 - val_loss: 0.6112 - val_mse: 0.6112\n",
      "Epoch 21/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.9635 - mse: 2.9635 - val_loss: 0.9453 - val_mse: 0.9453\n",
      "Epoch 22/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5384 - mse: 3.5384 - val_loss: 0.6965 - val_mse: 0.6965\n",
      "Epoch 23/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.1048 - mse: 3.1048 - val_loss: 0.2286 - val_mse: 0.2286\n",
      "Epoch 24/120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.1142 - mse: 2.1142 - val_loss: 0.1929 - val_mse: 0.1929\n",
      "Epoch 25/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.3611 - mse: 1.3611 - val_loss: 0.8832 - val_mse: 0.8832\n",
      "Epoch 26/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3103 - mse: 1.3103 - val_loss: 1.9718 - val_mse: 1.9718\n",
      "Epoch 27/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.7988 - mse: 1.7988 - val_loss: 2.7883 - val_mse: 2.7883\n",
      "Epoch 28/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2763 - mse: 2.2763 - val_loss: 2.8544 - val_mse: 2.8544\n",
      "Epoch 29/120\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.3131 - mse: 2.3131 - val_loss: 2.2038 - val_mse: 2.2038\n",
      "Epoch 30/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.9152 - mse: 1.9152 - val_loss: 1.2722 - val_mse: 1.2722\n",
      "Epoch 31/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.4309 - mse: 1.4309 - val_loss: 0.5312 - val_mse: 0.5312\n",
      "Epoch 32/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2116 - mse: 1.2116 - val_loss: 0.1848 - val_mse: 0.1848\n",
      "Epoch 33/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.3395 - mse: 1.3395 - val_loss: 0.1315 - val_mse: 0.1315\n",
      "Epoch 34/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.6149 - mse: 1.6149 - val_loss: 0.1543 - val_mse: 0.1543\n",
      "Epoch 35/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.7648 - mse: 1.7648 - val_loss: 0.1396 - val_mse: 0.1396\n",
      "Epoch 36/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.6675 - mse: 1.6675 - val_loss: 0.1460 - val_mse: 0.1460\n",
      "Epoch 37/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4180 - mse: 1.4180 - val_loss: 0.3029 - val_mse: 0.3029\n",
      "Epoch 38/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2147 - mse: 1.2147 - val_loss: 0.6535 - val_mse: 0.6535\n",
      "Epoch 39/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1875 - mse: 1.1875 - val_loss: 1.0832 - val_mse: 1.0832\n",
      "Epoch 40/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.3057 - mse: 1.3057 - val_loss: 1.3887 - val_mse: 1.3887\n",
      "Epoch 41/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4293 - mse: 1.4293 - val_loss: 1.4226 - val_mse: 1.4226\n",
      "Epoch 42/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.4392 - mse: 1.4392 - val_loss: 1.1907 - val_mse: 1.1907\n",
      "Epoch 43/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.3308 - mse: 1.3308 - val_loss: 0.8299 - val_mse: 0.8299\n",
      "Epoch 44/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1976 - mse: 1.1976 - val_loss: 0.5021 - val_mse: 0.5021\n",
      "Epoch 45/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1379 - mse: 1.1379 - val_loss: 0.2956 - val_mse: 0.2956\n",
      "Epoch 46/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1734 - mse: 1.1734 - val_loss: 0.2055 - val_mse: 0.2055\n",
      "Epoch 47/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2443 - mse: 1.2443 - val_loss: 0.1848 - val_mse: 0.1848\n",
      "Epoch 48/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2724 - mse: 1.2724 - val_loss: 0.2084 - val_mse: 0.2084\n",
      "Epoch 49/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2295 - mse: 1.2295 - val_loss: 0.2888 - val_mse: 0.2888\n",
      "Epoch 50/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1524 - mse: 1.1524 - val_loss: 0.4430 - val_mse: 0.4430\n",
      "Epoch 51/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1010 - mse: 1.1010 - val_loss: 0.6479 - val_mse: 0.6479\n",
      "Epoch 52/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1037 - mse: 1.1037 - val_loss: 0.8340 - val_mse: 0.8340\n",
      "Epoch 53/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1381 - mse: 1.1381 - val_loss: 0.9245 - val_mse: 0.9245\n",
      "Epoch 54/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1580 - mse: 1.1580 - val_loss: 0.8853 - val_mse: 0.8853\n",
      "Epoch 55/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1382 - mse: 1.1382 - val_loss: 0.7457 - val_mse: 0.7457\n",
      "Epoch 56/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0929 - mse: 1.0929 - val_loss: 0.5728 - val_mse: 0.5728\n",
      "Epoch 57/120\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0570 - mse: 1.0570 - val_loss: 0.4277 - val_mse: 0.4277\n",
      "Epoch 58/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0511 - mse: 1.0511 - val_loss: 0.3384 - val_mse: 0.3384\n",
      "Epoch 59/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0655 - mse: 1.0655 - val_loss: 0.3040 - val_mse: 0.3040\n",
      "Epoch 60/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0738 - mse: 1.0738 - val_loss: 0.3162 - val_mse: 0.3162\n",
      "Epoch 61/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0596 - mse: 1.0596 - val_loss: 0.3717 - val_mse: 0.3717\n",
      "Epoch 62/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0303 - mse: 1.0303 - val_loss: 0.4660 - val_mse: 0.4660\n",
      "Epoch 63/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0061 - mse: 1.0061 - val_loss: 0.5794 - val_mse: 0.5794\n",
      "Epoch 64/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9990 - mse: 0.9990 - val_loss: 0.6760 - val_mse: 0.6760\n",
      "Epoch 65/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0030 - mse: 1.0030 - val_loss: 0.7200 - val_mse: 0.7200\n",
      "Epoch 66/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0024 - mse: 1.0024 - val_loss: 0.6975 - val_mse: 0.6975\n",
      "Epoch 67/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9885 - mse: 0.9885 - val_loss: 0.6239 - val_mse: 0.6239\n",
      "Epoch 68/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9671 - mse: 0.9671 - val_loss: 0.5326 - val_mse: 0.5326\n",
      "Epoch 69/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9502 - mse: 0.9502 - val_loss: 0.4547 - val_mse: 0.4547\n",
      "Epoch 70/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9434 - mse: 0.9434 - val_loss: 0.4076 - val_mse: 0.4076\n",
      "Epoch 71/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9413 - mse: 0.9413 - val_loss: 0.3956 - val_mse: 0.3956\n",
      "Epoch 72/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9346 - mse: 0.9346 - val_loss: 0.4166 - val_mse: 0.4166\n",
      "Epoch 73/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9201 - mse: 0.9201 - val_loss: 0.4652 - val_mse: 0.4652\n",
      "Epoch 74/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9032 - mse: 0.9032 - val_loss: 0.5299 - val_mse: 0.5299\n",
      "Epoch 75/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8907 - mse: 0.8907 - val_loss: 0.5913 - val_mse: 0.5913\n",
      "Epoch 76/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8836 - mse: 0.8836 - val_loss: 0.6283 - val_mse: 0.6283\n",
      "Epoch 77/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8772 - mse: 0.8772 - val_loss: 0.6287 - val_mse: 0.6287\n",
      "Epoch 78/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8667 - mse: 0.8667 - val_loss: 0.5960 - val_mse: 0.5960\n",
      "Epoch 79/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8524 - mse: 0.8524 - val_loss: 0.5463 - val_mse: 0.5463\n",
      "Epoch 80/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8386 - mse: 0.8386 - val_loss: 0.4989 - val_mse: 0.4989\n",
      "Epoch 81/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8283 - mse: 0.8283 - val_loss: 0.4678 - val_mse: 0.4678\n",
      "Epoch 82/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8202 - mse: 0.8202 - val_loss: 0.4593 - val_mse: 0.4593\n",
      "Epoch 83/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8107 - mse: 0.8107 - val_loss: 0.4732 - val_mse: 0.4732\n",
      "Epoch 84/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7984 - mse: 0.7984 - val_loss: 0.5048 - val_mse: 0.5048\n",
      "Epoch 85/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7852 - mse: 0.7852 - val_loss: 0.5445 - val_mse: 0.5445\n",
      "Epoch 86/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7738 - mse: 0.7738 - val_loss: 0.5794 - val_mse: 0.5794\n",
      "Epoch 87/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7643 - mse: 0.7643 - val_loss: 0.5974 - val_mse: 0.5974\n",
      "Epoch 88/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7547 - mse: 0.7547 - val_loss: 0.5935 - val_mse: 0.5935\n",
      "Epoch 89/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7435 - mse: 0.7435 - val_loss: 0.5719 - val_mse: 0.5719\n",
      "Epoch 90/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7314 - mse: 0.7314 - val_loss: 0.5432 - val_mse: 0.5432\n",
      "Epoch 91/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7200 - mse: 0.7200 - val_loss: 0.5188 - val_mse: 0.5188\n",
      "Epoch 92/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7100 - mse: 0.7100 - val_loss: 0.5066 - val_mse: 0.5066\n",
      "Epoch 93/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7004 - mse: 0.7004 - val_loss: 0.5094 - val_mse: 0.5094\n",
      "Epoch 94/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6900 - mse: 0.6900 - val_loss: 0.5256 - val_mse: 0.5256\n",
      "Epoch 95/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6789 - mse: 0.6789 - val_loss: 0.5496 - val_mse: 0.5496\n",
      "Epoch 96/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6683 - mse: 0.6683 - val_loss: 0.5733 - val_mse: 0.5733\n",
      "Epoch 97/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6586 - mse: 0.6586 - val_loss: 0.5885 - val_mse: 0.5885\n",
      "Epoch 98/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6494 - mse: 0.6494 - val_loss: 0.5908 - val_mse: 0.5908\n",
      "Epoch 99/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6398 - mse: 0.6398 - val_loss: 0.5813 - val_mse: 0.5813\n",
      "Epoch 100/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6299 - mse: 0.6299 - val_loss: 0.5659 - val_mse: 0.5659\n",
      "Epoch 101/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6204 - mse: 0.6204 - val_loss: 0.5519 - val_mse: 0.5519\n",
      "Epoch 102/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6116 - mse: 0.6116 - val_loss: 0.5452 - val_mse: 0.5452\n",
      "Epoch 103/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6033 - mse: 0.6033 - val_loss: 0.5480 - val_mse: 0.5480\n",
      "Epoch 104/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5948 - mse: 0.5948 - val_loss: 0.5594 - val_mse: 0.5594\n",
      "Epoch 105/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5863 - mse: 0.5863 - val_loss: 0.5754 - val_mse: 0.5754\n",
      "Epoch 106/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5782 - mse: 0.5782 - val_loss: 0.5906 - val_mse: 0.5906\n",
      "Epoch 107/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5707 - mse: 0.5707 - val_loss: 0.6000 - val_mse: 0.6000\n",
      "Epoch 108/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5635 - mse: 0.5635 - val_loss: 0.6014 - val_mse: 0.6014\n",
      "Epoch 109/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5564 - mse: 0.5564 - val_loss: 0.5962 - val_mse: 0.5962\n",
      "Epoch 110/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5495 - mse: 0.5495 - val_loss: 0.5884 - val_mse: 0.5884\n",
      "Epoch 111/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5429 - mse: 0.5429 - val_loss: 0.5828 - val_mse: 0.5828\n",
      "Epoch 112/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5369 - mse: 0.5369 - val_loss: 0.5824 - val_mse: 0.5824\n",
      "Epoch 113/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5312 - mse: 0.5312 - val_loss: 0.5880 - val_mse: 0.5880\n",
      "Epoch 114/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5256 - mse: 0.5256 - val_loss: 0.5982 - val_mse: 0.5982\n",
      "Epoch 115/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5203 - mse: 0.5203 - val_loss: 0.6096 - val_mse: 0.6096\n",
      "Epoch 116/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5154 - mse: 0.5154 - val_loss: 0.6188 - val_mse: 0.6188\n",
      "Epoch 117/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5110 - mse: 0.5110 - val_loss: 0.6234 - val_mse: 0.6234\n",
      "Epoch 118/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5067 - mse: 0.5067 - val_loss: 0.6234 - val_mse: 0.6234\n",
      "Epoch 119/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5027 - mse: 0.5027 - val_loss: 0.6207 - val_mse: 0.6207\n",
      "Epoch 120/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4990 - mse: 0.4990 - val_loss: 0.6183 - val_mse: 0.6183\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "r2: 0.4226006436649332 meansquarederror: 0.12853872004279146 meanabsoluteerror: 0.32043951019382094 maxerror: 0.49545091418940634\n",
      "Epoch 1/120\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 2.4738 - mse: 2.4738 - val_loss: 31.7983 - val_mse: 31.7983\n",
      "Epoch 2/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 40.2691 - mse: 40.2691 - val_loss: 1.6721 - val_mse: 1.6721\n",
      "Epoch 3/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.8045 - mse: 4.8045 - val_loss: 12.4311 - val_mse: 12.4311\n",
      "Epoch 4/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 9.7311 - mse: 9.7311 - val_loss: 26.3157 - val_mse: 26.3157\n",
      "Epoch 5/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 21.6043 - mse: 21.6043 - val_loss: 16.8296 - val_mse: 16.8296\n",
      "Epoch 6/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 13.3844 - mse: 13.3844 - val_loss: 3.5670 - val_mse: 3.5670\n",
      "Epoch 7/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.8774 - mse: 2.8774 - val_loss: 0.3591 - val_mse: 0.3591\n",
      "Epoch 8/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.5408 - mse: 2.5408 - val_loss: 4.4505 - val_mse: 4.4505\n",
      "Epoch 9/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 8.5285 - mse: 8.5285 - val_loss: 6.4467 - val_mse: 6.4467\n",
      "Epoch 10/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 11.0295 - mse: 11.0295 - val_loss: 3.8876 - val_mse: 3.8876\n",
      "Epoch 11/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.7795 - mse: 7.7795 - val_loss: 0.6309 - val_mse: 0.6309\n",
      "Epoch 12/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.0521 - mse: 3.0521 - val_loss: 0.6563 - val_mse: 0.6563\n",
      "Epoch 13/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.3123 - mse: 1.3123 - val_loss: 4.0573 - val_mse: 4.0573\n",
      "Epoch 14/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.1705 - mse: 3.1705 - val_loss: 7.4447 - val_mse: 7.4447\n",
      "Epoch 15/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.6549 - mse: 5.6549 - val_loss: 7.8615 - val_mse: 7.8615\n",
      "Epoch 16/120\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.9718 - mse: 5.9718 - val_loss: 5.3811 - val_mse: 5.3811\n",
      "Epoch 17/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0955 - mse: 4.0955 - val_loss: 2.2002 - val_mse: 2.2002\n",
      "Epoch 18/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.9621 - mse: 1.9621 - val_loss: 0.3526 - val_mse: 0.3526\n",
      "Epoch 19/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2833 - mse: 1.2833 - val_loss: 0.2396 - val_mse: 0.2396\n",
      "Epoch 20/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.1588 - mse: 2.1588 - val_loss: 0.8401 - val_mse: 0.8401\n",
      "Epoch 21/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3560 - mse: 3.3560 - val_loss: 1.0307 - val_mse: 1.0307\n",
      "Epoch 22/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6659 - mse: 3.6659 - val_loss: 0.5931 - val_mse: 0.5931\n",
      "Epoch 23/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.9029 - mse: 2.9029 - val_loss: 0.1468 - val_mse: 0.1468\n",
      "Epoch 24/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8071 - mse: 1.8071 - val_loss: 0.3848 - val_mse: 0.3848\n",
      "Epoch 25/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2474 - mse: 1.2474 - val_loss: 1.3860 - val_mse: 1.3860\n",
      "Epoch 26/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4979 - mse: 1.4979 - val_loss: 2.5430 - val_mse: 2.5430\n",
      "Epoch 27/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.1217 - mse: 2.1217 - val_loss: 3.0971 - val_mse: 3.0971\n",
      "Epoch 28/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.4638 - mse: 2.4638 - val_loss: 2.7448 - val_mse: 2.7448\n",
      "Epoch 29/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.2361 - mse: 2.2361 - val_loss: 1.7937 - val_mse: 1.7937\n",
      "Epoch 30/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.6796 - mse: 1.6796 - val_loss: 0.8327 - val_mse: 0.8327\n",
      "Epoch 31/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2622 - mse: 1.2622 - val_loss: 0.2735 - val_mse: 0.2735\n",
      "Epoch 32/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.2535 - mse: 1.2535 - val_loss: 0.1323 - val_mse: 0.1323\n",
      "Epoch 33/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.5426 - mse: 1.5426 - val_loss: 0.1649 - val_mse: 0.1649\n",
      "Epoch 34/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.7984 - mse: 1.7984 - val_loss: 0.1635 - val_mse: 0.1635\n",
      "Epoch 35/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.7826 - mse: 1.7826 - val_loss: 0.1349 - val_mse: 0.1349\n",
      "Epoch 36/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.5267 - mse: 1.5267 - val_loss: 0.2352 - val_mse: 0.2352\n",
      "Epoch 37/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.2567 - mse: 1.2567 - val_loss: 0.5682 - val_mse: 0.5682\n",
      "Epoch 38/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1728 - mse: 1.1728 - val_loss: 1.0457 - val_mse: 1.0457\n",
      "Epoch 39/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2873 - mse: 1.2873 - val_loss: 1.4324 - val_mse: 1.4324\n",
      "Epoch 40/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4450 - mse: 1.4450 - val_loss: 1.5236 - val_mse: 1.5236\n",
      "Epoch 41/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4828 - mse: 1.4828 - val_loss: 1.2933 - val_mse: 1.2933\n",
      "Epoch 42/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3698 - mse: 1.3698 - val_loss: 0.8922 - val_mse: 0.8922\n",
      "Epoch 43/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2111 - mse: 1.2111 - val_loss: 0.5195 - val_mse: 0.5195\n",
      "Epoch 44/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1338 - mse: 1.1338 - val_loss: 0.2891 - val_mse: 0.2891\n",
      "Epoch 45/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1738 - mse: 1.1738 - val_loss: 0.1948 - val_mse: 0.1948\n",
      "Epoch 46/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2596 - mse: 1.2596 - val_loss: 0.1758 - val_mse: 0.1758\n",
      "Epoch 47/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2928 - mse: 1.2928 - val_loss: 0.2009 - val_mse: 0.2009\n",
      "Epoch 48/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.2393 - mse: 1.2393 - val_loss: 0.2902 - val_mse: 0.2902\n",
      "Epoch 49/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1481 - mse: 1.1481 - val_loss: 0.4668 - val_mse: 0.4668\n",
      "Epoch 50/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0944 - mse: 1.0944 - val_loss: 0.6992 - val_mse: 0.6992\n",
      "Epoch 51/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1074 - mse: 1.1074 - val_loss: 0.8984 - val_mse: 0.8984\n",
      "Epoch 52/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1514 - mse: 1.1514 - val_loss: 0.9740 - val_mse: 0.9740\n",
      "Epoch 53/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1686 - mse: 1.1686 - val_loss: 0.8982 - val_mse: 0.8982\n",
      "Epoch 54/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1362 - mse: 1.1362 - val_loss: 0.7213 - val_mse: 0.7213\n",
      "Epoch 55/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0815 - mse: 1.0815 - val_loss: 0.5286 - val_mse: 0.5286\n",
      "Epoch 56/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0487 - mse: 1.0487 - val_loss: 0.3847 - val_mse: 0.3847\n",
      "Epoch 57/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0538 - mse: 1.0538 - val_loss: 0.3085 - val_mse: 0.3085\n",
      "Epoch 58/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0745 - mse: 1.0745 - val_loss: 0.2906 - val_mse: 0.2906\n",
      "Epoch 59/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0774 - mse: 1.0774 - val_loss: 0.3220 - val_mse: 0.3220\n",
      "Epoch 60/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0521 - mse: 1.0521 - val_loss: 0.4019 - val_mse: 0.4019\n",
      "Epoch 61/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0174 - mse: 1.0174 - val_loss: 0.5212 - val_mse: 0.5212\n",
      "Epoch 62/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9984 - mse: 0.9984 - val_loss: 0.6472 - val_mse: 0.6472\n",
      "Epoch 63/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0004 - mse: 1.0004 - val_loss: 0.7321 - val_mse: 0.7321\n",
      "Epoch 64/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0071 - mse: 1.0071 - val_loss: 0.7422 - val_mse: 0.7422\n",
      "Epoch 65/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0001 - mse: 1.0001 - val_loss: 0.6793 - val_mse: 0.6793\n",
      "Epoch 66/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9780 - mse: 0.9780 - val_loss: 0.5778 - val_mse: 0.5778\n",
      "Epoch 67/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9552 - mse: 0.9552 - val_loss: 0.4796 - val_mse: 0.4796\n",
      "Epoch 68/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9443 - mse: 0.9443 - val_loss: 0.4127 - val_mse: 0.4127\n",
      "Epoch 69/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9435 - mse: 0.9435 - val_loss: 0.3860 - val_mse: 0.3860\n",
      "Epoch 70/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9406 - mse: 0.9406 - val_loss: 0.3982 - val_mse: 0.3982\n",
      "Epoch 71/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9278 - mse: 0.9278 - val_loss: 0.4447 - val_mse: 0.4447\n",
      "Epoch 72/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9089 - mse: 0.9089 - val_loss: 0.5153 - val_mse: 0.5153\n",
      "Epoch 73/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8938 - mse: 0.8938 - val_loss: 0.5891 - val_mse: 0.5891\n",
      "Epoch 74/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8864 - mse: 0.8864 - val_loss: 0.6397 - val_mse: 0.6397\n",
      "Epoch 75/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8816 - mse: 0.8816 - val_loss: 0.6484 - val_mse: 0.6484\n",
      "Epoch 76/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8723 - mse: 0.8723 - val_loss: 0.6154 - val_mse: 0.6154\n",
      "Epoch 77/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8574 - mse: 0.8574 - val_loss: 0.5589 - val_mse: 0.5589\n",
      "Epoch 78/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8423 - mse: 0.8423 - val_loss: 0.5029 - val_mse: 0.5029\n",
      "Epoch 79/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8317 - mse: 0.8317 - val_loss: 0.4652 - val_mse: 0.4652\n",
      "Epoch 80/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8243 - mse: 0.8243 - val_loss: 0.4536 - val_mse: 0.4536\n",
      "Epoch 81/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8155 - mse: 0.8155 - val_loss: 0.4684 - val_mse: 0.4684\n",
      "Epoch 82/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8029 - mse: 0.8029 - val_loss: 0.5043 - val_mse: 0.5043\n",
      "Epoch 83/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7890 - mse: 0.7890 - val_loss: 0.5503 - val_mse: 0.5503\n",
      "Epoch 84/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7775 - mse: 0.7775 - val_loss: 0.5905 - val_mse: 0.5905\n",
      "Epoch 85/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7685 - mse: 0.7685 - val_loss: 0.6102 - val_mse: 0.6102\n",
      "Epoch 86/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7592 - mse: 0.7592 - val_loss: 0.6036 - val_mse: 0.6036\n",
      "Epoch 87/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7478 - mse: 0.7478 - val_loss: 0.5766 - val_mse: 0.5766\n",
      "Epoch 88/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7352 - mse: 0.7352 - val_loss: 0.5428 - val_mse: 0.5428\n",
      "Epoch 89/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7238 - mse: 0.7238 - val_loss: 0.5158 - val_mse: 0.5158\n",
      "Epoch 90/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7142 - mse: 0.7142 - val_loss: 0.5043 - val_mse: 0.5043\n",
      "Epoch 91/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7048 - mse: 0.7048 - val_loss: 0.5106 - val_mse: 0.5106\n",
      "Epoch 92/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6940 - mse: 0.6940 - val_loss: 0.5319 - val_mse: 0.5319\n",
      "Epoch 93/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6826 - mse: 0.6826 - val_loss: 0.5607 - val_mse: 0.5607\n",
      "Epoch 94/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6720 - mse: 0.6720 - val_loss: 0.5867 - val_mse: 0.5867\n",
      "Epoch 95/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6627 - mse: 0.6627 - val_loss: 0.6006 - val_mse: 0.6006\n",
      "Epoch 96/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6535 - mse: 0.6535 - val_loss: 0.5984 - val_mse: 0.5984\n",
      "Epoch 97/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6436 - mse: 0.6436 - val_loss: 0.5836 - val_mse: 0.5836\n",
      "Epoch 98/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6334 - mse: 0.6334 - val_loss: 0.5646 - val_mse: 0.5646\n",
      "Epoch 99/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6240 - mse: 0.6240 - val_loss: 0.5503 - val_mse: 0.5503\n",
      "Epoch 100/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6154 - mse: 0.6154 - val_loss: 0.5462 - val_mse: 0.5462\n",
      "Epoch 101/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6070 - mse: 0.6070 - val_loss: 0.5536 - val_mse: 0.5536\n",
      "Epoch 102/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5982 - mse: 0.5982 - val_loss: 0.5698 - val_mse: 0.5698\n",
      "Epoch 103/120\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5895 - mse: 0.5895 - val_loss: 0.5889 - val_mse: 0.5889\n",
      "Epoch 104/120\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5814 - mse: 0.5814 - val_loss: 0.6041 - val_mse: 0.6041\n",
      "Epoch 105/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5740 - mse: 0.5740 - val_loss: 0.6104 - val_mse: 0.6104\n",
      "Epoch 106/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5667 - mse: 0.5667 - val_loss: 0.6071 - val_mse: 0.6071\n",
      "Epoch 107/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5593 - mse: 0.5593 - val_loss: 0.5980 - val_mse: 0.5980\n",
      "Epoch 108/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5522 - mse: 0.5522 - val_loss: 0.5888 - val_mse: 0.5888\n",
      "Epoch 109/120\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5458 - mse: 0.5458 - val_loss: 0.5847 - val_mse: 0.5847\n",
      "Epoch 110/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5397 - mse: 0.5397 - val_loss: 0.5879 - val_mse: 0.5879\n",
      "Epoch 111/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5338 - mse: 0.5338 - val_loss: 0.5977 - val_mse: 0.5977\n",
      "Epoch 112/120\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5280 - mse: 0.5280 - val_loss: 0.6109 - val_mse: 0.6109\n",
      "Epoch 113/120\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5226 - mse: 0.5226 - val_loss: 0.6228 - val_mse: 0.6228\n",
      "Epoch 114/120\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5177 - mse: 0.5177 - val_loss: 0.6299 - val_mse: 0.6299\n",
      "Epoch 115/120\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5131 - mse: 0.5131 - val_loss: 0.6308 - val_mse: 0.6308\n",
      "Epoch 116/120\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5087 - mse: 0.5087 - val_loss: 0.6274 - val_mse: 0.6274\n",
      "Epoch 117/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5045 - mse: 0.5045 - val_loss: 0.6233 - val_mse: 0.6233\n",
      "Epoch 118/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5007 - mse: 0.5007 - val_loss: 0.6218 - val_mse: 0.6218\n",
      "Epoch 119/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4973 - mse: 0.4973 - val_loss: 0.6250 - val_mse: 0.6250\n",
      "Epoch 120/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4941 - mse: 0.4941 - val_loss: 0.6323 - val_mse: 0.6323\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "r2: 0.44183099108170387 meansquarederror: 0.12425772420202803 meanabsoluteerror: 0.31338006982782923 maxerror: 0.48488762749449776\n",
      "Epoch 1/120\n",
      "1/1 [==============================] - 1s 637ms/step - loss: 1.3535 - mse: 1.3535 - val_loss: 23.5396 - val_mse: 23.5396\n",
      "Epoch 2/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 19.2520 - mse: 19.2520 - val_loss: 0.3943 - val_mse: 0.3943\n",
      "Epoch 3/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.4208 - mse: 2.4208 - val_loss: 10.8593 - val_mse: 10.8593\n",
      "Epoch 4/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 16.1753 - mse: 16.1753 - val_loss: 4.9959 - val_mse: 4.9959\n",
      "Epoch 5/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 9.0202 - mse: 9.0202 - val_loss: 0.1980 - val_mse: 0.1980\n",
      "Epoch 6/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2930 - mse: 1.2930 - val_loss: 6.4764 - val_mse: 6.4764\n",
      "Epoch 7/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.8723 - mse: 4.8723 - val_loss: 11.6546 - val_mse: 11.6546\n",
      "Epoch 8/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 8.9987 - mse: 8.9987 - val_loss: 8.2315 - val_mse: 8.2315\n",
      "Epoch 9/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.2224 - mse: 6.2224 - val_loss: 2.2334 - val_mse: 2.2334\n",
      "Epoch 10/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.8836 - mse: 1.8836 - val_loss: 0.1527 - val_mse: 0.1527\n",
      "Epoch 11/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.6549 - mse: 1.6549 - val_loss: 1.5947 - val_mse: 1.5947\n",
      "Epoch 12/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.3736 - mse: 4.3736 - val_loss: 2.2935 - val_mse: 2.2935\n",
      "Epoch 13/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.3705 - mse: 5.3705 - val_loss: 1.0560 - val_mse: 1.0560\n",
      "Epoch 14/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.5237 - mse: 3.5237 - val_loss: 0.1434 - val_mse: 0.1434\n",
      "Epoch 15/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4420 - mse: 1.4420 - val_loss: 1.3534 - val_mse: 1.3534\n",
      "Epoch 16/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.3803 - mse: 1.3803 - val_loss: 3.6701 - val_mse: 3.6701\n",
      "Epoch 17/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.7675 - mse: 2.7675 - val_loss: 4.7026 - val_mse: 4.7026\n",
      "Epoch 18/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.4884 - mse: 3.4884 - val_loss: 3.5947 - val_mse: 3.5947\n",
      "Epoch 19/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.7052 - mse: 2.7052 - val_loss: 1.5909 - val_mse: 1.5909\n",
      "Epoch 20/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.4722 - mse: 1.4722 - val_loss: 0.3231 - val_mse: 0.3231\n",
      "Epoch 21/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.1216 - mse: 1.1216 - val_loss: 0.2028 - val_mse: 0.2028\n",
      "Epoch 22/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.7543 - mse: 1.7543 - val_loss: 0.4539 - val_mse: 0.4539\n",
      "Epoch 23/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.3711 - mse: 2.3711 - val_loss: 0.3806 - val_mse: 0.3806\n",
      "Epoch 24/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.2045 - mse: 2.2045 - val_loss: 0.1594 - val_mse: 0.1594\n",
      "Epoch 25/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.5095 - mse: 1.5095 - val_loss: 0.3914 - val_mse: 0.3914\n",
      "Epoch 26/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0704 - mse: 1.0704 - val_loss: 1.2153 - val_mse: 1.2153\n",
      "Epoch 27/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2515 - mse: 1.2515 - val_loss: 2.0559 - val_mse: 2.0559\n",
      "Epoch 28/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.6762 - mse: 1.6762 - val_loss: 2.2361 - val_mse: 2.2361\n",
      "Epoch 29/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.7751 - mse: 1.7751 - val_loss: 1.6676 - val_mse: 1.6676\n",
      "Epoch 30/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.4492 - mse: 1.4492 - val_loss: 0.8519 - val_mse: 0.8519\n",
      "Epoch 31/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0885 - mse: 1.0885 - val_loss: 0.3168 - val_mse: 0.3168\n",
      "Epoch 32/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0539 - mse: 1.0539 - val_loss: 0.1666 - val_mse: 0.1666\n",
      "Epoch 33/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.2843 - mse: 1.2843 - val_loss: 0.1712 - val_mse: 0.1712\n",
      "Epoch 34/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4371 - mse: 1.4371 - val_loss: 0.1664 - val_mse: 0.1664\n",
      "Epoch 35/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.3208 - mse: 1.3208 - val_loss: 0.2414 - val_mse: 0.2414\n",
      "Epoch 36/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0818 - mse: 1.0818 - val_loss: 0.5406 - val_mse: 0.5406\n",
      "Epoch 37/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9815 - mse: 0.9815 - val_loss: 0.9897 - val_mse: 0.9897\n",
      "Epoch 38/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0808 - mse: 1.0808 - val_loss: 1.3041 - val_mse: 1.3041\n",
      "Epoch 39/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.2033 - mse: 1.2033 - val_loss: 1.2659 - val_mse: 1.2659\n",
      "Epoch 40/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.1778 - mse: 1.1778 - val_loss: 0.9323 - val_mse: 0.9323\n",
      "Epoch 41/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0355 - mse: 1.0355 - val_loss: 0.5503 - val_mse: 0.5503\n",
      "Epoch 42/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9400 - mse: 0.9400 - val_loss: 0.3106 - val_mse: 0.3106\n",
      "Epoch 43/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9731 - mse: 0.9731 - val_loss: 0.2249 - val_mse: 0.2249\n",
      "Epoch 44/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0515 - mse: 1.0515 - val_loss: 0.2210 - val_mse: 0.2210\n",
      "Epoch 45/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.0527 - mse: 1.0527 - val_loss: 0.2815 - val_mse: 0.2815\n",
      "Epoch 46/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9686 - mse: 0.9686 - val_loss: 0.4436 - val_mse: 0.4436\n",
      "Epoch 47/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8966 - mse: 0.8966 - val_loss: 0.6872 - val_mse: 0.6872\n",
      "Epoch 48/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9036 - mse: 0.9036 - val_loss: 0.8902 - val_mse: 0.8902\n",
      "Epoch 49/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9488 - mse: 0.9488 - val_loss: 0.9249 - val_mse: 0.9249\n",
      "Epoch 50/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9508 - mse: 0.9508 - val_loss: 0.7814 - val_mse: 0.7814\n",
      "Epoch 51/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8967 - mse: 0.8967 - val_loss: 0.5676 - val_mse: 0.5676\n",
      "Epoch 52/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8470 - mse: 0.8470 - val_loss: 0.4004 - val_mse: 0.4004\n",
      "Epoch 53/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8471 - mse: 0.8471 - val_loss: 0.3207 - val_mse: 0.3207\n",
      "Epoch 54/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8709 - mse: 0.8709 - val_loss: 0.3141 - val_mse: 0.3141\n",
      "Epoch 55/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8664 - mse: 0.8664 - val_loss: 0.3705 - val_mse: 0.3705\n",
      "Epoch 56/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8273 - mse: 0.8273 - val_loss: 0.4895 - val_mse: 0.4895\n",
      "Epoch 57/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7946 - mse: 0.7946 - val_loss: 0.6373 - val_mse: 0.6373\n",
      "Epoch 58/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7940 - mse: 0.7940 - val_loss: 0.7388 - val_mse: 0.7388\n",
      "Epoch 59/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8043 - mse: 0.8043 - val_loss: 0.7349 - val_mse: 0.7349\n",
      "Epoch 60/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7929 - mse: 0.7929 - val_loss: 0.6374 - val_mse: 0.6374\n",
      "Epoch 61/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7627 - mse: 0.7627 - val_loss: 0.5136 - val_mse: 0.5136\n",
      "Epoch 62/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7423 - mse: 0.7423 - val_loss: 0.4242 - val_mse: 0.4242\n",
      "Epoch 63/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7421 - mse: 0.7421 - val_loss: 0.3901 - val_mse: 0.3901\n",
      "Epoch 64/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7426 - mse: 0.7426 - val_loss: 0.4087 - val_mse: 0.4087\n",
      "Epoch 65/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7267 - mse: 0.7267 - val_loss: 0.4734 - val_mse: 0.4734\n",
      "Epoch 66/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7039 - mse: 0.7039 - val_loss: 0.5652 - val_mse: 0.5652\n",
      "Epoch 67/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6923 - mse: 0.6923 - val_loss: 0.6419 - val_mse: 0.6419\n",
      "Epoch 68/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6910 - mse: 0.6910 - val_loss: 0.6614 - val_mse: 0.6614\n",
      "Epoch 69/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6842 - mse: 0.6842 - val_loss: 0.6170 - val_mse: 0.6170\n",
      "Epoch 70/120\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6673 - mse: 0.6673 - val_loss: 0.5426 - val_mse: 0.5426\n",
      "Epoch 71/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6517 - mse: 0.6517 - val_loss: 0.4803 - val_mse: 0.4803\n",
      "Epoch 72/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6454 - mse: 0.6454 - val_loss: 0.4532 - val_mse: 0.4532\n",
      "Epoch 73/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6412 - mse: 0.6412 - val_loss: 0.4648 - val_mse: 0.4648\n",
      "Epoch 74/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6301 - mse: 0.6301 - val_loss: 0.5091 - val_mse: 0.5091\n",
      "Epoch 75/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6158 - mse: 0.6158 - val_loss: 0.5687 - val_mse: 0.5687\n",
      "Epoch 76/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6067 - mse: 0.6067 - val_loss: 0.6146 - val_mse: 0.6146\n",
      "Epoch 77/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6020 - mse: 0.6020 - val_loss: 0.6224 - val_mse: 0.6224\n",
      "Epoch 78/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5945 - mse: 0.5945 - val_loss: 0.5919 - val_mse: 0.5919\n",
      "Epoch 79/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5831 - mse: 0.5831 - val_loss: 0.5466 - val_mse: 0.5466\n",
      "Epoch 80/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5736 - mse: 0.5736 - val_loss: 0.5127 - val_mse: 0.5127\n",
      "Epoch 81/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5682 - mse: 0.5682 - val_loss: 0.5041 - val_mse: 0.5041\n",
      "Epoch 82/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5625 - mse: 0.5625 - val_loss: 0.5218 - val_mse: 0.5218\n",
      "Epoch 83/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5539 - mse: 0.5539 - val_loss: 0.5579 - val_mse: 0.5579\n",
      "Epoch 84/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5455 - mse: 0.5455 - val_loss: 0.5954 - val_mse: 0.5954\n",
      "Epoch 85/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5402 - mse: 0.5402 - val_loss: 0.6148 - val_mse: 0.6148\n",
      "Epoch 86/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5357 - mse: 0.5357 - val_loss: 0.6077 - val_mse: 0.6077\n",
      "Epoch 87/120\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5292 - mse: 0.5292 - val_loss: 0.5831 - val_mse: 0.5831\n",
      "Epoch 88/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5225 - mse: 0.5225 - val_loss: 0.5588 - val_mse: 0.5588\n",
      "Epoch 89/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5179 - mse: 0.5179 - val_loss: 0.5487 - val_mse: 0.5487\n",
      "Epoch 90/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5142 - mse: 0.5142 - val_loss: 0.5570 - val_mse: 0.5570\n",
      "Epoch 91/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5094 - mse: 0.5094 - val_loss: 0.5797 - val_mse: 0.5797\n",
      "Epoch 92/120\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5044 - mse: 0.5044 - val_loss: 0.6060 - val_mse: 0.6060\n",
      "Epoch 93/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5008 - mse: 0.5008 - val_loss: 0.6227 - val_mse: 0.6227\n",
      "Epoch 94/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4981 - mse: 0.4981 - val_loss: 0.6225 - val_mse: 0.6225\n",
      "Epoch 95/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4946 - mse: 0.4946 - val_loss: 0.6096 - val_mse: 0.6096\n",
      "Epoch 96/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4910 - mse: 0.4910 - val_loss: 0.5955 - val_mse: 0.5955\n",
      "Epoch 97/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4885 - mse: 0.4885 - val_loss: 0.5901 - val_mse: 0.5901\n",
      "Epoch 98/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4866 - mse: 0.4866 - val_loss: 0.5969 - val_mse: 0.5969\n",
      "Epoch 99/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4843 - mse: 0.4843 - val_loss: 0.6132 - val_mse: 0.6132\n",
      "Epoch 100/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4819 - mse: 0.4819 - val_loss: 0.6313 - val_mse: 0.6313\n",
      "Epoch 101/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4804 - mse: 0.4804 - val_loss: 0.6424 - val_mse: 0.6424\n",
      "Epoch 102/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4792 - mse: 0.4792 - val_loss: 0.6426 - val_mse: 0.6426\n",
      "Epoch 103/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4777 - mse: 0.4777 - val_loss: 0.6352 - val_mse: 0.6352\n",
      "Epoch 104/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4763 - mse: 0.4763 - val_loss: 0.6280 - val_mse: 0.6280\n",
      "Epoch 105/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4754 - mse: 0.4754 - val_loss: 0.6272 - val_mse: 0.6272\n",
      "Epoch 106/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4748 - mse: 0.4748 - val_loss: 0.6345 - val_mse: 0.6345\n",
      "Epoch 107/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4739 - mse: 0.4739 - val_loss: 0.6469 - val_mse: 0.6469\n",
      "Epoch 108/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4731 - mse: 0.4731 - val_loss: 0.6586 - val_mse: 0.6586\n",
      "Epoch 109/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4728 - mse: 0.4728 - val_loss: 0.6643 - val_mse: 0.6643\n",
      "Epoch 110/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4725 - mse: 0.4725 - val_loss: 0.6629 - val_mse: 0.6629\n",
      "Epoch 111/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4720 - mse: 0.4720 - val_loss: 0.6582 - val_mse: 0.6582\n",
      "Epoch 112/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4717 - mse: 0.4717 - val_loss: 0.6553 - val_mse: 0.6553\n",
      "Epoch 113/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4716 - mse: 0.4716 - val_loss: 0.6574 - val_mse: 0.6574\n",
      "Epoch 114/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4715 - mse: 0.4715 - val_loss: 0.6644 - val_mse: 0.6644\n",
      "Epoch 115/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4712 - mse: 0.4712 - val_loss: 0.6730 - val_mse: 0.6730\n",
      "Epoch 116/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4711 - mse: 0.4711 - val_loss: 0.6791 - val_mse: 0.6791\n",
      "Epoch 117/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4712 - mse: 0.4712 - val_loss: 0.6803 - val_mse: 0.6803\n",
      "Epoch 118/120\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4711 - mse: 0.4711 - val_loss: 0.6777 - val_mse: 0.6777\n",
      "Epoch 119/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4710 - mse: 0.4710 - val_loss: 0.6747 - val_mse: 0.6747\n",
      "Epoch 120/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4710 - mse: 0.4710 - val_loss: 0.6743 - val_mse: 0.6743\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "r2: 0.4988712917137288 meansquarederror: 0.11155960260966208 meanabsoluteerror: 0.28846661678812 maxerror: 0.4499197431172832\n",
      "Epoch 1/120\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 1.7386 - mse: 1.7386 - val_loss: 34.2253 - val_mse: 34.2253\n",
      "Epoch 2/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 43.1237 - mse: 43.1237 - val_loss: 1.4202 - val_mse: 1.4202\n",
      "Epoch 3/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.4477 - mse: 4.4477 - val_loss: 13.9258 - val_mse: 13.9258\n",
      "Epoch 4/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 10.9937 - mse: 10.9937 - val_loss: 28.6467 - val_mse: 28.6467\n",
      "Epoch 5/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 23.7165 - mse: 23.7165 - val_loss: 19.5289 - val_mse: 19.5289\n",
      "Epoch 6/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 15.7197 - mse: 15.7197 - val_loss: 5.2507 - val_mse: 5.2507\n",
      "Epoch 7/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.0607 - mse: 4.0607 - val_loss: 0.1238 - val_mse: 0.1238\n",
      "Epoch 8/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.8513 - mse: 1.8513 - val_loss: 3.6689 - val_mse: 3.6689\n",
      "Epoch 9/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.5544 - mse: 7.5544 - val_loss: 6.8513 - val_mse: 6.8513\n",
      "Epoch 10/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 11.5869 - mse: 11.5869 - val_loss: 5.3554 - val_mse: 5.3554\n",
      "Epoch 11/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 9.7110 - mse: 9.7110 - val_loss: 1.7178 - val_mse: 1.7178\n",
      "Epoch 12/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8278 - mse: 4.8278 - val_loss: 0.1256 - val_mse: 0.1256\n",
      "Epoch 13/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.5623 - mse: 1.5623 - val_loss: 2.1771 - val_mse: 2.1771\n",
      "Epoch 14/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.9723 - mse: 1.9723 - val_loss: 5.8963 - val_mse: 5.8963\n",
      "Epoch 15/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4876 - mse: 4.4876 - val_loss: 8.1068 - val_mse: 8.1068\n",
      "Epoch 16/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.1673 - mse: 6.1673 - val_loss: 7.3663 - val_mse: 7.3663\n",
      "Epoch 17/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5.5890 - mse: 5.5890 - val_loss: 4.5943 - val_mse: 4.5943\n",
      "Epoch 18/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5288 - mse: 3.5288 - val_loss: 1.7555 - val_mse: 1.7555\n",
      "Epoch 19/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.7189 - mse: 1.7189 - val_loss: 0.2733 - val_mse: 0.2733\n",
      "Epoch 20/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3203 - mse: 1.3203 - val_loss: 0.2434 - val_mse: 0.2434\n",
      "Epoch 21/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.1899 - mse: 2.1899 - val_loss: 0.7750 - val_mse: 0.7750\n",
      "Epoch 22/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2702 - mse: 3.2702 - val_loss: 0.9702 - val_mse: 0.9702\n",
      "Epoch 23/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5955 - mse: 3.5955 - val_loss: 0.6236 - val_mse: 0.6236\n",
      "Epoch 24/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.9860 - mse: 2.9860 - val_loss: 0.1857 - val_mse: 0.1857\n",
      "Epoch 25/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.9889 - mse: 1.9889 - val_loss: 0.2343 - val_mse: 0.2343\n",
      "Epoch 26/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3229 - mse: 1.3229 - val_loss: 0.9566 - val_mse: 0.9566\n",
      "Epoch 27/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3325 - mse: 1.3325 - val_loss: 2.0068 - val_mse: 2.0068\n",
      "Epoch 28/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.8146 - mse: 1.8146 - val_loss: 2.7884 - val_mse: 2.7884\n",
      "Epoch 29/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.2722 - mse: 2.2722 - val_loss: 2.8875 - val_mse: 2.8875\n",
      "Epoch 30/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.3300 - mse: 2.3300 - val_loss: 2.3167 - val_mse: 2.3167\n",
      "Epoch 31/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.9780 - mse: 1.9780 - val_loss: 1.4350 - val_mse: 1.4350\n",
      "Epoch 32/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.5035 - mse: 1.5035 - val_loss: 0.6671 - val_mse: 0.6671\n",
      "Epoch 33/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2301 - mse: 1.2301 - val_loss: 0.2445 - val_mse: 0.2445\n",
      "Epoch 34/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2815 - mse: 1.2815 - val_loss: 0.1313 - val_mse: 0.1313\n",
      "Epoch 35/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.5288 - mse: 1.5288 - val_loss: 0.1452 - val_mse: 0.1452\n",
      "Epoch 36/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.7282 - mse: 1.7282 - val_loss: 0.1452 - val_mse: 0.1452\n",
      "Epoch 37/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.7181 - mse: 1.7181 - val_loss: 0.1331 - val_mse: 0.1331\n",
      "Epoch 38/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.5202 - mse: 1.5202 - val_loss: 0.2123 - val_mse: 0.2123\n",
      "Epoch 39/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2901 - mse: 1.2901 - val_loss: 0.4633 - val_mse: 0.4633\n",
      "Epoch 40/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.1809 - mse: 1.1809 - val_loss: 0.8486 - val_mse: 0.8486\n",
      "Epoch 41/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.2317 - mse: 1.2317 - val_loss: 1.2191 - val_mse: 1.2191\n",
      "Epoch 42/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.3585 - mse: 1.3585 - val_loss: 1.4098 - val_mse: 1.4098\n",
      "Epoch 43/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.4370 - mse: 1.4370 - val_loss: 1.3452 - val_mse: 1.3452\n",
      "Epoch 44/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.4021 - mse: 1.4021 - val_loss: 1.0778 - val_mse: 1.0778\n",
      "Epoch 45/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2856 - mse: 1.2856 - val_loss: 0.7400 - val_mse: 0.7400\n",
      "Epoch 46/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1761 - mse: 1.1761 - val_loss: 0.4570 - val_mse: 0.4570\n",
      "Epoch 47/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.1424 - mse: 1.1424 - val_loss: 0.2848 - val_mse: 0.2848\n",
      "Epoch 48/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1847 - mse: 1.1847 - val_loss: 0.2100 - val_mse: 0.2100\n",
      "Epoch 49/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2453 - mse: 1.2453 - val_loss: 0.1946 - val_mse: 0.1946\n",
      "Epoch 50/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2630 - mse: 1.2630 - val_loss: 0.2212 - val_mse: 0.2212\n",
      "Epoch 51/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.2208 - mse: 1.2208 - val_loss: 0.3008 - val_mse: 0.3008\n",
      "Epoch 52/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1521 - mse: 1.1521 - val_loss: 0.4444 - val_mse: 0.4444\n",
      "Epoch 53/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1059 - mse: 1.1059 - val_loss: 0.6311 - val_mse: 0.6311\n",
      "Epoch 54/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1053 - mse: 1.1053 - val_loss: 0.8041 - val_mse: 0.8041\n",
      "Epoch 55/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1334 - mse: 1.1334 - val_loss: 0.8991 - val_mse: 0.8991\n",
      "Epoch 56/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1533 - mse: 1.1533 - val_loss: 0.8831 - val_mse: 0.8831\n",
      "Epoch 57/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1412 - mse: 1.1412 - val_loss: 0.7724 - val_mse: 0.7724\n",
      "Epoch 58/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1037 - mse: 1.1037 - val_loss: 0.6183 - val_mse: 0.6183\n",
      "Epoch 59/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0674 - mse: 1.0674 - val_loss: 0.4753 - val_mse: 0.4753\n",
      "Epoch 60/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0537 - mse: 1.0537 - val_loss: 0.3757 - val_mse: 0.3757\n",
      "Epoch 61/120\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.0614 - mse: 1.0614 - val_loss: 0.3259 - val_mse: 0.3259\n",
      "Epoch 62/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.0717 - mse: 1.0717 - val_loss: 0.3205 - val_mse: 0.3205\n",
      "Epoch 63/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0667 - mse: 1.0667 - val_loss: 0.3548 - val_mse: 0.3548\n",
      "Epoch 64/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0448 - mse: 1.0448 - val_loss: 0.4257 - val_mse: 0.4257\n",
      "Epoch 65/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0192 - mse: 1.0192 - val_loss: 0.5227 - val_mse: 0.5227\n",
      "Epoch 66/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0042 - mse: 1.0042 - val_loss: 0.6217 - val_mse: 0.6217\n",
      "Epoch 67/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0025 - mse: 1.0025 - val_loss: 0.6913 - val_mse: 0.6913\n",
      "Epoch 68/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0044 - mse: 1.0044 - val_loss: 0.7085 - val_mse: 0.7085\n",
      "Epoch 69/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9987 - mse: 0.9987 - val_loss: 0.6715 - val_mse: 0.6715\n",
      "Epoch 70/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9828 - mse: 0.9828 - val_loss: 0.5990 - val_mse: 0.5990\n",
      "Epoch 71/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9639 - mse: 0.9639 - val_loss: 0.5191 - val_mse: 0.5191\n",
      "Epoch 72/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9506 - mse: 0.9506 - val_loss: 0.4548 - val_mse: 0.4548\n",
      "Epoch 73/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9449 - mse: 0.9449 - val_loss: 0.4181 - val_mse: 0.4181\n",
      "Epoch 74/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9413 - mse: 0.9413 - val_loss: 0.4118 - val_mse: 0.4118\n",
      "Epoch 75/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9333 - mse: 0.9333 - val_loss: 0.4339 - val_mse: 0.4339\n",
      "Epoch 76/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9195 - mse: 0.9195 - val_loss: 0.4791 - val_mse: 0.4791\n",
      "Epoch 77/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9042 - mse: 0.9042 - val_loss: 0.5366 - val_mse: 0.5366\n",
      "Epoch 78/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8924 - mse: 0.8924 - val_loss: 0.5906 - val_mse: 0.5906\n",
      "Epoch 79/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8849 - mse: 0.8849 - val_loss: 0.6242 - val_mse: 0.6242\n",
      "Epoch 80/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8779 - mse: 0.8779 - val_loss: 0.6274 - val_mse: 0.6274\n",
      "Epoch 81/120\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8679 - mse: 0.8679 - val_loss: 0.6022 - val_mse: 0.6022\n",
      "Epoch 82/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8548 - mse: 0.8548 - val_loss: 0.5606 - val_mse: 0.5606\n",
      "Epoch 83/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8416 - mse: 0.8416 - val_loss: 0.5181 - val_mse: 0.5181\n",
      "Epoch 84/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8308 - mse: 0.8308 - val_loss: 0.4872 - val_mse: 0.4872\n",
      "Epoch 85/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8222 - mse: 0.8222 - val_loss: 0.4746 - val_mse: 0.4746\n",
      "Epoch 86/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8130 - mse: 0.8130 - val_loss: 0.4815 - val_mse: 0.4815\n",
      "Epoch 87/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8019 - mse: 0.8019 - val_loss: 0.5050 - val_mse: 0.5050\n",
      "Epoch 88/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7894 - mse: 0.7894 - val_loss: 0.5385 - val_mse: 0.5385\n",
      "Epoch 89/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7776 - mse: 0.7776 - val_loss: 0.5721 - val_mse: 0.5721\n",
      "Epoch 90/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7675 - mse: 0.7675 - val_loss: 0.5953 - val_mse: 0.5953\n",
      "Epoch 91/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7581 - mse: 0.7581 - val_loss: 0.6014 - val_mse: 0.6014\n",
      "Epoch 92/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7478 - mse: 0.7478 - val_loss: 0.5904 - val_mse: 0.5904\n",
      "Epoch 93/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7364 - mse: 0.7364 - val_loss: 0.5685 - val_mse: 0.5685\n",
      "Epoch 94/120\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7250 - mse: 0.7250 - val_loss: 0.5448 - val_mse: 0.5448\n",
      "Epoch 95/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7144 - mse: 0.7144 - val_loss: 0.5277 - val_mse: 0.5277\n",
      "Epoch 96/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7048 - mse: 0.7048 - val_loss: 0.5220 - val_mse: 0.5220\n",
      "Epoch 97/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6950 - mse: 0.6950 - val_loss: 0.5287 - val_mse: 0.5287\n",
      "Epoch 98/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6846 - mse: 0.6846 - val_loss: 0.5455 - val_mse: 0.5455\n",
      "Epoch 99/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6740 - mse: 0.6740 - val_loss: 0.5671 - val_mse: 0.5671\n",
      "Epoch 100/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6639 - mse: 0.6639 - val_loss: 0.5868 - val_mse: 0.5868\n",
      "Epoch 101/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6545 - mse: 0.6545 - val_loss: 0.5986 - val_mse: 0.5986\n",
      "Epoch 102/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6453 - mse: 0.6453 - val_loss: 0.5997 - val_mse: 0.5997\n",
      "Epoch 103/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6360 - mse: 0.6360 - val_loss: 0.5916 - val_mse: 0.5916\n",
      "Epoch 104/120\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6265 - mse: 0.6265 - val_loss: 0.5791 - val_mse: 0.5791\n",
      "Epoch 105/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6173 - mse: 0.6173 - val_loss: 0.5680 - val_mse: 0.5680\n",
      "Epoch 106/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6088 - mse: 0.6088 - val_loss: 0.5628 - val_mse: 0.5628\n",
      "Epoch 107/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6006 - mse: 0.6006 - val_loss: 0.5654 - val_mse: 0.5654\n",
      "Epoch 108/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5924 - mse: 0.5924 - val_loss: 0.5751 - val_mse: 0.5751\n",
      "Epoch 109/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5842 - mse: 0.5842 - val_loss: 0.5890 - val_mse: 0.5890\n",
      "Epoch 110/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5764 - mse: 0.5764 - val_loss: 0.6028 - val_mse: 0.6028\n",
      "Epoch 111/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5691 - mse: 0.5691 - val_loss: 0.6125 - val_mse: 0.6125\n",
      "Epoch 112/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5622 - mse: 0.5622 - val_loss: 0.6158 - val_mse: 0.6158\n",
      "Epoch 113/120\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5554 - mse: 0.5554 - val_loss: 0.6133 - val_mse: 0.6133\n",
      "Epoch 114/120\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5487 - mse: 0.5487 - val_loss: 0.6077 - val_mse: 0.6077\n",
      "Epoch 115/120\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5424 - mse: 0.5424 - val_loss: 0.6027 - val_mse: 0.6027\n",
      "Epoch 116/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5365 - mse: 0.5365 - val_loss: 0.6013 - val_mse: 0.6013\n",
      "Epoch 117/120\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5310 - mse: 0.5310 - val_loss: 0.6047 - val_mse: 0.6047\n",
      "Epoch 118/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5257 - mse: 0.5257 - val_loss: 0.6125 - val_mse: 0.6125\n",
      "Epoch 119/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5206 - mse: 0.5206 - val_loss: 0.6225 - val_mse: 0.6225\n",
      "Epoch 120/120\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5159 - mse: 0.5159 - val_loss: 0.6320 - val_mse: 0.6320\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "r2: 0.43163373454719867 meansquarederror: 0.12652780346088446 meanabsoluteerror: 0.32303853656924164 maxerror: 0.4865553552490671\n",
      "Epoch 1/120\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 5.0189 - mse: 5.0189 - val_loss: 20.1364 - val_mse: 20.1364\n",
      "Epoch 2/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 27.0669 - mse: 27.0669 - val_loss: 2.3786 - val_mse: 2.3786\n",
      "Epoch 3/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.7574 - mse: 5.7574 - val_loss: 5.5869 - val_mse: 5.5869\n",
      "Epoch 4/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.3793 - mse: 4.3793 - val_loss: 16.8232 - val_mse: 16.8232\n",
      "Epoch 5/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 13.5045 - mse: 13.5045 - val_loss: 11.6999 - val_mse: 11.6999\n",
      "Epoch 6/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.1951 - mse: 9.1951 - val_loss: 2.4821 - val_mse: 2.4821\n",
      "Epoch 7/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.2108 - mse: 2.2108 - val_loss: 0.3111 - val_mse: 0.3111\n",
      "Epoch 8/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.3904 - mse: 2.3904 - val_loss: 2.9624 - val_mse: 2.9624\n",
      "Epoch 9/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.4959 - mse: 6.4959 - val_loss: 3.6077 - val_mse: 3.6077\n",
      "Epoch 10/120\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.3431 - mse: 7.3431 - val_loss: 1.4819 - val_mse: 1.4819\n",
      "Epoch 11/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3895 - mse: 4.3895 - val_loss: 0.1187 - val_mse: 0.1187\n",
      "Epoch 12/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.6068 - mse: 1.6068 - val_loss: 1.7691 - val_mse: 1.7691\n",
      "Epoch 13/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.7640 - mse: 1.7640 - val_loss: 4.8032 - val_mse: 4.8032\n",
      "Epoch 14/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.7384 - mse: 3.7384 - val_loss: 6.0124 - val_mse: 6.0124\n",
      "Epoch 15/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.6249 - mse: 4.6249 - val_loss: 4.4698 - val_mse: 4.4698\n",
      "Epoch 16/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.4882 - mse: 3.4882 - val_loss: 1.8954 - val_mse: 1.8954\n",
      "Epoch 17/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.8101 - mse: 1.8101 - val_loss: 0.3190 - val_mse: 0.3190\n",
      "Epoch 18/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.2820 - mse: 1.2820 - val_loss: 0.2152 - val_mse: 0.2152\n",
      "Epoch 19/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.0495 - mse: 2.0495 - val_loss: 0.6243 - val_mse: 0.6243\n",
      "Epoch 20/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.9244 - mse: 2.9244 - val_loss: 0.6127 - val_mse: 0.6127\n",
      "Epoch 21/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.8954 - mse: 2.8954 - val_loss: 0.2343 - val_mse: 0.2343\n",
      "Epoch 22/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.0789 - mse: 2.0789 - val_loss: 0.1937 - val_mse: 0.1937\n",
      "Epoch 23/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.3413 - mse: 1.3413 - val_loss: 0.9063 - val_mse: 0.9063\n",
      "Epoch 24/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.3124 - mse: 1.3124 - val_loss: 1.9825 - val_mse: 1.9825\n",
      "Epoch 25/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.8150 - mse: 1.8150 - val_loss: 2.6063 - val_mse: 2.6063\n",
      "Epoch 26/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.1810 - mse: 2.1810 - val_loss: 2.3392 - val_mse: 2.3392\n",
      "Epoch 27/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.0120 - mse: 2.0120 - val_loss: 1.4651 - val_mse: 1.4651\n",
      "Epoch 28/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.5240 - mse: 1.5240 - val_loss: 0.6186 - val_mse: 0.6186\n",
      "Epoch 29/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2101 - mse: 1.2101 - val_loss: 0.1975 - val_mse: 0.1975\n",
      "Epoch 30/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.3017 - mse: 1.3017 - val_loss: 0.1361 - val_mse: 0.1361\n",
      "Epoch 31/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.5905 - mse: 1.5905 - val_loss: 0.1564 - val_mse: 0.1564\n",
      "Epoch 32/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.7165 - mse: 1.7165 - val_loss: 0.1362 - val_mse: 0.1362\n",
      "Epoch 33/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.5508 - mse: 1.5508 - val_loss: 0.1990 - val_mse: 0.1990\n",
      "Epoch 34/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2787 - mse: 1.2787 - val_loss: 0.4968 - val_mse: 0.4968\n",
      "Epoch 35/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1611 - mse: 1.1611 - val_loss: 0.9698 - val_mse: 0.9698\n",
      "Epoch 36/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2614 - mse: 1.2614 - val_loss: 1.3489 - val_mse: 1.3489\n",
      "Epoch 37/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4131 - mse: 1.4131 - val_loss: 1.3935 - val_mse: 1.3935\n",
      "Epoch 38/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.4275 - mse: 1.4275 - val_loss: 1.1017 - val_mse: 1.1017\n",
      "Epoch 39/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2913 - mse: 1.2913 - val_loss: 0.6850 - val_mse: 0.6850\n",
      "Epoch 40/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.1506 - mse: 1.1506 - val_loss: 0.3649 - val_mse: 0.3649\n",
      "Epoch 41/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1317 - mse: 1.1317 - val_loss: 0.2136 - val_mse: 0.2136\n",
      "Epoch 42/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2131 - mse: 1.2131 - val_loss: 0.1745 - val_mse: 0.1745\n",
      "Epoch 43/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2731 - mse: 1.2731 - val_loss: 0.1904 - val_mse: 0.1904\n",
      "Epoch 44/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2345 - mse: 1.2345 - val_loss: 0.2749 - val_mse: 0.2749\n",
      "Epoch 45/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1386 - mse: 1.1386 - val_loss: 0.4612 - val_mse: 0.4612\n",
      "Epoch 46/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0814 - mse: 1.0814 - val_loss: 0.7107 - val_mse: 0.7107\n",
      "Epoch 47/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1020 - mse: 1.1020 - val_loss: 0.9041 - val_mse: 0.9041\n",
      "Epoch 48/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1488 - mse: 1.1488 - val_loss: 0.9336 - val_mse: 0.9336\n",
      "Epoch 49/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1504 - mse: 1.1504 - val_loss: 0.7947 - val_mse: 0.7947\n",
      "Epoch 50/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0978 - mse: 1.0978 - val_loss: 0.5815 - val_mse: 0.5815\n",
      "Epoch 51/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0444 - mse: 1.0444 - val_loss: 0.4008 - val_mse: 0.4008\n",
      "Epoch 52/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0358 - mse: 1.0358 - val_loss: 0.2999 - val_mse: 0.2999\n",
      "Epoch 53/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0594 - mse: 1.0594 - val_loss: 0.2716 - val_mse: 0.2716\n",
      "Epoch 54/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0682 - mse: 1.0682 - val_loss: 0.3019 - val_mse: 0.3019\n",
      "Epoch 55/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0403 - mse: 1.0403 - val_loss: 0.3909 - val_mse: 0.3909\n",
      "Epoch 56/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0001 - mse: 1.0001 - val_loss: 0.5274 - val_mse: 0.5274\n",
      "Epoch 57/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9823 - mse: 0.9823 - val_loss: 0.6632 - val_mse: 0.6632\n",
      "Epoch 58/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9897 - mse: 0.9897 - val_loss: 0.7324 - val_mse: 0.7324\n",
      "Epoch 59/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9946 - mse: 0.9946 - val_loss: 0.7020 - val_mse: 0.7020\n",
      "Epoch 60/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9769 - mse: 0.9769 - val_loss: 0.5977 - val_mse: 0.5977\n",
      "Epoch 61/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9473 - mse: 0.9473 - val_loss: 0.4789 - val_mse: 0.4789\n",
      "Epoch 62/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9291 - mse: 0.9291 - val_loss: 0.3932 - val_mse: 0.3932\n",
      "Epoch 63/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9278 - mse: 0.9278 - val_loss: 0.3573 - val_mse: 0.3573\n",
      "Epoch 64/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9269 - mse: 0.9269 - val_loss: 0.3696 - val_mse: 0.3696\n",
      "Epoch 65/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9122 - mse: 0.9122 - val_loss: 0.4247 - val_mse: 0.4247\n",
      "Epoch 66/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8891 - mse: 0.8891 - val_loss: 0.5090 - val_mse: 0.5090\n",
      "Epoch 67/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8729 - mse: 0.8729 - val_loss: 0.5914 - val_mse: 0.5914\n",
      "Epoch 68/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8674 - mse: 0.8674 - val_loss: 0.6340 - val_mse: 0.6340\n",
      "Epoch 69/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8618 - mse: 0.8618 - val_loss: 0.6178 - val_mse: 0.6178\n",
      "Epoch 70/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8474 - mse: 0.8474 - val_loss: 0.5571 - val_mse: 0.5571\n",
      "Epoch 71/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8282 - mse: 0.8282 - val_loss: 0.4865 - val_mse: 0.4865\n",
      "Epoch 72/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8142 - mse: 0.8142 - val_loss: 0.4358 - val_mse: 0.4358\n",
      "Epoch 73/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8065 - mse: 0.8065 - val_loss: 0.4185 - val_mse: 0.4185\n",
      "Epoch 74/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7977 - mse: 0.7977 - val_loss: 0.4355 - val_mse: 0.4355\n",
      "Epoch 75/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7830 - mse: 0.7830 - val_loss: 0.4799 - val_mse: 0.4799\n",
      "Epoch 76/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7667 - mse: 0.7667 - val_loss: 0.5356 - val_mse: 0.5356\n",
      "Epoch 77/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7545 - mse: 0.7545 - val_loss: 0.5787 - val_mse: 0.5787\n",
      "Epoch 78/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7456 - mse: 0.7456 - val_loss: 0.5893 - val_mse: 0.5893\n",
      "Epoch 79/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7348 - mse: 0.7348 - val_loss: 0.5654 - val_mse: 0.5654\n",
      "Epoch 80/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7204 - mse: 0.7204 - val_loss: 0.5235 - val_mse: 0.5235\n",
      "Epoch 81/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7065 - mse: 0.7065 - val_loss: 0.4856 - val_mse: 0.4856\n",
      "Epoch 82/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6959 - mse: 0.6959 - val_loss: 0.4670 - val_mse: 0.4670\n",
      "Epoch 83/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6863 - mse: 0.6863 - val_loss: 0.4725 - val_mse: 0.4725\n",
      "Epoch 84/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6746 - mse: 0.6746 - val_loss: 0.4986 - val_mse: 0.4986\n",
      "Epoch 85/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6615 - mse: 0.6615 - val_loss: 0.5345 - val_mse: 0.5345\n",
      "Epoch 86/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6501 - mse: 0.6501 - val_loss: 0.5644 - val_mse: 0.5644\n",
      "Epoch 87/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6406 - mse: 0.6406 - val_loss: 0.5749 - val_mse: 0.5749\n",
      "Epoch 88/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6307 - mse: 0.6307 - val_loss: 0.5631 - val_mse: 0.5631\n",
      "Epoch 89/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6195 - mse: 0.6195 - val_loss: 0.5389 - val_mse: 0.5389\n",
      "Epoch 90/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6086 - mse: 0.6086 - val_loss: 0.5166 - val_mse: 0.5166\n",
      "Epoch 91/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5994 - mse: 0.5994 - val_loss: 0.5070 - val_mse: 0.5070\n",
      "Epoch 92/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5908 - mse: 0.5908 - val_loss: 0.5136 - val_mse: 0.5136\n",
      "Epoch 93/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5816 - mse: 0.5816 - val_loss: 0.5333 - val_mse: 0.5333\n",
      "Epoch 94/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5721 - mse: 0.5721 - val_loss: 0.5575 - val_mse: 0.5575\n",
      "Epoch 95/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5637 - mse: 0.5637 - val_loss: 0.5753 - val_mse: 0.5753\n",
      "Epoch 96/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5563 - mse: 0.5563 - val_loss: 0.5796 - val_mse: 0.5796\n",
      "Epoch 97/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5488 - mse: 0.5488 - val_loss: 0.5710 - val_mse: 0.5710\n",
      "Epoch 98/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5411 - mse: 0.5411 - val_loss: 0.5573 - val_mse: 0.5573\n",
      "Epoch 99/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5341 - mse: 0.5341 - val_loss: 0.5479 - val_mse: 0.5479\n",
      "Epoch 100/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5280 - mse: 0.5280 - val_loss: 0.5483 - val_mse: 0.5483\n",
      "Epoch 101/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5221 - mse: 0.5221 - val_loss: 0.5590 - val_mse: 0.5590\n",
      "Epoch 102/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5162 - mse: 0.5162 - val_loss: 0.5756 - val_mse: 0.5756\n",
      "Epoch 103/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5107 - mse: 0.5107 - val_loss: 0.5912 - val_mse: 0.5912\n",
      "Epoch 104/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5060 - mse: 0.5060 - val_loss: 0.5995 - val_mse: 0.5995\n",
      "Epoch 105/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5017 - mse: 0.5017 - val_loss: 0.5990 - val_mse: 0.5990\n",
      "Epoch 106/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4974 - mse: 0.4974 - val_loss: 0.5932 - val_mse: 0.5932\n",
      "Epoch 107/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4935 - mse: 0.4935 - val_loss: 0.5882 - val_mse: 0.5882\n",
      "Epoch 108/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4902 - mse: 0.4902 - val_loss: 0.5887 - val_mse: 0.5887\n",
      "Epoch 109/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4872 - mse: 0.4872 - val_loss: 0.5961 - val_mse: 0.5961\n",
      "Epoch 110/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4843 - mse: 0.4843 - val_loss: 0.6080 - val_mse: 0.6080\n",
      "Epoch 111/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4817 - mse: 0.4817 - val_loss: 0.6200 - val_mse: 0.6200\n",
      "Epoch 112/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4796 - mse: 0.4796 - val_loss: 0.6278 - val_mse: 0.6278\n",
      "Epoch 113/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4778 - mse: 0.4778 - val_loss: 0.6298 - val_mse: 0.6298\n",
      "Epoch 114/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4760 - mse: 0.4760 - val_loss: 0.6281 - val_mse: 0.6281\n",
      "Epoch 115/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4745 - mse: 0.4745 - val_loss: 0.6266 - val_mse: 0.6266\n",
      "Epoch 116/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4733 - mse: 0.4733 - val_loss: 0.6284 - val_mse: 0.6284\n",
      "Epoch 117/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4723 - mse: 0.4723 - val_loss: 0.6344 - val_mse: 0.6344\n",
      "Epoch 118/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4714 - mse: 0.4714 - val_loss: 0.6432 - val_mse: 0.6432\n",
      "Epoch 119/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4707 - mse: 0.4707 - val_loss: 0.6518 - val_mse: 0.6518\n",
      "Epoch 120/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4701 - mse: 0.4701 - val_loss: 0.6573 - val_mse: 0.6573\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "r2: 0.49507727414028124 meansquarederror: 0.11240421415513774 meanabsoluteerror: 0.2954317275045421 maxerror: 0.4597870546803522\n",
      "Epoch 1/120\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 3.4435 - mse: 3.4435 - val_loss: 24.7439 - val_mse: 24.7439\n",
      "Epoch 2/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 32.4221 - mse: 32.4221 - val_loss: 1.7632 - val_mse: 1.7632\n",
      "Epoch 3/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.9329 - mse: 4.9329 - val_loss: 8.8412 - val_mse: 8.8412\n",
      "Epoch 4/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.8672 - mse: 6.8672 - val_loss: 20.7194 - val_mse: 20.7194\n",
      "Epoch 5/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.8107 - mse: 16.8107 - val_loss: 13.3596 - val_mse: 13.3596\n",
      "Epoch 6/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 10.5318 - mse: 10.5318 - val_loss: 2.6991 - val_mse: 2.6991\n",
      "Epoch 7/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.3339 - mse: 2.3339 - val_loss: 0.3652 - val_mse: 0.3652\n",
      "Epoch 8/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.5486 - mse: 2.5486 - val_loss: 3.5613 - val_mse: 3.5613\n",
      "Epoch 9/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 7.3601 - mse: 7.3601 - val_loss: 4.6503 - val_mse: 4.6503\n",
      "Epoch 10/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.7645 - mse: 8.7645 - val_loss: 2.3407 - val_mse: 2.3407\n",
      "Epoch 11/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.6847 - mse: 5.6847 - val_loss: 0.2071 - val_mse: 0.2071\n",
      "Epoch 12/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.1216 - mse: 2.1216 - val_loss: 1.1490 - val_mse: 1.1490\n",
      "Epoch 13/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4663 - mse: 1.4663 - val_loss: 4.3622 - val_mse: 4.3622\n",
      "Epoch 14/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4063 - mse: 3.4063 - val_loss: 6.6303 - val_mse: 6.6303\n",
      "Epoch 15/120\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.0691 - mse: 5.0691 - val_loss: 6.0464 - val_mse: 6.0464\n",
      "Epoch 16/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6232 - mse: 4.6232 - val_loss: 3.4892 - val_mse: 3.4892\n",
      "Epoch 17/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.7907 - mse: 2.7907 - val_loss: 1.0810 - val_mse: 1.0810\n",
      "Epoch 18/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4131 - mse: 1.4131 - val_loss: 0.1356 - val_mse: 0.1356\n",
      "Epoch 19/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4929 - mse: 1.4929 - val_loss: 0.3866 - val_mse: 0.3866\n",
      "Epoch 20/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.5000 - mse: 2.5000 - val_loss: 0.7614 - val_mse: 0.7614\n",
      "Epoch 21/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.2067 - mse: 3.2067 - val_loss: 0.6206 - val_mse: 0.6206\n",
      "Epoch 22/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.9474 - mse: 2.9474 - val_loss: 0.2146 - val_mse: 0.2146\n",
      "Epoch 23/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.0545 - mse: 2.0545 - val_loss: 0.2029 - val_mse: 0.2029\n",
      "Epoch 24/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.3414 - mse: 1.3414 - val_loss: 0.9037 - val_mse: 0.9037\n",
      "Epoch 25/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.3148 - mse: 1.3148 - val_loss: 1.9604 - val_mse: 1.9604\n",
      "Epoch 26/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.7982 - mse: 1.7982 - val_loss: 2.6643 - val_mse: 2.6643\n",
      "Epoch 27/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.2094 - mse: 2.2094 - val_loss: 2.5732 - val_mse: 2.5732\n",
      "Epoch 28/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.1482 - mse: 2.1482 - val_loss: 1.8248 - val_mse: 1.8248\n",
      "Epoch 29/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.7088 - mse: 1.7088 - val_loss: 0.9325 - val_mse: 0.9325\n",
      "Epoch 30/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2979 - mse: 1.2979 - val_loss: 0.3397 - val_mse: 0.3397\n",
      "Epoch 31/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.2227 - mse: 1.2227 - val_loss: 0.1401 - val_mse: 0.1401\n",
      "Epoch 32/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4465 - mse: 1.4465 - val_loss: 0.1430 - val_mse: 0.1430\n",
      "Epoch 33/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.6851 - mse: 1.6851 - val_loss: 0.1470 - val_mse: 0.1470\n",
      "Epoch 34/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.6981 - mse: 1.6981 - val_loss: 0.1350 - val_mse: 0.1350\n",
      "Epoch 35/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.4871 - mse: 1.4871 - val_loss: 0.2384 - val_mse: 0.2384\n",
      "Epoch 36/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2492 - mse: 1.2492 - val_loss: 0.5506 - val_mse: 0.5506\n",
      "Epoch 37/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1722 - mse: 1.1722 - val_loss: 0.9890 - val_mse: 0.9890\n",
      "Epoch 38/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2722 - mse: 1.2722 - val_loss: 1.3332 - val_mse: 1.3332\n",
      "Epoch 39/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.4073 - mse: 1.4073 - val_loss: 1.3965 - val_mse: 1.3965\n",
      "Epoch 40/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.4305 - mse: 1.4305 - val_loss: 1.1664 - val_mse: 1.1664\n",
      "Epoch 41/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3222 - mse: 1.3222 - val_loss: 0.7939 - val_mse: 0.7939\n",
      "Epoch 42/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1857 - mse: 1.1857 - val_loss: 0.4634 - val_mse: 0.4634\n",
      "Epoch 43/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.1328 - mse: 1.1328 - val_loss: 0.2686 - val_mse: 0.2686\n",
      "Epoch 44/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1807 - mse: 1.1807 - val_loss: 0.1935 - val_mse: 0.1935\n",
      "Epoch 45/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2525 - mse: 1.2525 - val_loss: 0.1844 - val_mse: 0.1844\n",
      "Epoch 46/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.2634 - mse: 1.2634 - val_loss: 0.2239 - val_mse: 0.2239\n",
      "Epoch 47/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2002 - mse: 1.2002 - val_loss: 0.3350 - val_mse: 0.3350\n",
      "Epoch 48/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.1213 - mse: 1.1213 - val_loss: 0.5258 - val_mse: 0.5258\n",
      "Epoch 49/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0908 - mse: 1.0908 - val_loss: 0.7445 - val_mse: 0.7445\n",
      "Epoch 50/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1165 - mse: 1.1165 - val_loss: 0.8968 - val_mse: 0.8968\n",
      "Epoch 51/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.1517 - mse: 1.1517 - val_loss: 0.9118 - val_mse: 0.9118\n",
      "Epoch 52/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1487 - mse: 1.1487 - val_loss: 0.7931 - val_mse: 0.7931\n",
      "Epoch 53/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1051 - mse: 1.1051 - val_loss: 0.6103 - val_mse: 0.6103\n",
      "Epoch 54/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0590 - mse: 1.0590 - val_loss: 0.4438 - val_mse: 0.4438\n",
      "Epoch 55/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0448 - mse: 1.0448 - val_loss: 0.3373 - val_mse: 0.3373\n",
      "Epoch 56/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0594 - mse: 1.0594 - val_loss: 0.2940 - val_mse: 0.2940\n",
      "Epoch 57/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0718 - mse: 1.0718 - val_loss: 0.3031 - val_mse: 0.3031\n",
      "Epoch 58/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0584 - mse: 1.0584 - val_loss: 0.3609 - val_mse: 0.3609\n",
      "Epoch 59/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0259 - mse: 1.0259 - val_loss: 0.4632 - val_mse: 0.4632\n",
      "Epoch 60/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9995 - mse: 0.9995 - val_loss: 0.5867 - val_mse: 0.5867\n",
      "Epoch 61/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9939 - mse: 0.9939 - val_loss: 0.6865 - val_mse: 0.6865\n",
      "Epoch 62/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9999 - mse: 0.9999 - val_loss: 0.7206 - val_mse: 0.7206\n",
      "Epoch 63/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9973 - mse: 0.9973 - val_loss: 0.6785 - val_mse: 0.6785\n",
      "Epoch 64/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9787 - mse: 0.9787 - val_loss: 0.5866 - val_mse: 0.5866\n",
      "Epoch 65/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9548 - mse: 0.9548 - val_loss: 0.4879 - val_mse: 0.4879\n",
      "Epoch 66/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9403 - mse: 0.9403 - val_loss: 0.4153 - val_mse: 0.4153\n",
      "Epoch 67/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9372 - mse: 0.9372 - val_loss: 0.3819 - val_mse: 0.3819\n",
      "Epoch 68/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9346 - mse: 0.9346 - val_loss: 0.3881 - val_mse: 0.3881\n",
      "Epoch 69/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9227 - mse: 0.9227 - val_loss: 0.4297 - val_mse: 0.4297\n",
      "Epoch 70/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9038 - mse: 0.9038 - val_loss: 0.4968 - val_mse: 0.4968\n",
      "Epoch 71/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8876 - mse: 0.8876 - val_loss: 0.5693 - val_mse: 0.5693\n",
      "Epoch 72/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8790 - mse: 0.8790 - val_loss: 0.6199 - val_mse: 0.6199\n",
      "Epoch 73/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8734 - mse: 0.8734 - val_loss: 0.6287 - val_mse: 0.6287\n",
      "Epoch 74/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8634 - mse: 0.8634 - val_loss: 0.5958 - val_mse: 0.5958\n",
      "Epoch 75/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8479 - mse: 0.8479 - val_loss: 0.5399 - val_mse: 0.5399\n",
      "Epoch 76/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8324 - mse: 0.8324 - val_loss: 0.4857 - val_mse: 0.4857\n",
      "Epoch 77/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8214 - mse: 0.8214 - val_loss: 0.4511 - val_mse: 0.4511\n",
      "Epoch 78/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8133 - mse: 0.8133 - val_loss: 0.4433 - val_mse: 0.4433\n",
      "Epoch 79/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8032 - mse: 0.8032 - val_loss: 0.4618 - val_mse: 0.4618\n",
      "Epoch 80/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7895 - mse: 0.7895 - val_loss: 0.5002 - val_mse: 0.5002\n",
      "Epoch 81/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7752 - mse: 0.7752 - val_loss: 0.5457 - val_mse: 0.5457\n",
      "Epoch 82/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7637 - mse: 0.7637 - val_loss: 0.5813 - val_mse: 0.5813\n",
      "Epoch 83/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7542 - mse: 0.7542 - val_loss: 0.5932 - val_mse: 0.5932\n",
      "Epoch 84/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7438 - mse: 0.7438 - val_loss: 0.5788 - val_mse: 0.5788\n",
      "Epoch 85/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7310 - mse: 0.7310 - val_loss: 0.5477 - val_mse: 0.5477\n",
      "Epoch 86/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7180 - mse: 0.7180 - val_loss: 0.5152 - val_mse: 0.5152\n",
      "Epoch 87/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7068 - mse: 0.7068 - val_loss: 0.4941 - val_mse: 0.4941\n",
      "Epoch 88/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6969 - mse: 0.6969 - val_loss: 0.4907 - val_mse: 0.4907\n",
      "Epoch 89/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6864 - mse: 0.6864 - val_loss: 0.5049 - val_mse: 0.5049\n",
      "Epoch 90/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6746 - mse: 0.6746 - val_loss: 0.5312 - val_mse: 0.5312\n",
      "Epoch 91/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6630 - mse: 0.6630 - val_loss: 0.5598 - val_mse: 0.5598\n",
      "Epoch 92/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6526 - mse: 0.6526 - val_loss: 0.5795 - val_mse: 0.5795\n",
      "Epoch 93/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6431 - mse: 0.6431 - val_loss: 0.5834 - val_mse: 0.5834\n",
      "Epoch 94/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6332 - mse: 0.6332 - val_loss: 0.5720 - val_mse: 0.5720\n",
      "Epoch 95/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6226 - mse: 0.6226 - val_loss: 0.5532 - val_mse: 0.5532\n",
      "Epoch 96/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6125 - mse: 0.6125 - val_loss: 0.5368 - val_mse: 0.5368\n",
      "Epoch 97/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6034 - mse: 0.6034 - val_loss: 0.5300 - val_mse: 0.5300\n",
      "Epoch 98/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5948 - mse: 0.5948 - val_loss: 0.5353 - val_mse: 0.5353\n",
      "Epoch 99/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5859 - mse: 0.5859 - val_loss: 0.5506 - val_mse: 0.5506\n",
      "Epoch 100/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5770 - mse: 0.5770 - val_loss: 0.5700 - val_mse: 0.5700\n",
      "Epoch 101/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5687 - mse: 0.5687 - val_loss: 0.5861 - val_mse: 0.5861\n",
      "Epoch 102/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5612 - mse: 0.5612 - val_loss: 0.5932 - val_mse: 0.5932\n",
      "Epoch 103/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5539 - mse: 0.5539 - val_loss: 0.5901 - val_mse: 0.5901\n",
      "Epoch 104/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5465 - mse: 0.5465 - val_loss: 0.5810 - val_mse: 0.5810\n",
      "Epoch 105/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5395 - mse: 0.5395 - val_loss: 0.5721 - val_mse: 0.5721\n",
      "Epoch 106/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5331 - mse: 0.5331 - val_loss: 0.5689 - val_mse: 0.5689\n",
      "Epoch 107/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5273 - mse: 0.5273 - val_loss: 0.5734 - val_mse: 0.5734\n",
      "Epoch 108/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5215 - mse: 0.5215 - val_loss: 0.5845 - val_mse: 0.5845\n",
      "Epoch 109/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5160 - mse: 0.5160 - val_loss: 0.5983 - val_mse: 0.5983\n",
      "Epoch 110/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5109 - mse: 0.5109 - val_loss: 0.6098 - val_mse: 0.6098\n",
      "Epoch 111/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5064 - mse: 0.5064 - val_loss: 0.6155 - val_mse: 0.6155\n",
      "Epoch 112/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5022 - mse: 0.5022 - val_loss: 0.6150 - val_mse: 0.6150\n",
      "Epoch 113/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4981 - mse: 0.4981 - val_loss: 0.6112 - val_mse: 0.6112\n",
      "Epoch 114/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4944 - mse: 0.4944 - val_loss: 0.6082 - val_mse: 0.6082\n",
      "Epoch 115/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4911 - mse: 0.4911 - val_loss: 0.6091 - val_mse: 0.6091\n",
      "Epoch 116/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4882 - mse: 0.4882 - val_loss: 0.6149 - val_mse: 0.6149\n",
      "Epoch 117/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4854 - mse: 0.4854 - val_loss: 0.6243 - val_mse: 0.6243\n",
      "Epoch 118/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4829 - mse: 0.4829 - val_loss: 0.6343 - val_mse: 0.6343\n",
      "Epoch 119/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4808 - mse: 0.4808 - val_loss: 0.6418 - val_mse: 0.6418\n",
      "Epoch 120/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4789 - mse: 0.4789 - val_loss: 0.6453 - val_mse: 0.6453\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "r2: 0.4795776272478517 meansquarederror: 0.11585469388084076 meanabsoluteerror: 0.3029149172219825 maxerror: 0.47179772031593714\n",
      "Epoch 1/120\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 4.5705 - mse: 4.5705 - val_loss: 33.4859 - val_mse: 33.4859\n",
      "Epoch 2/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 28.1119 - mse: 28.1119 - val_loss: 7.1323 - val_mse: 7.1323\n",
      "Epoch 3/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.5303 - mse: 5.5303 - val_loss: 1.7524 - val_mse: 1.7524\n",
      "Epoch 4/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.8923 - mse: 4.8923 - val_loss: 8.9962 - val_mse: 8.9962\n",
      "Epoch 5/120\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 14.1487 - mse: 14.1487 - val_loss: 5.0843 - val_mse: 5.0843\n",
      "Epoch 6/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 9.3322 - mse: 9.3322 - val_loss: 0.2162 - val_mse: 0.2162\n",
      "Epoch 7/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.1831 - mse: 2.1831 - val_loss: 2.9092 - val_mse: 2.9092\n",
      "Epoch 8/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.4593 - mse: 2.4593 - val_loss: 8.6419 - val_mse: 8.6419\n",
      "Epoch 9/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.6606 - mse: 6.6606 - val_loss: 9.8004 - val_mse: 9.8004\n",
      "Epoch 10/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.5764 - mse: 7.5764 - val_loss: 6.0152 - val_mse: 6.0152\n",
      "Epoch 11/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.6236 - mse: 4.6236 - val_loss: 1.6557 - val_mse: 1.6557\n",
      "Epoch 12/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.7049 - mse: 1.7049 - val_loss: 0.1162 - val_mse: 0.1162\n",
      "Epoch 13/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.6738 - mse: 1.6738 - val_loss: 0.9884 - val_mse: 0.9884\n",
      "Epoch 14/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6274 - mse: 3.6274 - val_loss: 1.6935 - val_mse: 1.6935\n",
      "Epoch 15/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.7041 - mse: 4.7041 - val_loss: 1.0695 - val_mse: 1.0695\n",
      "Epoch 16/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.7420 - mse: 3.7420 - val_loss: 0.1906 - val_mse: 0.1906\n",
      "Epoch 17/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.0181 - mse: 2.0181 - val_loss: 0.4886 - val_mse: 0.4886\n",
      "Epoch 18/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.2657 - mse: 1.2657 - val_loss: 2.0289 - val_mse: 2.0289\n",
      "Epoch 19/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.8693 - mse: 1.8693 - val_loss: 3.5457 - val_mse: 3.5457\n",
      "Epoch 20/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.8136 - mse: 2.8136 - val_loss: 3.8294 - val_mse: 3.8294\n",
      "Epoch 21/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.0017 - mse: 3.0017 - val_loss: 2.7977 - val_mse: 2.7977\n",
      "Epoch 22/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.3158 - mse: 2.3158 - val_loss: 1.3287 - val_mse: 1.3287\n",
      "Epoch 23/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4885 - mse: 1.4885 - val_loss: 0.3537 - val_mse: 0.3537\n",
      "Epoch 24/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2467 - mse: 1.2467 - val_loss: 0.1274 - val_mse: 0.1274\n",
      "Epoch 25/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.6382 - mse: 1.6382 - val_loss: 0.2466 - val_mse: 0.2466\n",
      "Epoch 26/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.1038 - mse: 2.1038 - val_loss: 0.2579 - val_mse: 0.2579\n",
      "Epoch 27/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.1251 - mse: 2.1251 - val_loss: 0.1416 - val_mse: 0.1416\n",
      "Epoch 28/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.7143 - mse: 1.7143 - val_loss: 0.2134 - val_mse: 0.2134\n",
      "Epoch 29/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.2953 - mse: 1.2953 - val_loss: 0.6783 - val_mse: 0.6783\n",
      "Epoch 30/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2214 - mse: 1.2214 - val_loss: 1.3529 - val_mse: 1.3529\n",
      "Epoch 31/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4565 - mse: 1.4565 - val_loss: 1.8128 - val_mse: 1.8128\n",
      "Epoch 32/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.6834 - mse: 1.6834 - val_loss: 1.7714 - val_mse: 1.7714\n",
      "Epoch 33/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.6555 - mse: 1.6555 - val_loss: 1.3003 - val_mse: 1.3003\n",
      "Epoch 34/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4153 - mse: 1.4153 - val_loss: 0.7220 - val_mse: 0.7220\n",
      "Epoch 35/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2007 - mse: 1.2007 - val_loss: 0.3232 - val_mse: 0.3232\n",
      "Epoch 36/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1862 - mse: 1.1862 - val_loss: 0.1662 - val_mse: 0.1662\n",
      "Epoch 37/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3256 - mse: 1.3256 - val_loss: 0.1396 - val_mse: 0.1396\n",
      "Epoch 38/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4321 - mse: 1.4321 - val_loss: 0.1462 - val_mse: 0.1462\n",
      "Epoch 39/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3850 - mse: 1.3850 - val_loss: 0.2091 - val_mse: 0.2091\n",
      "Epoch 40/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2376 - mse: 1.2376 - val_loss: 0.4015 - val_mse: 0.4015\n",
      "Epoch 41/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1343 - mse: 1.1343 - val_loss: 0.7105 - val_mse: 0.7105\n",
      "Epoch 42/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.1514 - mse: 1.1514 - val_loss: 0.9996 - val_mse: 0.9996\n",
      "Epoch 43/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2326 - mse: 1.2326 - val_loss: 1.1094 - val_mse: 1.1094\n",
      "Epoch 44/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.2681 - mse: 1.2681 - val_loss: 0.9887 - val_mse: 0.9887\n",
      "Epoch 45/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2140 - mse: 1.2140 - val_loss: 0.7268 - val_mse: 0.7268\n",
      "Epoch 46/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1254 - mse: 1.1254 - val_loss: 0.4678 - val_mse: 0.4678\n",
      "Epoch 47/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0843 - mse: 1.0843 - val_loss: 0.3019 - val_mse: 0.3019\n",
      "Epoch 48/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.1103 - mse: 1.1103 - val_loss: 0.2330 - val_mse: 0.2330\n",
      "Epoch 49/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.1503 - mse: 1.1503 - val_loss: 0.2304 - val_mse: 0.2304\n",
      "Epoch 50/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1454 - mse: 1.1454 - val_loss: 0.2851 - val_mse: 0.2851\n",
      "Epoch 51/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0948 - mse: 1.0948 - val_loss: 0.4072 - val_mse: 0.4072\n",
      "Epoch 52/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0471 - mse: 1.0471 - val_loss: 0.5788 - val_mse: 0.5788\n",
      "Epoch 53/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0397 - mse: 1.0397 - val_loss: 0.7341 - val_mse: 0.7341\n",
      "Epoch 54/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0602 - mse: 1.0602 - val_loss: 0.7970 - val_mse: 0.7970\n",
      "Epoch 55/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0680 - mse: 1.0680 - val_loss: 0.7406 - val_mse: 0.7406\n",
      "Epoch 56/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0434 - mse: 1.0434 - val_loss: 0.6052 - val_mse: 0.6052\n",
      "Epoch 57/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0060 - mse: 1.0060 - val_loss: 0.4622 - val_mse: 0.4622\n",
      "Epoch 58/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9867 - mse: 0.9867 - val_loss: 0.3625 - val_mse: 0.3625\n",
      "Epoch 59/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9909 - mse: 0.9909 - val_loss: 0.3195 - val_mse: 0.3195\n",
      "Epoch 60/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9961 - mse: 0.9961 - val_loss: 0.3279 - val_mse: 0.3279\n",
      "Epoch 61/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9826 - mse: 0.9826 - val_loss: 0.3829 - val_mse: 0.3829\n",
      "Epoch 62/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9556 - mse: 0.9556 - val_loss: 0.4752 - val_mse: 0.4752\n",
      "Epoch 63/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9353 - mse: 0.9353 - val_loss: 0.5765 - val_mse: 0.5765\n",
      "Epoch 64/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9305 - mse: 0.9305 - val_loss: 0.6434 - val_mse: 0.6434\n",
      "Epoch 65/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9302 - mse: 0.9302 - val_loss: 0.6454 - val_mse: 0.6454\n",
      "Epoch 66/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9196 - mse: 0.9196 - val_loss: 0.5871 - val_mse: 0.5871\n",
      "Epoch 67/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8989 - mse: 0.8989 - val_loss: 0.5027 - val_mse: 0.5027\n",
      "Epoch 68/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8805 - mse: 0.8805 - val_loss: 0.4299 - val_mse: 0.4299\n",
      "Epoch 69/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8719 - mse: 0.8719 - val_loss: 0.3900 - val_mse: 0.3900\n",
      "Epoch 70/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8671 - mse: 0.8671 - val_loss: 0.3877 - val_mse: 0.3877\n",
      "Epoch 71/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8563 - mse: 0.8563 - val_loss: 0.4197 - val_mse: 0.4197\n",
      "Epoch 72/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8389 - mse: 0.8389 - val_loss: 0.4765 - val_mse: 0.4765\n",
      "Epoch 73/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8227 - mse: 0.8227 - val_loss: 0.5380 - val_mse: 0.5380\n",
      "Epoch 74/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8128 - mse: 0.8128 - val_loss: 0.5781 - val_mse: 0.5781\n",
      "Epoch 75/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8051 - mse: 0.8051 - val_loss: 0.5792 - val_mse: 0.5792\n",
      "Epoch 76/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7934 - mse: 0.7934 - val_loss: 0.5445 - val_mse: 0.5445\n",
      "Epoch 77/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7778 - mse: 0.7778 - val_loss: 0.4946 - val_mse: 0.4946\n",
      "Epoch 78/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7636 - mse: 0.7636 - val_loss: 0.4526 - val_mse: 0.4526\n",
      "Epoch 79/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7534 - mse: 0.7534 - val_loss: 0.4325 - val_mse: 0.4325\n",
      "Epoch 80/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7440 - mse: 0.7440 - val_loss: 0.4381 - val_mse: 0.4381\n",
      "Epoch 81/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7318 - mse: 0.7318 - val_loss: 0.4656 - val_mse: 0.4656\n",
      "Epoch 82/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7177 - mse: 0.7177 - val_loss: 0.5045 - val_mse: 0.5045\n",
      "Epoch 83/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7053 - mse: 0.7053 - val_loss: 0.5387 - val_mse: 0.5387\n",
      "Epoch 84/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6954 - mse: 0.6954 - val_loss: 0.5530 - val_mse: 0.5530\n",
      "Epoch 85/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6852 - mse: 0.6852 - val_loss: 0.5427 - val_mse: 0.5427\n",
      "Epoch 86/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6732 - mse: 0.6732 - val_loss: 0.5159 - val_mse: 0.5159\n",
      "Epoch 87/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6608 - mse: 0.6608 - val_loss: 0.4879 - val_mse: 0.4879\n",
      "Epoch 88/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6502 - mse: 0.6502 - val_loss: 0.4711 - val_mse: 0.4711\n",
      "Epoch 89/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6408 - mse: 0.6408 - val_loss: 0.4712 - val_mse: 0.4712\n",
      "Epoch 90/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6307 - mse: 0.6307 - val_loss: 0.4870 - val_mse: 0.4870\n",
      "Epoch 91/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6197 - mse: 0.6197 - val_loss: 0.5118 - val_mse: 0.5118\n",
      "Epoch 92/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6094 - mse: 0.6094 - val_loss: 0.5350 - val_mse: 0.5350\n",
      "Epoch 93/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6005 - mse: 0.6005 - val_loss: 0.5465 - val_mse: 0.5465\n",
      "Epoch 94/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5920 - mse: 0.5920 - val_loss: 0.5426 - val_mse: 0.5426\n",
      "Epoch 95/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5828 - mse: 0.5828 - val_loss: 0.5282 - val_mse: 0.5282\n",
      "Epoch 96/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5737 - mse: 0.5737 - val_loss: 0.5128 - val_mse: 0.5128\n",
      "Epoch 97/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5656 - mse: 0.5656 - val_loss: 0.5049 - val_mse: 0.5049\n",
      "Epoch 98/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5583 - mse: 0.5583 - val_loss: 0.5080 - val_mse: 0.5080\n",
      "Epoch 99/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5510 - mse: 0.5510 - val_loss: 0.5211 - val_mse: 0.5211\n",
      "Epoch 100/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5435 - mse: 0.5435 - val_loss: 0.5387 - val_mse: 0.5387\n",
      "Epoch 101/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5367 - mse: 0.5367 - val_loss: 0.5534 - val_mse: 0.5534\n",
      "Epoch 102/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5307 - mse: 0.5307 - val_loss: 0.5598 - val_mse: 0.5598\n",
      "Epoch 103/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5250 - mse: 0.5250 - val_loss: 0.5570 - val_mse: 0.5570\n",
      "Epoch 104/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5192 - mse: 0.5192 - val_loss: 0.5496 - val_mse: 0.5496\n",
      "Epoch 105/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5139 - mse: 0.5139 - val_loss: 0.5438 - val_mse: 0.5438\n",
      "Epoch 106/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5093 - mse: 0.5093 - val_loss: 0.5441 - val_mse: 0.5441\n",
      "Epoch 107/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5051 - mse: 0.5051 - val_loss: 0.5515 - val_mse: 0.5515\n",
      "Epoch 108/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5009 - mse: 0.5009 - val_loss: 0.5638 - val_mse: 0.5638\n",
      "Epoch 109/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4971 - mse: 0.4971 - val_loss: 0.5764 - val_mse: 0.5764\n",
      "Epoch 110/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4938 - mse: 0.4938 - val_loss: 0.5848 - val_mse: 0.5848\n",
      "Epoch 111/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4909 - mse: 0.4909 - val_loss: 0.5873 - val_mse: 0.5873\n",
      "Epoch 112/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4882 - mse: 0.4882 - val_loss: 0.5855 - val_mse: 0.5855\n",
      "Epoch 113/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4856 - mse: 0.4856 - val_loss: 0.5835 - val_mse: 0.5835\n",
      "Epoch 114/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4835 - mse: 0.4835 - val_loss: 0.5846 - val_mse: 0.5846\n",
      "Epoch 115/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4817 - mse: 0.4817 - val_loss: 0.5902 - val_mse: 0.5902\n",
      "Epoch 116/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4801 - mse: 0.4801 - val_loss: 0.5993 - val_mse: 0.5993\n",
      "Epoch 117/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4786 - mse: 0.4786 - val_loss: 0.6091 - val_mse: 0.6091\n",
      "Epoch 118/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4774 - mse: 0.4774 - val_loss: 0.6165 - val_mse: 0.6165\n",
      "Epoch 119/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4764 - mse: 0.4764 - val_loss: 0.6201 - val_mse: 0.6201\n",
      "Epoch 120/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4755 - mse: 0.4755 - val_loss: 0.6207 - val_mse: 0.6207\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "r2: 0.44777560918866777 meansquarederror: 0.12293435313444943 meanabsoluteerror: 0.3116642232447587 maxerror: 0.49391686463809625\n",
      "Epoch 1/120\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 1.5235 - mse: 1.5235 - val_loss: 53.8271 - val_mse: 53.8271\n",
      "Epoch 2/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 46.4506 - mse: 46.4506 - val_loss: 5.8664 - val_mse: 5.8664\n",
      "Epoch 3/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.5384 - mse: 4.5384 - val_loss: 7.1725 - val_mse: 7.1725\n",
      "Epoch 4/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 11.9610 - mse: 11.9610 - val_loss: 19.0025 - val_mse: 19.0025\n",
      "Epoch 5/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 25.7656 - mse: 25.7656 - val_loss: 11.7545 - val_mse: 11.7545\n",
      "Epoch 6/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 17.3984 - mse: 17.3984 - val_loss: 1.6520 - val_mse: 1.6520\n",
      "Epoch 7/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7163 - mse: 4.7163 - val_loss: 1.5648 - val_mse: 1.5648\n",
      "Epoch 8/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.6723 - mse: 1.6723 - val_loss: 9.6236 - val_mse: 9.6236\n",
      "Epoch 9/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 7.4050 - mse: 7.4050 - val_loss: 15.4339 - val_mse: 15.4339\n",
      "Epoch 10/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 12.1663 - mse: 12.1663 - val_loss: 13.8962 - val_mse: 13.8962\n",
      "Epoch 11/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 10.8753 - mse: 10.8753 - val_loss: 7.7213 - val_mse: 7.7213\n",
      "Epoch 12/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.8909 - mse: 5.8909 - val_loss: 2.0900 - val_mse: 2.0900\n",
      "Epoch 13/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.9279 - mse: 1.9279 - val_loss: 0.1180 - val_mse: 0.1180\n",
      "Epoch 14/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.6263 - mse: 1.6263 - val_loss: 1.2236 - val_mse: 1.2236\n",
      "Epoch 15/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.0094 - mse: 4.0094 - val_loss: 2.7301 - val_mse: 2.7301\n",
      "Epoch 16/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.1744 - mse: 6.1744 - val_loss: 2.7560 - val_mse: 2.7560\n",
      "Epoch 17/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.2033 - mse: 6.2033 - val_loss: 1.4651 - val_mse: 1.4651\n",
      "Epoch 18/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.3615 - mse: 4.3615 - val_loss: 0.2687 - val_mse: 0.2687\n",
      "Epoch 19/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.2416 - mse: 2.2416 - val_loss: 0.3769 - val_mse: 0.3769\n",
      "Epoch 20/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2765 - mse: 1.2765 - val_loss: 1.8596 - val_mse: 1.8596\n",
      "Epoch 21/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.7680 - mse: 1.7680 - val_loss: 3.7231 - val_mse: 3.7231\n",
      "Epoch 22/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.9170 - mse: 2.9170 - val_loss: 4.7731 - val_mse: 4.7731\n",
      "Epoch 23/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.6441 - mse: 3.6441 - val_loss: 4.4668 - val_mse: 4.4668\n",
      "Epoch 24/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.4235 - mse: 3.4235 - val_loss: 3.1313 - val_mse: 3.1313\n",
      "Epoch 25/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.5146 - mse: 2.5146 - val_loss: 1.5751 - val_mse: 1.5751\n",
      "Epoch 26/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6012 - mse: 1.6012 - val_loss: 0.5026 - val_mse: 0.5026\n",
      "Epoch 27/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2384 - mse: 1.2384 - val_loss: 0.1329 - val_mse: 0.1329\n",
      "Epoch 28/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.5023 - mse: 1.5023 - val_loss: 0.2151 - val_mse: 0.2151\n",
      "Epoch 29/120\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.0305 - mse: 2.0305 - val_loss: 0.3455 - val_mse: 0.3455\n",
      "Epoch 30/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.3570 - mse: 2.3570 - val_loss: 0.3028 - val_mse: 0.3028\n",
      "Epoch 31/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2509 - mse: 2.2509 - val_loss: 0.1620 - val_mse: 0.1620\n",
      "Epoch 32/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.8248 - mse: 1.8248 - val_loss: 0.1610 - val_mse: 0.1610\n",
      "Epoch 33/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.3899 - mse: 1.3899 - val_loss: 0.4687 - val_mse: 0.4687\n",
      "Epoch 34/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2085 - mse: 1.2085 - val_loss: 1.0331 - val_mse: 1.0331\n",
      "Epoch 35/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3254 - mse: 1.3254 - val_loss: 1.6086 - val_mse: 1.6086\n",
      "Epoch 36/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.5757 - mse: 1.5757 - val_loss: 1.9211 - val_mse: 1.9211\n",
      "Epoch 37/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.7358 - mse: 1.7358 - val_loss: 1.8404 - val_mse: 1.8404\n",
      "Epoch 38/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.6874 - mse: 1.6874 - val_loss: 1.4407 - val_mse: 1.4407\n",
      "Epoch 39/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4798 - mse: 1.4798 - val_loss: 0.9277 - val_mse: 0.9277\n",
      "Epoch 40/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2652 - mse: 1.2652 - val_loss: 0.5020 - val_mse: 0.5020\n",
      "Epoch 41/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1751 - mse: 1.1751 - val_loss: 0.2558 - val_mse: 0.2558\n",
      "Epoch 42/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2326 - mse: 1.2326 - val_loss: 0.1627 - val_mse: 0.1627\n",
      "Epoch 43/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.3541 - mse: 1.3541 - val_loss: 0.1439 - val_mse: 0.1439\n",
      "Epoch 44/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.4267 - mse: 1.4267 - val_loss: 0.1498 - val_mse: 0.1498\n",
      "Epoch 45/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.3933 - mse: 1.3933 - val_loss: 0.1914 - val_mse: 0.1914\n",
      "Epoch 46/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.2832 - mse: 1.2832 - val_loss: 0.3101 - val_mse: 0.3101\n",
      "Epoch 47/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.1765 - mse: 1.1765 - val_loss: 0.5203 - val_mse: 0.5203\n",
      "Epoch 48/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.1381 - mse: 1.1381 - val_loss: 0.7757 - val_mse: 0.7757\n",
      "Epoch 49/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.1725 - mse: 1.1725 - val_loss: 0.9859 - val_mse: 0.9859\n",
      "Epoch 50/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2308 - mse: 1.2308 - val_loss: 1.0691 - val_mse: 1.0691\n",
      "Epoch 51/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2554 - mse: 1.2554 - val_loss: 1.0005 - val_mse: 1.0005\n",
      "Epoch 52/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2239 - mse: 1.2239 - val_loss: 0.8218 - val_mse: 0.8218\n",
      "Epoch 53/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1604 - mse: 1.1604 - val_loss: 0.6098 - val_mse: 0.6098\n",
      "Epoch 54/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.1092 - mse: 1.1092 - val_loss: 0.4320 - val_mse: 0.4320\n",
      "Epoch 55/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0983 - mse: 1.0983 - val_loss: 0.3186 - val_mse: 0.3186\n",
      "Epoch 56/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1203 - mse: 1.1203 - val_loss: 0.2660 - val_mse: 0.2660\n",
      "Epoch 57/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1439 - mse: 1.1439 - val_loss: 0.2600 - val_mse: 0.2600\n",
      "Epoch 58/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1423 - mse: 1.1423 - val_loss: 0.2944 - val_mse: 0.2944\n",
      "Epoch 59/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1129 - mse: 1.1129 - val_loss: 0.3709 - val_mse: 0.3709\n",
      "Epoch 60/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0757 - mse: 1.0757 - val_loss: 0.4847 - val_mse: 0.4847\n",
      "Epoch 61/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0538 - mse: 1.0538 - val_loss: 0.6124 - val_mse: 0.6124\n",
      "Epoch 62/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0541 - mse: 1.0541 - val_loss: 0.7156 - val_mse: 0.7156\n",
      "Epoch 63/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0646 - mse: 1.0646 - val_loss: 0.7599 - val_mse: 0.7599\n",
      "Epoch 64/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0672 - mse: 1.0672 - val_loss: 0.7334 - val_mse: 0.7334\n",
      "Epoch 65/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0531 - mse: 1.0531 - val_loss: 0.6524 - val_mse: 0.6524\n",
      "Epoch 66/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0291 - mse: 1.0291 - val_loss: 0.5498 - val_mse: 0.5498\n",
      "Epoch 67/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0090 - mse: 1.0090 - val_loss: 0.4576 - val_mse: 0.4576\n",
      "Epoch 68/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0011 - mse: 1.0011 - val_loss: 0.3947 - val_mse: 0.3947\n",
      "Epoch 69/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0020 - mse: 1.0020 - val_loss: 0.3662 - val_mse: 0.3662\n",
      "Epoch 70/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0012 - mse: 1.0012 - val_loss: 0.3707 - val_mse: 0.3707\n",
      "Epoch 71/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9916 - mse: 0.9916 - val_loss: 0.4048 - val_mse: 0.4048\n",
      "Epoch 72/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.4628 - val_mse: 0.4628\n",
      "Epoch 73/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9584 - mse: 0.9584 - val_loss: 0.5326 - val_mse: 0.5326\n",
      "Epoch 74/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9483 - mse: 0.9483 - val_loss: 0.5954 - val_mse: 0.5954\n",
      "Epoch 75/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9439 - mse: 0.9439 - val_loss: 0.6321 - val_mse: 0.6321\n",
      "Epoch 76/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9395 - mse: 0.9395 - val_loss: 0.6324 - val_mse: 0.6324\n",
      "Epoch 77/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9302 - mse: 0.9302 - val_loss: 0.5995 - val_mse: 0.5995\n",
      "Epoch 78/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9165 - mse: 0.9165 - val_loss: 0.5479 - val_mse: 0.5479\n",
      "Epoch 79/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9027 - mse: 0.9027 - val_loss: 0.4955 - val_mse: 0.4955\n",
      "Epoch 80/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8924 - mse: 0.8924 - val_loss: 0.4561 - val_mse: 0.4561\n",
      "Epoch 81/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8853 - mse: 0.8853 - val_loss: 0.4369 - val_mse: 0.4369\n",
      "Epoch 82/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8782 - mse: 0.8782 - val_loss: 0.4395 - val_mse: 0.4395\n",
      "Epoch 83/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8681 - mse: 0.8681 - val_loss: 0.4615 - val_mse: 0.4615\n",
      "Epoch 84/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8557 - mse: 0.8557 - val_loss: 0.4973 - val_mse: 0.4973\n",
      "Epoch 85/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8434 - mse: 0.8434 - val_loss: 0.5373 - val_mse: 0.5373\n",
      "Epoch 86/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8334 - mse: 0.8334 - val_loss: 0.5702 - val_mse: 0.5702\n",
      "Epoch 87/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8249 - mse: 0.8249 - val_loss: 0.5861 - val_mse: 0.5861\n",
      "Epoch 88/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8160 - mse: 0.8160 - val_loss: 0.5814 - val_mse: 0.5814\n",
      "Epoch 89/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8054 - mse: 0.8054 - val_loss: 0.5600 - val_mse: 0.5600\n",
      "Epoch 90/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7936 - mse: 0.7936 - val_loss: 0.5309 - val_mse: 0.5309\n",
      "Epoch 91/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7824 - mse: 0.7824 - val_loss: 0.5042 - val_mse: 0.5042\n",
      "Epoch 92/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7726 - mse: 0.7726 - val_loss: 0.4873 - val_mse: 0.4873\n",
      "Epoch 93/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7634 - mse: 0.7634 - val_loss: 0.4839 - val_mse: 0.4839\n",
      "Epoch 94/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7537 - mse: 0.7537 - val_loss: 0.4936 - val_mse: 0.4936\n",
      "Epoch 95/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7429 - mse: 0.7429 - val_loss: 0.5134 - val_mse: 0.5134\n",
      "Epoch 96/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7319 - mse: 0.7319 - val_loss: 0.5373 - val_mse: 0.5373\n",
      "Epoch 97/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7216 - mse: 0.7216 - val_loss: 0.5583 - val_mse: 0.5583\n",
      "Epoch 98/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7121 - mse: 0.7121 - val_loss: 0.5701 - val_mse: 0.5701\n",
      "Epoch 99/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7028 - mse: 0.7028 - val_loss: 0.5700 - val_mse: 0.5700\n",
      "Epoch 100/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6929 - mse: 0.6929 - val_loss: 0.5598 - val_mse: 0.5598\n",
      "Epoch 101/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6827 - mse: 0.6827 - val_loss: 0.5444 - val_mse: 0.5444\n",
      "Epoch 102/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6728 - mse: 0.6728 - val_loss: 0.5301 - val_mse: 0.5301\n",
      "Epoch 103/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6634 - mse: 0.6634 - val_loss: 0.5217 - val_mse: 0.5217\n",
      "Epoch 104/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6545 - mse: 0.6545 - val_loss: 0.5217 - val_mse: 0.5217\n",
      "Epoch 105/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6455 - mse: 0.6455 - val_loss: 0.5297 - val_mse: 0.5297\n",
      "Epoch 106/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6363 - mse: 0.6363 - val_loss: 0.5433 - val_mse: 0.5433\n",
      "Epoch 107/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6272 - mse: 0.6272 - val_loss: 0.5583 - val_mse: 0.5583\n",
      "Epoch 108/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6186 - mse: 0.6186 - val_loss: 0.5703 - val_mse: 0.5703\n",
      "Epoch 109/120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6104 - mse: 0.6104 - val_loss: 0.5760 - val_mse: 0.5760\n",
      "Epoch 110/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6024 - mse: 0.6024 - val_loss: 0.5748 - val_mse: 0.5748\n",
      "Epoch 111/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5944 - mse: 0.5944 - val_loss: 0.5686 - val_mse: 0.5686\n",
      "Epoch 112/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5865 - mse: 0.5865 - val_loss: 0.5611 - val_mse: 0.5611\n",
      "Epoch 113/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5790 - mse: 0.5790 - val_loss: 0.5557 - val_mse: 0.5557\n",
      "Epoch 114/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5719 - mse: 0.5719 - val_loss: 0.5550 - val_mse: 0.5550\n",
      "Epoch 115/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5650 - mse: 0.5650 - val_loss: 0.5595 - val_mse: 0.5595\n",
      "Epoch 116/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5583 - mse: 0.5583 - val_loss: 0.5681 - val_mse: 0.5681\n",
      "Epoch 117/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5518 - mse: 0.5518 - val_loss: 0.5784 - val_mse: 0.5784\n",
      "Epoch 118/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5456 - mse: 0.5456 - val_loss: 0.5875 - val_mse: 0.5875\n",
      "Epoch 119/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5398 - mse: 0.5398 - val_loss: 0.5933 - val_mse: 0.5933\n",
      "Epoch 120/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5343 - mse: 0.5343 - val_loss: 0.5948 - val_mse: 0.5948\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "r2: 0.37426619686853946 meansquarederror: 0.13929877347378197 meanabsoluteerror: 0.34316465426799253 maxerror: 0.5104020372817408\n",
      "Epoch 1/120\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 2.8609 - mse: 2.8609 - val_loss: 42.7237 - val_mse: 42.7237\n",
      "Epoch 2/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 36.3887 - mse: 36.3887 - val_loss: 6.1591 - val_mse: 6.1591\n",
      "Epoch 3/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4.7744 - mse: 4.7744 - val_loss: 4.2976 - val_mse: 4.2976\n",
      "Epoch 4/120\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.3844 - mse: 8.3844 - val_loss: 13.2707 - val_mse: 13.2707\n",
      "Epoch 5/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 19.2318 - mse: 19.2318 - val_loss: 7.1875 - val_mse: 7.1875\n",
      "Epoch 6/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 11.9785 - mse: 11.9785 - val_loss: 0.3948 - val_mse: 0.3948\n",
      "Epoch 7/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.6307 - mse: 2.6307 - val_loss: 2.9976 - val_mse: 2.9976\n",
      "Epoch 8/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.5128 - mse: 2.5128 - val_loss: 10.2125 - val_mse: 10.2125\n",
      "Epoch 9/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.8949 - mse: 7.8949 - val_loss: 12.6818 - val_mse: 12.6818\n",
      "Epoch 10/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 9.8995 - mse: 9.8995 - val_loss: 8.8304 - val_mse: 8.8304\n",
      "Epoch 11/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.7801 - mse: 6.7801 - val_loss: 3.1968 - val_mse: 3.1968\n",
      "Epoch 12/120\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.6203 - mse: 2.6203 - val_loss: 0.2526 - val_mse: 0.2526\n",
      "Epoch 13/120\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.3570 - mse: 1.3570 - val_loss: 0.7285 - val_mse: 0.7285\n",
      "Epoch 14/120\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.2131 - mse: 3.2131 - val_loss: 2.1075 - val_mse: 2.1075\n",
      "Epoch 15/120\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.3285 - mse: 5.3285 - val_loss: 2.1290 - val_mse: 2.1290\n",
      "Epoch 16/120\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.3510 - mse: 5.3510 - val_loss: 0.9291 - val_mse: 0.9291\n",
      "Epoch 17/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.5325 - mse: 3.5325 - val_loss: 0.1216 - val_mse: 0.1216\n",
      "Epoch 18/120\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.7212 - mse: 1.7212 - val_loss: 0.8344 - val_mse: 0.8344\n",
      "Epoch 19/120\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.3330 - mse: 1.3330 - val_loss: 2.6627 - val_mse: 2.6627\n",
      "Epoch 20/120\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.2456 - mse: 2.2456 - val_loss: 4.1948 - val_mse: 4.1948\n",
      "Epoch 21/120\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.2542 - mse: 3.2542 - val_loss: 4.3524 - val_mse: 4.3524\n",
      "Epoch 22/120\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.3605 - mse: 3.3605 - val_loss: 3.1802 - val_mse: 3.1802\n",
      "Epoch 23/120\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.5617 - mse: 2.5617 - val_loss: 1.5733 - val_mse: 1.5733\n",
      "Epoch 24/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.6126 - mse: 1.6126 - val_loss: 0.4527 - val_mse: 0.4527\n",
      "Epoch 25/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.2471 - mse: 1.2471 - val_loss: 0.1235 - val_mse: 0.1235\n",
      "Epoch 26/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.5827 - mse: 1.5827 - val_loss: 0.2488 - val_mse: 0.2488\n",
      "Epoch 27/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.1371 - mse: 2.1371 - val_loss: 0.3364 - val_mse: 0.3364\n",
      "Epoch 28/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.3445 - mse: 2.3445 - val_loss: 0.2215 - val_mse: 0.2215\n",
      "Epoch 29/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.0454 - mse: 2.0454 - val_loss: 0.1276 - val_mse: 0.1276\n",
      "Epoch 30/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5356 - mse: 1.5356 - val_loss: 0.3552 - val_mse: 0.3552\n",
      "Epoch 31/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2316 - mse: 1.2316 - val_loss: 0.9437 - val_mse: 0.9437\n",
      "Epoch 32/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3055 - mse: 1.3055 - val_loss: 1.6063 - val_mse: 1.6063\n",
      "Epoch 33/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.5878 - mse: 1.5878 - val_loss: 1.9602 - val_mse: 1.9602\n",
      "Epoch 34/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.7712 - mse: 1.7712 - val_loss: 1.8219 - val_mse: 1.8219\n",
      "Epoch 35/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.6908 - mse: 1.6908 - val_loss: 1.3157 - val_mse: 1.3157\n",
      "Epoch 36/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.4336 - mse: 1.4336 - val_loss: 0.7410 - val_mse: 0.7410\n",
      "Epoch 37/120\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2206 - mse: 1.2206 - val_loss: 0.3421 - val_mse: 0.3421\n",
      "Epoch 38/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.1990 - mse: 1.1990 - val_loss: 0.1726 - val_mse: 0.1726\n",
      "Epoch 39/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.3303 - mse: 1.3303 - val_loss: 0.1378 - val_mse: 0.1378\n",
      "Epoch 40/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.4541 - mse: 1.4541 - val_loss: 0.1389 - val_mse: 0.1389\n",
      "Epoch 41/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.4461 - mse: 1.4461 - val_loss: 0.1719 - val_mse: 0.1719\n",
      "Epoch 42/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3184 - mse: 1.3184 - val_loss: 0.3009 - val_mse: 0.3009\n",
      "Epoch 43/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1858 - mse: 1.1858 - val_loss: 0.5548 - val_mse: 0.5548\n",
      "Epoch 44/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1485 - mse: 1.1485 - val_loss: 0.8613 - val_mse: 0.8613\n",
      "Epoch 45/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2069 - mse: 1.2069 - val_loss: 1.0812 - val_mse: 1.0812\n",
      "Epoch 46/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2779 - mse: 1.2779 - val_loss: 1.1087 - val_mse: 1.1087\n",
      "Epoch 47/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2825 - mse: 1.2825 - val_loss: 0.9453 - val_mse: 0.9453\n",
      "Epoch 48/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2150 - mse: 1.2150 - val_loss: 0.6883 - val_mse: 0.6883\n",
      "Epoch 49/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1359 - mse: 1.1359 - val_loss: 0.4535 - val_mse: 0.4535\n",
      "Epoch 50/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1067 - mse: 1.1067 - val_loss: 0.3040 - val_mse: 0.3040\n",
      "Epoch 51/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1334 - mse: 1.1334 - val_loss: 0.2387 - val_mse: 0.2387\n",
      "Epoch 52/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1699 - mse: 1.1699 - val_loss: 0.2323 - val_mse: 0.2323\n",
      "Epoch 53/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1693 - mse: 1.1693 - val_loss: 0.2759 - val_mse: 0.2759\n",
      "Epoch 54/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1275 - mse: 1.1275 - val_loss: 0.3765 - val_mse: 0.3765\n",
      "Epoch 55/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0801 - mse: 1.0801 - val_loss: 0.5263 - val_mse: 0.5263\n",
      "Epoch 56/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0623 - mse: 1.0623 - val_loss: 0.6818 - val_mse: 0.6818\n",
      "Epoch 57/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0752 - mse: 1.0752 - val_loss: 0.7800 - val_mse: 0.7800\n",
      "Epoch 58/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0905 - mse: 1.0905 - val_loss: 0.7800 - val_mse: 0.7800\n",
      "Epoch 59/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0823 - mse: 1.0823 - val_loss: 0.6899 - val_mse: 0.6899\n",
      "Epoch 60/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0521 - mse: 1.0521 - val_loss: 0.5580 - val_mse: 0.5580\n",
      "Epoch 61/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.0231 - mse: 1.0231 - val_loss: 0.4377 - val_mse: 0.4377\n",
      "Epoch 62/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0132 - mse: 1.0132 - val_loss: 0.3596 - val_mse: 0.3596\n",
      "Epoch 63/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0185 - mse: 1.0185 - val_loss: 0.3290 - val_mse: 0.3290\n",
      "Epoch 64/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0202 - mse: 1.0202 - val_loss: 0.3417 - val_mse: 0.3417\n",
      "Epoch 65/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0064 - mse: 1.0064 - val_loss: 0.3935 - val_mse: 0.3935\n",
      "Epoch 66/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9831 - mse: 0.9831 - val_loss: 0.4757 - val_mse: 0.4757\n",
      "Epoch 67/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9650 - mse: 0.9650 - val_loss: 0.5660 - val_mse: 0.5660\n",
      "Epoch 68/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9591 - mse: 0.9591 - val_loss: 0.6318 - val_mse: 0.6318\n",
      "Epoch 69/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9581 - mse: 0.9581 - val_loss: 0.6474 - val_mse: 0.6474\n",
      "Epoch 70/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9508 - mse: 0.9508 - val_loss: 0.6102 - val_mse: 0.6102\n",
      "Epoch 71/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9346 - mse: 0.9346 - val_loss: 0.5411 - val_mse: 0.5411\n",
      "Epoch 72/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9167 - mse: 0.9167 - val_loss: 0.4700 - val_mse: 0.4700\n",
      "Epoch 73/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9050 - mse: 0.9050 - val_loss: 0.4193 - val_mse: 0.4193\n",
      "Epoch 74/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8993 - mse: 0.8993 - val_loss: 0.3986 - val_mse: 0.3986\n",
      "Epoch 75/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8925 - mse: 0.8925 - val_loss: 0.4083 - val_mse: 0.4083\n",
      "Epoch 76/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8800 - mse: 0.8800 - val_loss: 0.4442 - val_mse: 0.4442\n",
      "Epoch 77/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8643 - mse: 0.8643 - val_loss: 0.4962 - val_mse: 0.4962\n",
      "Epoch 78/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8510 - mse: 0.8510 - val_loss: 0.5474 - val_mse: 0.5474\n",
      "Epoch 79/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8420 - mse: 0.8420 - val_loss: 0.5786 - val_mse: 0.5786\n",
      "Epoch 80/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8339 - mse: 0.8339 - val_loss: 0.5787 - val_mse: 0.5787\n",
      "Epoch 81/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8228 - mse: 0.8228 - val_loss: 0.5507 - val_mse: 0.5507\n",
      "Epoch 82/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8089 - mse: 0.8089 - val_loss: 0.5092 - val_mse: 0.5092\n",
      "Epoch 83/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7956 - mse: 0.7956 - val_loss: 0.4714 - val_mse: 0.4714\n",
      "Epoch 84/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7852 - mse: 0.7852 - val_loss: 0.4492 - val_mse: 0.4492\n",
      "Epoch 85/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7759 - mse: 0.7759 - val_loss: 0.4474 - val_mse: 0.4474\n",
      "Epoch 86/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7650 - mse: 0.7650 - val_loss: 0.4646 - val_mse: 0.4646\n",
      "Epoch 87/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7523 - mse: 0.7523 - val_loss: 0.4947 - val_mse: 0.4947\n",
      "Epoch 88/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7398 - mse: 0.7398 - val_loss: 0.5270 - val_mse: 0.5270\n",
      "Epoch 89/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7290 - mse: 0.7290 - val_loss: 0.5497 - val_mse: 0.5497\n",
      "Epoch 90/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7192 - mse: 0.7192 - val_loss: 0.5544 - val_mse: 0.5544\n",
      "Epoch 91/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7085 - mse: 0.7085 - val_loss: 0.5412 - val_mse: 0.5412\n",
      "Epoch 92/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6968 - mse: 0.6968 - val_loss: 0.5182 - val_mse: 0.5182\n",
      "Epoch 93/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6852 - mse: 0.6852 - val_loss: 0.4961 - val_mse: 0.4961\n",
      "Epoch 94/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6749 - mse: 0.6749 - val_loss: 0.4833 - val_mse: 0.4833\n",
      "Epoch 95/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6652 - mse: 0.6652 - val_loss: 0.4836 - val_mse: 0.4836\n",
      "Epoch 96/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6551 - mse: 0.6551 - val_loss: 0.4962 - val_mse: 0.4962\n",
      "Epoch 97/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6445 - mse: 0.6445 - val_loss: 0.5162 - val_mse: 0.5162\n",
      "Epoch 98/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6342 - mse: 0.6342 - val_loss: 0.5361 - val_mse: 0.5361\n",
      "Epoch 99/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6248 - mse: 0.6248 - val_loss: 0.5485 - val_mse: 0.5485\n",
      "Epoch 100/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6159 - mse: 0.6159 - val_loss: 0.5496 - val_mse: 0.5496\n",
      "Epoch 101/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6068 - mse: 0.6068 - val_loss: 0.5408 - val_mse: 0.5408\n",
      "Epoch 102/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5975 - mse: 0.5975 - val_loss: 0.5280 - val_mse: 0.5280\n",
      "Epoch 103/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5888 - mse: 0.5888 - val_loss: 0.5179 - val_mse: 0.5179\n",
      "Epoch 104/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5807 - mse: 0.5807 - val_loss: 0.5151 - val_mse: 0.5151\n",
      "Epoch 105/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5730 - mse: 0.5730 - val_loss: 0.5208 - val_mse: 0.5208\n",
      "Epoch 106/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5652 - mse: 0.5652 - val_loss: 0.5329 - val_mse: 0.5329\n",
      "Epoch 107/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5576 - mse: 0.5576 - val_loss: 0.5471 - val_mse: 0.5471\n",
      "Epoch 108/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5506 - mse: 0.5506 - val_loss: 0.5584 - val_mse: 0.5584\n",
      "Epoch 109/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5441 - mse: 0.5441 - val_loss: 0.5631 - val_mse: 0.5631\n",
      "Epoch 110/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5379 - mse: 0.5379 - val_loss: 0.5613 - val_mse: 0.5613\n",
      "Epoch 111/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5317 - mse: 0.5317 - val_loss: 0.5558 - val_mse: 0.5558\n",
      "Epoch 112/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5260 - mse: 0.5260 - val_loss: 0.5511 - val_mse: 0.5511\n",
      "Epoch 113/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5207 - mse: 0.5207 - val_loss: 0.5504 - val_mse: 0.5504\n",
      "Epoch 114/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5159 - mse: 0.5159 - val_loss: 0.5551 - val_mse: 0.5551\n",
      "Epoch 115/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5112 - mse: 0.5112 - val_loss: 0.5640 - val_mse: 0.5640\n",
      "Epoch 116/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5068 - mse: 0.5068 - val_loss: 0.5745 - val_mse: 0.5745\n",
      "Epoch 117/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5028 - mse: 0.5028 - val_loss: 0.5833 - val_mse: 0.5833\n",
      "Epoch 118/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4992 - mse: 0.4992 - val_loss: 0.5882 - val_mse: 0.5882\n",
      "Epoch 119/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4958 - mse: 0.4958 - val_loss: 0.5890 - val_mse: 0.5890\n",
      "Epoch 120/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4927 - mse: 0.4927 - val_loss: 0.5877 - val_mse: 0.5877\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "r2: 0.3939892650551041 meansquarederror: 0.1349080897776496 meanabsoluteerror: 0.33017174293341234 maxerror: 0.5183895023670542\n",
      "Epoch 1/120\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 1.8158 - mse: 1.8158 - val_loss: 32.8484 - val_mse: 32.8484\n",
      "Epoch 2/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 41.3739 - mse: 41.3739 - val_loss: 1.4381 - val_mse: 1.4381\n",
      "Epoch 3/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.4195 - mse: 4.4195 - val_loss: 13.3713 - val_mse: 13.3713\n",
      "Epoch 4/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 10.6001 - mse: 10.6001 - val_loss: 27.3382 - val_mse: 27.3382\n",
      "Epoch 5/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 22.6533 - mse: 22.6533 - val_loss: 18.0683 - val_mse: 18.0683\n",
      "Epoch 6/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 14.5471 - mse: 14.5471 - val_loss: 4.4671 - val_mse: 4.4671\n",
      "Epoch 7/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.5344 - mse: 3.5344 - val_loss: 0.1702 - val_mse: 0.1702\n",
      "Epoch 8/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.0328 - mse: 2.0328 - val_loss: 3.8179 - val_mse: 3.8179\n",
      "Epoch 9/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.6738 - mse: 7.6738 - val_loss: 6.5932 - val_mse: 6.5932\n",
      "Epoch 10/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 11.1732 - mse: 11.1732 - val_loss: 4.8896 - val_mse: 4.8896\n",
      "Epoch 11/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 9.0367 - mse: 9.0367 - val_loss: 1.4283 - val_mse: 1.4283\n",
      "Epoch 12/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.3411 - mse: 4.3411 - val_loss: 0.1570 - val_mse: 0.1570\n",
      "Epoch 13/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4527 - mse: 1.4527 - val_loss: 2.3656 - val_mse: 2.3656\n",
      "Epoch 14/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.1016 - mse: 2.1016 - val_loss: 5.9394 - val_mse: 5.9394\n",
      "Epoch 15/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.5623 - mse: 4.5623 - val_loss: 7.8165 - val_mse: 7.8165\n",
      "Epoch 16/120\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.9931 - mse: 5.9931 - val_loss: 6.8097 - val_mse: 6.8097\n",
      "Epoch 17/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.2108 - mse: 5.2108 - val_loss: 4.0217 - val_mse: 4.0217\n",
      "Epoch 18/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.1619 - mse: 3.1619 - val_loss: 1.4016 - val_mse: 1.4016\n",
      "Epoch 19/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.5562 - mse: 1.5562 - val_loss: 0.1912 - val_mse: 0.1912\n",
      "Epoch 20/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3769 - mse: 1.3769 - val_loss: 0.3024 - val_mse: 0.3024\n",
      "Epoch 21/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.3118 - mse: 2.3118 - val_loss: 0.8079 - val_mse: 0.8079\n",
      "Epoch 22/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.2877 - mse: 3.2877 - val_loss: 0.9135 - val_mse: 0.9135\n",
      "Epoch 23/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.4600 - mse: 3.4600 - val_loss: 0.5318 - val_mse: 0.5318\n",
      "Epoch 24/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.7777 - mse: 2.7777 - val_loss: 0.1497 - val_mse: 0.1497\n",
      "Epoch 25/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.8275 - mse: 1.8275 - val_loss: 0.2949 - val_mse: 0.2949\n",
      "Epoch 26/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2761 - mse: 1.2761 - val_loss: 1.0718 - val_mse: 1.0718\n",
      "Epoch 27/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3794 - mse: 1.3794 - val_loss: 2.0838 - val_mse: 2.0838\n",
      "Epoch 28/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.8750 - mse: 1.8750 - val_loss: 2.7491 - val_mse: 2.7491\n",
      "Epoch 29/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.2709 - mse: 2.2709 - val_loss: 2.7217 - val_mse: 2.7217\n",
      "Epoch 30/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.2494 - mse: 2.2494 - val_loss: 2.0847 - val_mse: 2.0847\n",
      "Epoch 31/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.8624 - mse: 1.8624 - val_loss: 1.2245 - val_mse: 1.2245\n",
      "Epoch 32/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4190 - mse: 1.4190 - val_loss: 0.5373 - val_mse: 0.5373\n",
      "Epoch 33/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2134 - mse: 1.2134 - val_loss: 0.1979 - val_mse: 0.1979\n",
      "Epoch 34/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.3164 - mse: 1.3164 - val_loss: 0.1292 - val_mse: 0.1292\n",
      "Epoch 35/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.5652 - mse: 1.5652 - val_loss: 0.1475 - val_mse: 0.1475\n",
      "Epoch 36/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.7243 - mse: 1.7243 - val_loss: 0.1401 - val_mse: 0.1401\n",
      "Epoch 37/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.6695 - mse: 1.6695 - val_loss: 0.1369 - val_mse: 0.1369\n",
      "Epoch 38/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4567 - mse: 1.4567 - val_loss: 0.2447 - val_mse: 0.2447\n",
      "Epoch 39/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.2489 - mse: 1.2489 - val_loss: 0.5233 - val_mse: 0.5233\n",
      "Epoch 40/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.1782 - mse: 1.1782 - val_loss: 0.9085 - val_mse: 0.9085\n",
      "Epoch 41/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2541 - mse: 1.2541 - val_loss: 1.2408 - val_mse: 1.2408\n",
      "Epoch 42/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3767 - mse: 1.3767 - val_loss: 1.3700 - val_mse: 1.3700\n",
      "Epoch 43/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4295 - mse: 1.4295 - val_loss: 1.2511 - val_mse: 1.2511\n",
      "Epoch 44/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3703 - mse: 1.3703 - val_loss: 0.9612 - val_mse: 0.9612\n",
      "Epoch 45/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2498 - mse: 1.2498 - val_loss: 0.6371 - val_mse: 0.6371\n",
      "Epoch 46/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1576 - mse: 1.1576 - val_loss: 0.3884 - val_mse: 0.3884\n",
      "Epoch 47/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1468 - mse: 1.1468 - val_loss: 0.2498 - val_mse: 0.2498\n",
      "Epoch 48/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.1994 - mse: 1.1994 - val_loss: 0.1963 - val_mse: 0.1963\n",
      "Epoch 49/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2519 - mse: 1.2519 - val_loss: 0.1928 - val_mse: 0.1928\n",
      "Epoch 50/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2525 - mse: 1.2525 - val_loss: 0.2308 - val_mse: 0.2308\n",
      "Epoch 51/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1994 - mse: 1.1994 - val_loss: 0.3249 - val_mse: 0.3249\n",
      "Epoch 52/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1340 - mse: 1.1340 - val_loss: 0.4800 - val_mse: 0.4800\n",
      "Epoch 53/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1009 - mse: 1.1009 - val_loss: 0.6644 - val_mse: 0.6644\n",
      "Epoch 54/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1117 - mse: 1.1117 - val_loss: 0.8161 - val_mse: 0.8161\n",
      "Epoch 55/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1407 - mse: 1.1407 - val_loss: 0.8770 - val_mse: 0.8770\n",
      "Epoch 56/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1518 - mse: 1.1518 - val_loss: 0.8289 - val_mse: 0.8289\n",
      "Epoch 57/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.1302 - mse: 1.1302 - val_loss: 0.7013 - val_mse: 0.7013\n",
      "Epoch 58/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0906 - mse: 1.0906 - val_loss: 0.5495 - val_mse: 0.5495\n",
      "Epoch 59/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.0607 - mse: 1.0607 - val_loss: 0.4220 - val_mse: 0.4220\n",
      "Epoch 60/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0553 - mse: 1.0553 - val_loss: 0.3416 - val_mse: 0.3416\n",
      "Epoch 61/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0662 - mse: 1.0662 - val_loss: 0.3085 - val_mse: 0.3085\n",
      "Epoch 62/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.0726 - mse: 1.0726 - val_loss: 0.3167 - val_mse: 0.3167\n",
      "Epoch 63/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0612 - mse: 1.0612 - val_loss: 0.3626 - val_mse: 0.3626\n",
      "Epoch 64/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0364 - mse: 1.0364 - val_loss: 0.4422 - val_mse: 0.4422\n",
      "Epoch 65/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0137 - mse: 1.0137 - val_loss: 0.5405 - val_mse: 0.5405\n",
      "Epoch 66/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0041 - mse: 1.0041 - val_loss: 0.6299 - val_mse: 0.6299\n",
      "Epoch 67/120\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0052 - mse: 1.0052 - val_loss: 0.6805 - val_mse: 0.6805\n",
      "Epoch 68/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0053 - mse: 1.0053 - val_loss: 0.6763 - val_mse: 0.6763\n",
      "Epoch 69/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9956 - mse: 0.9956 - val_loss: 0.6237 - val_mse: 0.6237\n",
      "Epoch 70/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9776 - mse: 0.9776 - val_loss: 0.5468 - val_mse: 0.5468\n",
      "Epoch 71/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9603 - mse: 0.9603 - val_loss: 0.4726 - val_mse: 0.4726\n",
      "Epoch 72/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9504 - mse: 0.9504 - val_loss: 0.4198 - val_mse: 0.4198\n",
      "Epoch 73/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9465 - mse: 0.9465 - val_loss: 0.3960 - val_mse: 0.3960\n",
      "Epoch 74/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9418 - mse: 0.9418 - val_loss: 0.4013 - val_mse: 0.4013\n",
      "Epoch 75/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9313 - mse: 0.9313 - val_loss: 0.4327 - val_mse: 0.4327\n",
      "Epoch 76/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9163 - mse: 0.9163 - val_loss: 0.4831 - val_mse: 0.4831\n",
      "Epoch 77/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9022 - mse: 0.9022 - val_loss: 0.5397 - val_mse: 0.5397\n",
      "Epoch 78/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8926 - mse: 0.8926 - val_loss: 0.5854 - val_mse: 0.5854\n",
      "Epoch 79/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8859 - mse: 0.8859 - val_loss: 0.6056 - val_mse: 0.6056\n",
      "Epoch 80/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8780 - mse: 0.8780 - val_loss: 0.5954 - val_mse: 0.5954\n",
      "Epoch 81/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8665 - mse: 0.8665 - val_loss: 0.5616 - val_mse: 0.5616\n",
      "Epoch 82/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8530 - mse: 0.8530 - val_loss: 0.5186 - val_mse: 0.5186\n",
      "Epoch 83/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8408 - mse: 0.8408 - val_loss: 0.4810 - val_mse: 0.4810\n",
      "Epoch 84/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8314 - mse: 0.8314 - val_loss: 0.4585 - val_mse: 0.4585\n",
      "Epoch 85/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8229 - mse: 0.8229 - val_loss: 0.4549 - val_mse: 0.4549\n",
      "Epoch 86/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8130 - mse: 0.8130 - val_loss: 0.4697 - val_mse: 0.4697\n",
      "Epoch 87/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8010 - mse: 0.8010 - val_loss: 0.4980 - val_mse: 0.4980\n",
      "Epoch 88/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7887 - mse: 0.7887 - val_loss: 0.5317 - val_mse: 0.5317\n",
      "Epoch 89/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7778 - mse: 0.7778 - val_loss: 0.5604 - val_mse: 0.5604\n",
      "Epoch 90/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7683 - mse: 0.7683 - val_loss: 0.5751 - val_mse: 0.5751\n",
      "Epoch 91/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7586 - mse: 0.7586 - val_loss: 0.5721 - val_mse: 0.5721\n",
      "Epoch 92/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7478 - mse: 0.7478 - val_loss: 0.5547 - val_mse: 0.5547\n",
      "Epoch 93/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7362 - mse: 0.7362 - val_loss: 0.5311 - val_mse: 0.5311\n",
      "Epoch 94/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7252 - mse: 0.7252 - val_loss: 0.5103 - val_mse: 0.5103\n",
      "Epoch 95/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7152 - mse: 0.7152 - val_loss: 0.4989 - val_mse: 0.4989\n",
      "Epoch 96/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7056 - mse: 0.7056 - val_loss: 0.4995 - val_mse: 0.4995\n",
      "Epoch 97/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6955 - mse: 0.6955 - val_loss: 0.5115 - val_mse: 0.5115\n",
      "Epoch 98/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6848 - mse: 0.6848 - val_loss: 0.5309 - val_mse: 0.5309\n",
      "Epoch 99/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6743 - mse: 0.6743 - val_loss: 0.5515 - val_mse: 0.5515\n",
      "Epoch 100/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6646 - mse: 0.6646 - val_loss: 0.5668 - val_mse: 0.5668\n",
      "Epoch 101/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6554 - mse: 0.6554 - val_loss: 0.5725 - val_mse: 0.5725\n",
      "Epoch 102/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6460 - mse: 0.6460 - val_loss: 0.5679 - val_mse: 0.5679\n",
      "Epoch 103/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6364 - mse: 0.6364 - val_loss: 0.5568 - val_mse: 0.5568\n",
      "Epoch 104/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6270 - mse: 0.6270 - val_loss: 0.5446 - val_mse: 0.5446\n",
      "Epoch 105/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6180 - mse: 0.6180 - val_loss: 0.5366 - val_mse: 0.5366\n",
      "Epoch 106/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6096 - mse: 0.6096 - val_loss: 0.5357 - val_mse: 0.5357\n",
      "Epoch 107/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6013 - mse: 0.6013 - val_loss: 0.5423 - val_mse: 0.5423\n",
      "Epoch 108/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5929 - mse: 0.5929 - val_loss: 0.5545 - val_mse: 0.5545\n",
      "Epoch 109/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5847 - mse: 0.5847 - val_loss: 0.5683 - val_mse: 0.5683\n",
      "Epoch 110/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5770 - mse: 0.5770 - val_loss: 0.5796 - val_mse: 0.5796\n",
      "Epoch 111/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5698 - mse: 0.5698 - val_loss: 0.5853 - val_mse: 0.5853\n",
      "Epoch 112/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5627 - mse: 0.5627 - val_loss: 0.5849 - val_mse: 0.5849\n",
      "Epoch 113/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5558 - mse: 0.5558 - val_loss: 0.5802 - val_mse: 0.5802\n",
      "Epoch 114/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5491 - mse: 0.5491 - val_loss: 0.5747 - val_mse: 0.5747\n",
      "Epoch 115/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5428 - mse: 0.5428 - val_loss: 0.5717 - val_mse: 0.5717\n",
      "Epoch 116/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5369 - mse: 0.5369 - val_loss: 0.5733 - val_mse: 0.5733\n",
      "Epoch 117/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5313 - mse: 0.5313 - val_loss: 0.5794 - val_mse: 0.5794\n",
      "Epoch 118/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5259 - mse: 0.5259 - val_loss: 0.5887 - val_mse: 0.5887\n",
      "Epoch 119/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5207 - mse: 0.5207 - val_loss: 0.5985 - val_mse: 0.5985\n",
      "Epoch 120/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5160 - mse: 0.5160 - val_loss: 0.6062 - val_mse: 0.6062\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "r2: 0.4026138632501388 meansquarederror: 0.1329881104761316 meanabsoluteerror: 0.332567910884612 maxerror: 0.5044171581492893\n",
      "Epoch 1/120\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 1.4450 - mse: 1.4450 - val_loss: 54.6729 - val_mse: 54.6729\n",
      "Epoch 2/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 47.2019 - mse: 47.2019 - val_loss: 5.9004 - val_mse: 5.9004\n",
      "Epoch 3/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.5377 - mse: 4.5377 - val_loss: 7.2595 - val_mse: 7.2595\n",
      "Epoch 4/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 12.2030 - mse: 12.2030 - val_loss: 19.3254 - val_mse: 19.3254\n",
      "Epoch 5/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 26.3495 - mse: 26.3495 - val_loss: 12.2293 - val_mse: 12.2293\n",
      "Epoch 6/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 18.1209 - mse: 18.1209 - val_loss: 1.8969 - val_mse: 1.8969\n",
      "Epoch 7/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.1481 - mse: 5.1481 - val_loss: 1.3447 - val_mse: 1.3447\n",
      "Epoch 8/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.5680 - mse: 1.5680 - val_loss: 9.2959 - val_mse: 9.2959\n",
      "Epoch 9/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.1123 - mse: 7.1123 - val_loss: 15.5279 - val_mse: 15.5279\n",
      "Epoch 10/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 12.2057 - mse: 12.2057 - val_loss: 14.4834 - val_mse: 14.4834\n",
      "Epoch 11/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 11.3255 - mse: 11.3255 - val_loss: 8.4591 - val_mse: 8.4591\n",
      "Epoch 12/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.4366 - mse: 6.4366 - val_loss: 2.5619 - val_mse: 2.5619\n",
      "Epoch 13/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.1962 - mse: 2.1962 - val_loss: 0.1483 - val_mse: 0.1483\n",
      "Epoch 14/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4911 - mse: 1.4911 - val_loss: 0.9913 - val_mse: 0.9913\n",
      "Epoch 15/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.6892 - mse: 3.6892 - val_loss: 2.5688 - val_mse: 2.5688\n",
      "Epoch 16/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.0207 - mse: 6.0207 - val_loss: 2.8418 - val_mse: 2.8418\n",
      "Epoch 17/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.3877 - mse: 6.3877 - val_loss: 1.6999 - val_mse: 1.6999\n",
      "Epoch 18/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7664 - mse: 4.7664 - val_loss: 0.4036 - val_mse: 0.4036\n",
      "Epoch 19/120\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.5887 - mse: 2.5887 - val_loss: 0.2346 - val_mse: 0.2346\n",
      "Epoch 20/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.3517 - mse: 1.3517 - val_loss: 1.4873 - val_mse: 1.4873\n",
      "Epoch 21/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.5778 - mse: 1.5778 - val_loss: 3.3582 - val_mse: 3.3582\n",
      "Epoch 22/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.6630 - mse: 2.6630 - val_loss: 4.6582 - val_mse: 4.6582\n",
      "Epoch 23/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.5471 - mse: 3.5471 - val_loss: 4.6799 - val_mse: 4.6799\n",
      "Epoch 24/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.5592 - mse: 3.5592 - val_loss: 3.5553 - val_mse: 3.5553\n",
      "Epoch 25/120\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.7827 - mse: 2.7827 - val_loss: 1.9971 - val_mse: 1.9971\n",
      "Epoch 26/120\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.8202 - mse: 1.8202 - val_loss: 0.7553 - val_mse: 0.7553\n",
      "Epoch 27/120\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2806 - mse: 1.2806 - val_loss: 0.1851 - val_mse: 0.1851\n",
      "Epoch 28/120\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.3762 - mse: 1.3762 - val_loss: 0.1583 - val_mse: 0.1583\n",
      "Epoch 29/120\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.8600 - mse: 1.8600 - val_loss: 0.2999 - val_mse: 0.2999\n",
      "Epoch 30/120\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 2.2813 - mse: 2.2813 - val_loss: 0.3212 - val_mse: 0.3212\n",
      "Epoch 31/120\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.3260 - mse: 2.3260 - val_loss: 0.2009 - val_mse: 0.2009\n",
      "Epoch 32/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.9951 - mse: 1.9951 - val_loss: 0.1302 - val_mse: 0.1302\n",
      "Epoch 33/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.5399 - mse: 1.5399 - val_loss: 0.3136 - val_mse: 0.3136\n",
      "Epoch 34/120\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2496 - mse: 1.2496 - val_loss: 0.7875 - val_mse: 0.7875\n",
      "Epoch 35/120\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2544 - mse: 1.2544 - val_loss: 1.3799 - val_mse: 1.3799\n",
      "Epoch 36/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.4675 - mse: 1.4675 - val_loss: 1.8217 - val_mse: 1.8217\n",
      "Epoch 37/120\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.6815 - mse: 1.6815 - val_loss: 1.9177 - val_mse: 1.9177\n",
      "Epoch 38/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.7286 - mse: 1.7286 - val_loss: 1.6537 - val_mse: 1.6537\n",
      "Epoch 39/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.5857 - mse: 1.5857 - val_loss: 1.1805 - val_mse: 1.1805\n",
      "Epoch 40/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.3636 - mse: 1.3636 - val_loss: 0.7045 - val_mse: 0.7045\n",
      "Epoch 41/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.2081 - mse: 1.2081 - val_loss: 0.3698 - val_mse: 0.3698\n",
      "Epoch 42/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.1955 - mse: 1.1955 - val_loss: 0.2047 - val_mse: 0.2047\n",
      "Epoch 43/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2925 - mse: 1.2925 - val_loss: 0.1526 - val_mse: 0.1526\n",
      "Epoch 44/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.3979 - mse: 1.3979 - val_loss: 0.1464 - val_mse: 0.1464\n",
      "Epoch 45/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.4236 - mse: 1.4236 - val_loss: 0.1651 - val_mse: 0.1651\n",
      "Epoch 46/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.3530 - mse: 1.3530 - val_loss: 0.2359 - val_mse: 0.2359\n",
      "Epoch 47/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2402 - mse: 1.2402 - val_loss: 0.3914 - val_mse: 0.3914\n",
      "Epoch 48/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.1603 - mse: 1.1603 - val_loss: 0.6220 - val_mse: 0.6220\n",
      "Epoch 49/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1530 - mse: 1.1530 - val_loss: 0.8639 - val_mse: 0.8639\n",
      "Epoch 50/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2004 - mse: 1.2004 - val_loss: 1.0297 - val_mse: 1.0297\n",
      "Epoch 51/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2489 - mse: 1.2489 - val_loss: 1.0591 - val_mse: 1.0591\n",
      "Epoch 52/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2539 - mse: 1.2539 - val_loss: 0.9518 - val_mse: 0.9518\n",
      "Epoch 53/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2104 - mse: 1.2104 - val_loss: 0.7615 - val_mse: 0.7615\n",
      "Epoch 54/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1499 - mse: 1.1499 - val_loss: 0.5610 - val_mse: 0.5610\n",
      "Epoch 55/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1117 - mse: 1.1117 - val_loss: 0.4043 - val_mse: 0.4043\n",
      "Epoch 56/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1119 - mse: 1.1119 - val_loss: 0.3098 - val_mse: 0.3098\n",
      "Epoch 57/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1358 - mse: 1.1358 - val_loss: 0.2704 - val_mse: 0.2704\n",
      "Epoch 58/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1533 - mse: 1.1533 - val_loss: 0.2741 - val_mse: 0.2741\n",
      "Epoch 59/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.1446 - mse: 1.1446 - val_loss: 0.3174 - val_mse: 0.3174\n",
      "Epoch 60/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1134 - mse: 1.1134 - val_loss: 0.4011 - val_mse: 0.4011\n",
      "Epoch 61/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0802 - mse: 1.0802 - val_loss: 0.5166 - val_mse: 0.5166\n",
      "Epoch 62/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0637 - mse: 1.0637 - val_loss: 0.6383 - val_mse: 0.6383\n",
      "Epoch 63/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0666 - mse: 1.0666 - val_loss: 0.7298 - val_mse: 0.7298\n",
      "Epoch 64/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0759 - mse: 1.0759 - val_loss: 0.7619 - val_mse: 0.7619\n",
      "Epoch 65/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0758 - mse: 1.0758 - val_loss: 0.7281 - val_mse: 0.7281\n",
      "Epoch 66/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0606 - mse: 1.0606 - val_loss: 0.6462 - val_mse: 0.6462\n",
      "Epoch 67/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0380 - mse: 1.0380 - val_loss: 0.5476 - val_mse: 0.5476\n",
      "Epoch 68/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0202 - mse: 1.0202 - val_loss: 0.4608 - val_mse: 0.4608\n",
      "Epoch 69/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0136 - mse: 1.0136 - val_loss: 0.4023 - val_mse: 0.4023\n",
      "Epoch 70/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.0142 - mse: 1.0142 - val_loss: 0.3767 - val_mse: 0.3767\n",
      "Epoch 71/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0127 - mse: 1.0127 - val_loss: 0.3826 - val_mse: 0.3826\n",
      "Epoch 72/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0031 - mse: 1.0031 - val_loss: 0.4168 - val_mse: 0.4168\n",
      "Epoch 73/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9872 - mse: 0.9872 - val_loss: 0.4733 - val_mse: 0.4733\n",
      "Epoch 74/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9719 - mse: 0.9719 - val_loss: 0.5404 - val_mse: 0.5404\n",
      "Epoch 75/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9623 - mse: 0.9623 - val_loss: 0.6005 - val_mse: 0.6005\n",
      "Epoch 76/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9577 - mse: 0.9577 - val_loss: 0.6362 - val_mse: 0.6362\n",
      "Epoch 77/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9532 - mse: 0.9532 - val_loss: 0.6377 - val_mse: 0.6377\n",
      "Epoch 78/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9444 - mse: 0.9444 - val_loss: 0.6077 - val_mse: 0.6077\n",
      "Epoch 79/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9315 - mse: 0.9315 - val_loss: 0.5592 - val_mse: 0.5592\n",
      "Epoch 80/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9183 - mse: 0.9183 - val_loss: 0.5086 - val_mse: 0.5086\n",
      "Epoch 81/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9081 - mse: 0.9081 - val_loss: 0.4693 - val_mse: 0.4693\n",
      "Epoch 82/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9009 - mse: 0.9009 - val_loss: 0.4486 - val_mse: 0.4486\n",
      "Epoch 83/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8939 - mse: 0.8939 - val_loss: 0.4486 - val_mse: 0.4486\n",
      "Epoch 84/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8845 - mse: 0.8845 - val_loss: 0.4675 - val_mse: 0.4675\n",
      "Epoch 85/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8727 - mse: 0.8727 - val_loss: 0.5003 - val_mse: 0.5003\n",
      "Epoch 86/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8607 - mse: 0.8607 - val_loss: 0.5386 - val_mse: 0.5386\n",
      "Epoch 87/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8506 - mse: 0.8506 - val_loss: 0.5719 - val_mse: 0.5719\n",
      "Epoch 88/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8420 - mse: 0.8420 - val_loss: 0.5905 - val_mse: 0.5905\n",
      "Epoch 89/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8334 - mse: 0.8334 - val_loss: 0.5901 - val_mse: 0.5901\n",
      "Epoch 90/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8234 - mse: 0.8234 - val_loss: 0.5726 - val_mse: 0.5726\n",
      "Epoch 91/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8121 - mse: 0.8121 - val_loss: 0.5459 - val_mse: 0.5459\n",
      "Epoch 92/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8009 - mse: 0.8009 - val_loss: 0.5192 - val_mse: 0.5192\n",
      "Epoch 93/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7909 - mse: 0.7909 - val_loss: 0.5001 - val_mse: 0.5001\n",
      "Epoch 94/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7817 - mse: 0.7817 - val_loss: 0.4931 - val_mse: 0.4931\n",
      "Epoch 95/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7722 - mse: 0.7722 - val_loss: 0.4989 - val_mse: 0.4989\n",
      "Epoch 96/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7618 - mse: 0.7618 - val_loss: 0.5153 - val_mse: 0.5153\n",
      "Epoch 97/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7510 - mse: 0.7510 - val_loss: 0.5374 - val_mse: 0.5374\n",
      "Epoch 98/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7406 - mse: 0.7406 - val_loss: 0.5589 - val_mse: 0.5589\n",
      "Epoch 99/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7309 - mse: 0.7309 - val_loss: 0.5736 - val_mse: 0.5736\n",
      "Epoch 100/120\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7215 - mse: 0.7215 - val_loss: 0.5777 - val_mse: 0.5777\n",
      "Epoch 101/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7118 - mse: 0.7118 - val_loss: 0.5712 - val_mse: 0.5712\n",
      "Epoch 102/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7017 - mse: 0.7017 - val_loss: 0.5579 - val_mse: 0.5579\n",
      "Epoch 103/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6916 - mse: 0.6916 - val_loss: 0.5433 - val_mse: 0.5433\n",
      "Epoch 104/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6820 - mse: 0.6820 - val_loss: 0.5326 - val_mse: 0.5326\n",
      "Epoch 105/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6728 - mse: 0.6728 - val_loss: 0.5289 - val_mse: 0.5289\n",
      "Epoch 106/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6637 - mse: 0.6637 - val_loss: 0.5332 - val_mse: 0.5332\n",
      "Epoch 107/120\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6545 - mse: 0.6545 - val_loss: 0.5440 - val_mse: 0.5440\n",
      "Epoch 108/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6452 - mse: 0.6452 - val_loss: 0.5581 - val_mse: 0.5581\n",
      "Epoch 109/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6362 - mse: 0.6362 - val_loss: 0.5712 - val_mse: 0.5712\n",
      "Epoch 110/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6277 - mse: 0.6277 - val_loss: 0.5798 - val_mse: 0.5798\n",
      "Epoch 111/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6194 - mse: 0.6194 - val_loss: 0.5820 - val_mse: 0.5820\n",
      "Epoch 112/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6111 - mse: 0.6111 - val_loss: 0.5783 - val_mse: 0.5783\n",
      "Epoch 113/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6029 - mse: 0.6029 - val_loss: 0.5714 - val_mse: 0.5714\n",
      "Epoch 114/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5949 - mse: 0.5949 - val_loss: 0.5648 - val_mse: 0.5648\n",
      "Epoch 115/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5873 - mse: 0.5873 - val_loss: 0.5614 - val_mse: 0.5614\n",
      "Epoch 116/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5801 - mse: 0.5801 - val_loss: 0.5627 - val_mse: 0.5627\n",
      "Epoch 117/120\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5730 - mse: 0.5730 - val_loss: 0.5686 - val_mse: 0.5686\n",
      "Epoch 118/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5660 - mse: 0.5660 - val_loss: 0.5776 - val_mse: 0.5776\n",
      "Epoch 119/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5593 - mse: 0.5593 - val_loss: 0.5871 - val_mse: 0.5871\n",
      "Epoch 120/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5529 - mse: 0.5529 - val_loss: 0.5947 - val_mse: 0.5947\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "r2: 0.3581659087294976 meansquarederror: 0.14288296595166836 meanabsoluteerror: 0.3493902606597486 maxerror: 0.509182594812422\n",
      "Epoch 1/120\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 1.6253 - mse: 1.6253 - val_loss: 39.0334 - val_mse: 39.0334\n",
      "Epoch 2/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 48.2298 - mse: 48.2298 - val_loss: 1.6760 - val_mse: 1.6760\n",
      "Epoch 3/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.7809 - mse: 4.7809 - val_loss: 15.5815 - val_mse: 15.5815\n",
      "Epoch 4/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 12.4927 - mse: 12.4927 - val_loss: 31.8778 - val_mse: 31.8778\n",
      "Epoch 5/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 26.7350 - mse: 26.7350 - val_loss: 21.3874 - val_mse: 21.3874\n",
      "Epoch 6/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 17.4429 - mse: 17.4429 - val_loss: 5.5009 - val_mse: 5.5009\n",
      "Epoch 7/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.3001 - mse: 4.3001 - val_loss: 0.1528 - val_mse: 0.1528\n",
      "Epoch 8/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.9757 - mse: 1.9757 - val_loss: 4.4197 - val_mse: 4.4197\n",
      "Epoch 9/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.4571 - mse: 8.4571 - val_loss: 8.0731 - val_mse: 8.0731\n",
      "Epoch 10/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 12.9781 - mse: 12.9781 - val_loss: 6.3722 - val_mse: 6.3722\n",
      "Epoch 11/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 10.8914 - mse: 10.8914 - val_loss: 2.1481 - val_mse: 2.1481\n",
      "Epoch 12/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.3948 - mse: 5.3948 - val_loss: 0.1151 - val_mse: 0.1151\n",
      "Epoch 13/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.6376 - mse: 1.6376 - val_loss: 2.2095 - val_mse: 2.2095\n",
      "Epoch 14/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.0200 - mse: 2.0200 - val_loss: 6.3259 - val_mse: 6.3259\n",
      "Epoch 15/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.8630 - mse: 4.8630 - val_loss: 8.8543 - val_mse: 8.8543\n",
      "Epoch 16/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.8178 - mse: 6.8178 - val_loss: 8.0796 - val_mse: 8.0796\n",
      "Epoch 17/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.2014 - mse: 6.2014 - val_loss: 5.0047 - val_mse: 5.0047\n",
      "Epoch 18/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.8677 - mse: 3.8677 - val_loss: 1.8593 - val_mse: 1.8593\n",
      "Epoch 19/120\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.7980 - mse: 1.7980 - val_loss: 0.2583 - val_mse: 0.2583\n",
      "Epoch 20/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3287 - mse: 1.3287 - val_loss: 0.2973 - val_mse: 0.2973\n",
      "Epoch 21/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.3063 - mse: 2.3063 - val_loss: 0.9526 - val_mse: 0.9526\n",
      "Epoch 22/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.5360 - mse: 3.5360 - val_loss: 1.1966 - val_mse: 1.1966\n",
      "Epoch 23/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.9216 - mse: 3.9216 - val_loss: 0.7875 - val_mse: 0.7875\n",
      "Epoch 24/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2470 - mse: 3.2470 - val_loss: 0.2337 - val_mse: 0.2337\n",
      "Epoch 25/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.1180 - mse: 2.1180 - val_loss: 0.2058 - val_mse: 0.2058\n",
      "Epoch 26/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3483 - mse: 1.3483 - val_loss: 0.9461 - val_mse: 0.9461\n",
      "Epoch 27/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.3426 - mse: 1.3426 - val_loss: 2.0886 - val_mse: 2.0886\n",
      "Epoch 28/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.8851 - mse: 1.8851 - val_loss: 2.9626 - val_mse: 2.9626\n",
      "Epoch 29/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.4126 - mse: 2.4126 - val_loss: 3.0890 - val_mse: 3.0890\n",
      "Epoch 30/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.4897 - mse: 2.4897 - val_loss: 2.4698 - val_mse: 2.4698\n",
      "Epoch 31/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.0960 - mse: 2.0960 - val_loss: 1.5048 - val_mse: 1.5048\n",
      "Epoch 32/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.5561 - mse: 1.5561 - val_loss: 0.6718 - val_mse: 0.6718\n",
      "Epoch 33/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2408 - mse: 1.2408 - val_loss: 0.2288 - val_mse: 0.2288\n",
      "Epoch 34/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.2949 - mse: 1.2949 - val_loss: 0.1298 - val_mse: 0.1298\n",
      "Epoch 35/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.5749 - mse: 1.5749 - val_loss: 0.1626 - val_mse: 0.1626\n",
      "Epoch 36/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.8048 - mse: 1.8048 - val_loss: 0.1631 - val_mse: 0.1631\n",
      "Epoch 37/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.7989 - mse: 1.7989 - val_loss: 0.1325 - val_mse: 0.1325\n",
      "Epoch 38/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.5780 - mse: 1.5780 - val_loss: 0.1916 - val_mse: 0.1916\n",
      "Epoch 39/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.3166 - mse: 1.3166 - val_loss: 0.4403 - val_mse: 0.4403\n",
      "Epoch 40/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1895 - mse: 1.1895 - val_loss: 0.8468 - val_mse: 0.8468\n",
      "Epoch 41/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2446 - mse: 1.2446 - val_loss: 1.2492 - val_mse: 1.2492\n",
      "Epoch 42/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.3891 - mse: 1.3891 - val_loss: 1.4624 - val_mse: 1.4624\n",
      "Epoch 43/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.4816 - mse: 1.4816 - val_loss: 1.3983 - val_mse: 1.3983\n",
      "Epoch 44/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4458 - mse: 1.4458 - val_loss: 1.1118 - val_mse: 1.1118\n",
      "Epoch 45/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.3157 - mse: 1.3157 - val_loss: 0.7489 - val_mse: 0.7489\n",
      "Epoch 46/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.1912 - mse: 1.1912 - val_loss: 0.4477 - val_mse: 0.4477\n",
      "Epoch 47/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.1519 - mse: 1.1519 - val_loss: 0.2690 - val_mse: 0.2690\n",
      "Epoch 48/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.1993 - mse: 1.1993 - val_loss: 0.1945 - val_mse: 0.1945\n",
      "Epoch 49/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.2695 - mse: 1.2695 - val_loss: 0.1793 - val_mse: 0.1793\n",
      "Epoch 50/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2924 - mse: 1.2924 - val_loss: 0.2028 - val_mse: 0.2028\n",
      "Epoch 51/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2475 - mse: 1.2475 - val_loss: 0.2787 - val_mse: 0.2787\n",
      "Epoch 52/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1710 - mse: 1.1710 - val_loss: 0.4232 - val_mse: 0.4232\n",
      "Epoch 53/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.1184 - mse: 1.1184 - val_loss: 0.6183 - val_mse: 0.6183\n",
      "Epoch 54/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1172 - mse: 1.1172 - val_loss: 0.8040 - val_mse: 0.8040\n",
      "Epoch 55/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1498 - mse: 1.1498 - val_loss: 0.9098 - val_mse: 0.9098\n",
      "Epoch 56/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1746 - mse: 1.1746 - val_loss: 0.8972 - val_mse: 0.8972\n",
      "Epoch 57/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1636 - mse: 1.1636 - val_loss: 0.7818 - val_mse: 0.7818\n",
      "Epoch 58/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1232 - mse: 1.1232 - val_loss: 0.6188 - val_mse: 0.6188\n",
      "Epoch 59/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0829 - mse: 1.0829 - val_loss: 0.4673 - val_mse: 0.4673\n",
      "Epoch 60/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0675 - mse: 1.0675 - val_loss: 0.3620 - val_mse: 0.3620\n",
      "Epoch 61/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0769 - mse: 1.0769 - val_loss: 0.3091 - val_mse: 0.3091\n",
      "Epoch 62/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0904 - mse: 1.0904 - val_loss: 0.3016 - val_mse: 0.3016\n",
      "Epoch 63/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0872 - mse: 1.0872 - val_loss: 0.3341 - val_mse: 0.3341\n",
      "Epoch 64/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0647 - mse: 1.0647 - val_loss: 0.4047 - val_mse: 0.4047\n",
      "Epoch 65/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.0371 - mse: 1.0371 - val_loss: 0.5044 - val_mse: 0.5044\n",
      "Epoch 66/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0208 - mse: 1.0208 - val_loss: 0.6090 - val_mse: 0.6090\n",
      "Epoch 67/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0197 - mse: 1.0197 - val_loss: 0.6854 - val_mse: 0.6854\n",
      "Epoch 68/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0235 - mse: 1.0235 - val_loss: 0.7077 - val_mse: 0.7077\n",
      "Epoch 69/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0194 - mse: 1.0194 - val_loss: 0.6721 - val_mse: 0.6721\n",
      "Epoch 70/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0038 - mse: 1.0038 - val_loss: 0.5974 - val_mse: 0.5974\n",
      "Epoch 71/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9840 - mse: 0.9840 - val_loss: 0.5132 - val_mse: 0.5132\n",
      "Epoch 72/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9700 - mse: 0.9700 - val_loss: 0.4443 - val_mse: 0.4443\n",
      "Epoch 73/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9646 - mse: 0.9646 - val_loss: 0.4038 - val_mse: 0.4038\n",
      "Epoch 74/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9624 - mse: 0.9624 - val_loss: 0.3946 - val_mse: 0.3946\n",
      "Epoch 75/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9556 - mse: 0.9556 - val_loss: 0.4146 - val_mse: 0.4146\n",
      "Epoch 76/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9422 - mse: 0.9422 - val_loss: 0.4592 - val_mse: 0.4592\n",
      "Epoch 77/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9266 - mse: 0.9266 - val_loss: 0.5183 - val_mse: 0.5183\n",
      "Epoch 78/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9145 - mse: 0.9145 - val_loss: 0.5758 - val_mse: 0.5758\n",
      "Epoch 79/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9073 - mse: 0.9073 - val_loss: 0.6140 - val_mse: 0.6140\n",
      "Epoch 80/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9013 - mse: 0.9013 - val_loss: 0.6211 - val_mse: 0.6211\n",
      "Epoch 81/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8923 - mse: 0.8923 - val_loss: 0.5977 - val_mse: 0.5977\n",
      "Epoch 82/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8795 - mse: 0.8795 - val_loss: 0.5553 - val_mse: 0.5553\n",
      "Epoch 83/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8662 - mse: 0.8662 - val_loss: 0.5102 - val_mse: 0.5102\n",
      "Epoch 84/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8554 - mse: 0.8554 - val_loss: 0.4759 - val_mse: 0.4759\n",
      "Epoch 85/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8471 - mse: 0.8471 - val_loss: 0.4598 - val_mse: 0.4598\n",
      "Epoch 86/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8388 - mse: 0.8388 - val_loss: 0.4639 - val_mse: 0.4639\n",
      "Epoch 87/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8282 - mse: 0.8282 - val_loss: 0.4859 - val_mse: 0.4859\n",
      "Epoch 88/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8159 - mse: 0.8159 - val_loss: 0.5194 - val_mse: 0.5194\n",
      "Epoch 89/120\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8041 - mse: 0.8041 - val_loss: 0.5548 - val_mse: 0.5548\n",
      "Epoch 90/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7940 - mse: 0.7940 - val_loss: 0.5814 - val_mse: 0.5814\n",
      "Epoch 91/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7849 - mse: 0.7849 - val_loss: 0.5911 - val_mse: 0.5911\n",
      "Epoch 92/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7752 - mse: 0.7752 - val_loss: 0.5824 - val_mse: 0.5824\n",
      "Epoch 93/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7641 - mse: 0.7641 - val_loss: 0.5609 - val_mse: 0.5609\n",
      "Epoch 94/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7525 - mse: 0.7525 - val_loss: 0.5357 - val_mse: 0.5357\n",
      "Epoch 95/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7419 - mse: 0.7419 - val_loss: 0.5159 - val_mse: 0.5159\n",
      "Epoch 96/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7322 - mse: 0.7322 - val_loss: 0.5070 - val_mse: 0.5070\n",
      "Epoch 97/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7227 - mse: 0.7227 - val_loss: 0.5110 - val_mse: 0.5110\n",
      "Epoch 98/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7124 - mse: 0.7124 - val_loss: 0.5262 - val_mse: 0.5262\n",
      "Epoch 99/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7017 - mse: 0.7017 - val_loss: 0.5478 - val_mse: 0.5478\n",
      "Epoch 100/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6913 - mse: 0.6913 - val_loss: 0.5691 - val_mse: 0.5691\n",
      "Epoch 101/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6817 - mse: 0.6817 - val_loss: 0.5836 - val_mse: 0.5836\n",
      "Epoch 102/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6724 - mse: 0.6724 - val_loss: 0.5874 - val_mse: 0.5874\n",
      "Epoch 103/120\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6630 - mse: 0.6630 - val_loss: 0.5810 - val_mse: 0.5810\n",
      "Epoch 104/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6532 - mse: 0.6532 - val_loss: 0.5685 - val_mse: 0.5685\n",
      "Epoch 105/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6436 - mse: 0.6436 - val_loss: 0.5557 - val_mse: 0.5557\n",
      "Epoch 106/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6346 - mse: 0.6346 - val_loss: 0.5480 - val_mse: 0.5480\n",
      "Epoch 107/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6260 - mse: 0.6260 - val_loss: 0.5479 - val_mse: 0.5479\n",
      "Epoch 108/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6175 - mse: 0.6175 - val_loss: 0.5556 - val_mse: 0.5556\n",
      "Epoch 109/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6088 - mse: 0.6088 - val_loss: 0.5688 - val_mse: 0.5688\n",
      "Epoch 110/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6004 - mse: 0.6004 - val_loss: 0.5834 - val_mse: 0.5834\n",
      "Epoch 111/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5924 - mse: 0.5924 - val_loss: 0.5950 - val_mse: 0.5950\n",
      "Epoch 112/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5849 - mse: 0.5849 - val_loss: 0.6005 - val_mse: 0.6005\n",
      "Epoch 113/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5775 - mse: 0.5775 - val_loss: 0.5996 - val_mse: 0.5996\n",
      "Epoch 114/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5702 - mse: 0.5702 - val_loss: 0.5943 - val_mse: 0.5943\n",
      "Epoch 115/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5631 - mse: 0.5631 - val_loss: 0.5881 - val_mse: 0.5881\n",
      "Epoch 116/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5564 - mse: 0.5564 - val_loss: 0.5847 - val_mse: 0.5847\n",
      "Epoch 117/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5501 - mse: 0.5501 - val_loss: 0.5859 - val_mse: 0.5859\n",
      "Epoch 118/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5441 - mse: 0.5441 - val_loss: 0.5920 - val_mse: 0.5920\n",
      "Epoch 119/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5382 - mse: 0.5382 - val_loss: 0.6014 - val_mse: 0.6014\n",
      "Epoch 120/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5326 - mse: 0.5326 - val_loss: 0.6116 - val_mse: 0.6116\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "r2: 0.39241435638613476 meansquarederror: 0.13525869069583998 meanabsoluteerror: 0.33623308512611644 maxerror: 0.49935805425520163\n",
      "Epoch 1/120\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 1.5225 - mse: 1.5225 - val_loss: 36.6727 - val_mse: 36.6727\n",
      "Epoch 2/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 45.6719 - mse: 45.6719 - val_loss: 1.4711 - val_mse: 1.4711\n",
      "Epoch 3/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.5060 - mse: 4.5060 - val_loss: 14.9568 - val_mse: 14.9568\n",
      "Epoch 4/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 11.8375 - mse: 11.8375 - val_loss: 30.5611 - val_mse: 30.5611\n",
      "Epoch 5/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 25.3586 - mse: 25.3586 - val_loss: 21.0329 - val_mse: 21.0329\n",
      "Epoch 6/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.9826 - mse: 16.9826 - val_loss: 5.9088 - val_mse: 5.9088\n",
      "Epoch 7/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.5404 - mse: 4.5404 - val_loss: 0.1117 - val_mse: 0.1117\n",
      "Epoch 8/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.7168 - mse: 1.7168 - val_loss: 3.5910 - val_mse: 3.5910\n",
      "Epoch 9/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.4204 - mse: 7.4204 - val_loss: 7.2445 - val_mse: 7.2445\n",
      "Epoch 10/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 12.0228 - mse: 12.0228 - val_loss: 6.1580 - val_mse: 6.1580\n",
      "Epoch 11/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.6749 - mse: 10.6749 - val_loss: 2.3852 - val_mse: 2.3852\n",
      "Epoch 12/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.7623 - mse: 5.7623 - val_loss: 0.1421 - val_mse: 0.1421\n",
      "Epoch 13/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.8987 - mse: 1.8987 - val_loss: 1.5581 - val_mse: 1.5581\n",
      "Epoch 14/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.6413 - mse: 1.6413 - val_loss: 5.2379 - val_mse: 5.2379\n",
      "Epoch 15/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.0003 - mse: 4.0003 - val_loss: 8.0430 - val_mse: 8.0430\n",
      "Epoch 16/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.1097 - mse: 6.1097 - val_loss: 8.0355 - val_mse: 8.0355\n",
      "Epoch 17/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.0996 - mse: 6.0996 - val_loss: 5.6189 - val_mse: 5.6189\n",
      "Epoch 18/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.2652 - mse: 4.2652 - val_loss: 2.5899 - val_mse: 2.5899\n",
      "Epoch 19/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.1924 - mse: 2.1924 - val_loss: 0.5940 - val_mse: 0.5940\n",
      "Epoch 20/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2765 - mse: 1.2765 - val_loss: 0.1326 - val_mse: 0.1326\n",
      "Epoch 21/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.7823 - mse: 1.7823 - val_loss: 0.5822 - val_mse: 0.5822\n",
      "Epoch 22/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.9086 - mse: 2.9086 - val_loss: 0.9858 - val_mse: 0.9858\n",
      "Epoch 23/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.6060 - mse: 3.6060 - val_loss: 0.8522 - val_mse: 0.8522\n",
      "Epoch 24/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3771 - mse: 3.3771 - val_loss: 0.3800 - val_mse: 0.3800\n",
      "Epoch 25/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.4841 - mse: 2.4841 - val_loss: 0.1234 - val_mse: 0.1234\n",
      "Epoch 26/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.5931 - mse: 1.5931 - val_loss: 0.4813 - val_mse: 0.4813\n",
      "Epoch 27/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2411 - mse: 1.2411 - val_loss: 1.3844 - val_mse: 1.3844\n",
      "Epoch 28/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.5000 - mse: 1.5000 - val_loss: 2.3624 - val_mse: 2.3624\n",
      "Epoch 29/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.0162 - mse: 2.0162 - val_loss: 2.8906 - val_mse: 2.8906\n",
      "Epoch 30/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.3350 - mse: 2.3350 - val_loss: 2.7309 - val_mse: 2.7309\n",
      "Epoch 31/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.2312 - mse: 2.2312 - val_loss: 2.0329 - val_mse: 2.0329\n",
      "Epoch 32/120\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.8149 - mse: 1.8149 - val_loss: 1.1784 - val_mse: 1.1784\n",
      "Epoch 33/120\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.3897 - mse: 1.3897 - val_loss: 0.5201 - val_mse: 0.5201\n",
      "Epoch 34/120\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2111 - mse: 1.2111 - val_loss: 0.1978 - val_mse: 0.1978\n",
      "Epoch 35/120\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.3230 - mse: 1.3230 - val_loss: 0.1299 - val_mse: 0.1299\n",
      "Epoch 36/120\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.5662 - mse: 1.5662 - val_loss: 0.1461 - val_mse: 0.1461\n",
      "Epoch 37/120\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.7241 - mse: 1.7241 - val_loss: 0.1409 - val_mse: 0.1409\n",
      "Epoch 38/120\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.6807 - mse: 1.6807 - val_loss: 0.1357 - val_mse: 0.1357\n",
      "Epoch 39/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.4807 - mse: 1.4807 - val_loss: 0.2265 - val_mse: 0.2265\n",
      "Epoch 40/120\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.2701 - mse: 1.2701 - val_loss: 0.4765 - val_mse: 0.4765\n",
      "Epoch 41/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.1778 - mse: 1.1778 - val_loss: 0.8429 - val_mse: 0.8429\n",
      "Epoch 42/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.2294 - mse: 1.2294 - val_loss: 1.1900 - val_mse: 1.1900\n",
      "Epoch 43/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.3470 - mse: 1.3470 - val_loss: 1.3718 - val_mse: 1.3718\n",
      "Epoch 44/120\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.4208 - mse: 1.4208 - val_loss: 1.3204 - val_mse: 1.3204\n",
      "Epoch 45/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.3924 - mse: 1.3924 - val_loss: 1.0790 - val_mse: 1.0790\n",
      "Epoch 46/120\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2870 - mse: 1.2870 - val_loss: 0.7629 - val_mse: 0.7629\n",
      "Epoch 47/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.1815 - mse: 1.1815 - val_loss: 0.4864 - val_mse: 0.4864\n",
      "Epoch 48/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.1401 - mse: 1.1401 - val_loss: 0.3076 - val_mse: 0.3076\n",
      "Epoch 49/120\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.1703 - mse: 1.1703 - val_loss: 0.2223 - val_mse: 0.2223\n",
      "Epoch 50/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.2269 - mse: 1.2269 - val_loss: 0.1980 - val_mse: 0.1980\n",
      "Epoch 51/120\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2534 - mse: 1.2534 - val_loss: 0.2142 - val_mse: 0.2142\n",
      "Epoch 52/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.2260 - mse: 1.2260 - val_loss: 0.2756 - val_mse: 0.2756\n",
      "Epoch 53/120\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1651 - mse: 1.1651 - val_loss: 0.3939 - val_mse: 0.3939\n",
      "Epoch 54/120\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1132 - mse: 1.1132 - val_loss: 0.5597 - val_mse: 0.5597\n",
      "Epoch 55/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.0992 - mse: 1.0992 - val_loss: 0.7310 - val_mse: 0.7310\n",
      "Epoch 56/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.1186 - mse: 1.1186 - val_loss: 0.8503 - val_mse: 0.8503\n",
      "Epoch 57/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1422 - mse: 1.1422 - val_loss: 0.8761 - val_mse: 0.8761\n",
      "Epoch 58/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1429 - mse: 1.1429 - val_loss: 0.8060 - val_mse: 0.8060\n",
      "Epoch 59/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.1160 - mse: 1.1160 - val_loss: 0.6753 - val_mse: 0.6753\n",
      "Epoch 60/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0794 - mse: 1.0794 - val_loss: 0.5335 - val_mse: 0.5335\n",
      "Epoch 61/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0559 - mse: 1.0559 - val_loss: 0.4194 - val_mse: 0.4194\n",
      "Epoch 62/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0540 - mse: 1.0540 - val_loss: 0.3491 - val_mse: 0.3491\n",
      "Epoch 63/120\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.0637 - mse: 1.0637 - val_loss: 0.3222 - val_mse: 0.3222\n",
      "Epoch 64/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0672 - mse: 1.0672 - val_loss: 0.3333 - val_mse: 0.3333\n",
      "Epoch 65/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0549 - mse: 1.0549 - val_loss: 0.3794 - val_mse: 0.3794\n",
      "Epoch 66/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0318 - mse: 1.0318 - val_loss: 0.4557 - val_mse: 0.4557\n",
      "Epoch 67/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0110 - mse: 1.0110 - val_loss: 0.5481 - val_mse: 0.5481\n",
      "Epoch 68/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0016 - mse: 1.0016 - val_loss: 0.6324 - val_mse: 0.6324\n",
      "Epoch 69/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0015 - mse: 1.0015 - val_loss: 0.6825 - val_mse: 0.6825\n",
      "Epoch 70/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0010 - mse: 1.0010 - val_loss: 0.6836 - val_mse: 0.6836\n",
      "Epoch 71/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9925 - mse: 0.9925 - val_loss: 0.6399 - val_mse: 0.6399\n",
      "Epoch 72/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9764 - mse: 0.9764 - val_loss: 0.5705 - val_mse: 0.5705\n",
      "Epoch 73/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9596 - mse: 0.9596 - val_loss: 0.4995 - val_mse: 0.4995\n",
      "Epoch 74/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9486 - mse: 0.9486 - val_loss: 0.4448 - val_mse: 0.4448\n",
      "Epoch 75/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9434 - mse: 0.9434 - val_loss: 0.4155 - val_mse: 0.4155\n",
      "Epoch 76/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9389 - mse: 0.9389 - val_loss: 0.4131 - val_mse: 0.4131\n",
      "Epoch 77/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9302 - mse: 0.9302 - val_loss: 0.4356 - val_mse: 0.4356\n",
      "Epoch 78/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9169 - mse: 0.9169 - val_loss: 0.4778 - val_mse: 0.4778\n",
      "Epoch 79/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9029 - mse: 0.9029 - val_loss: 0.5298 - val_mse: 0.5298\n",
      "Epoch 80/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8919 - mse: 0.8919 - val_loss: 0.5778 - val_mse: 0.5778\n",
      "Epoch 81/120\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8843 - mse: 0.8843 - val_loss: 0.6075 - val_mse: 0.6075\n",
      "Epoch 82/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8771 - mse: 0.8771 - val_loss: 0.6108 - val_mse: 0.6108\n",
      "Epoch 83/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8674 - mse: 0.8674 - val_loss: 0.5893 - val_mse: 0.5893\n",
      "Epoch 84/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8551 - mse: 0.8551 - val_loss: 0.5528 - val_mse: 0.5528\n",
      "Epoch 85/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8426 - mse: 0.8426 - val_loss: 0.5143 - val_mse: 0.5143\n",
      "Epoch 86/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8319 - mse: 0.8319 - val_loss: 0.4850 - val_mse: 0.4850\n",
      "Epoch 87/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8232 - mse: 0.8232 - val_loss: 0.4712 - val_mse: 0.4712\n",
      "Epoch 88/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8143 - mse: 0.8143 - val_loss: 0.4746 - val_mse: 0.4746\n",
      "Epoch 89/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8038 - mse: 0.8038 - val_loss: 0.4931 - val_mse: 0.4931\n",
      "Epoch 90/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7920 - mse: 0.7920 - val_loss: 0.5216 - val_mse: 0.5216\n",
      "Epoch 91/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7805 - mse: 0.7805 - val_loss: 0.5521 - val_mse: 0.5521\n",
      "Epoch 92/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7703 - mse: 0.7703 - val_loss: 0.5756 - val_mse: 0.5756\n",
      "Epoch 93/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7609 - mse: 0.7609 - val_loss: 0.5855 - val_mse: 0.5855\n",
      "Epoch 94/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7512 - mse: 0.7512 - val_loss: 0.5801 - val_mse: 0.5801\n",
      "Epoch 95/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7405 - mse: 0.7405 - val_loss: 0.5632 - val_mse: 0.5632\n",
      "Epoch 96/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7294 - mse: 0.7294 - val_loss: 0.5420 - val_mse: 0.5420\n",
      "Epoch 97/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7188 - mse: 0.7188 - val_loss: 0.5241 - val_mse: 0.5241\n",
      "Epoch 98/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7091 - mse: 0.7091 - val_loss: 0.5148 - val_mse: 0.5148\n",
      "Epoch 99/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6997 - mse: 0.6997 - val_loss: 0.5162 - val_mse: 0.5162\n",
      "Epoch 100/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6898 - mse: 0.6898 - val_loss: 0.5275 - val_mse: 0.5275\n",
      "Epoch 101/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6796 - mse: 0.6796 - val_loss: 0.5451 - val_mse: 0.5451\n",
      "Epoch 102/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6695 - mse: 0.6695 - val_loss: 0.5639 - val_mse: 0.5639\n",
      "Epoch 103/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6601 - mse: 0.6601 - val_loss: 0.5783 - val_mse: 0.5783\n",
      "Epoch 104/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6511 - mse: 0.6511 - val_loss: 0.5844 - val_mse: 0.5844\n",
      "Epoch 105/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6421 - mse: 0.6421 - val_loss: 0.5816 - val_mse: 0.5816\n",
      "Epoch 106/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6329 - mse: 0.6329 - val_loss: 0.5725 - val_mse: 0.5725\n",
      "Epoch 107/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6238 - mse: 0.6238 - val_loss: 0.5617 - val_mse: 0.5617\n",
      "Epoch 108/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6151 - mse: 0.6151 - val_loss: 0.5538 - val_mse: 0.5538\n",
      "Epoch 109/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6069 - mse: 0.6069 - val_loss: 0.5517 - val_mse: 0.5517\n",
      "Epoch 110/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5989 - mse: 0.5989 - val_loss: 0.5563 - val_mse: 0.5563\n",
      "Epoch 111/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5910 - mse: 0.5910 - val_loss: 0.5663 - val_mse: 0.5663\n",
      "Epoch 112/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5831 - mse: 0.5831 - val_loss: 0.5788 - val_mse: 0.5788\n",
      "Epoch 113/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5756 - mse: 0.5756 - val_loss: 0.5903 - val_mse: 0.5903\n",
      "Epoch 114/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5686 - mse: 0.5686 - val_loss: 0.5976 - val_mse: 0.5976\n",
      "Epoch 115/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5618 - mse: 0.5618 - val_loss: 0.5995 - val_mse: 0.5995\n",
      "Epoch 116/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5552 - mse: 0.5552 - val_loss: 0.5970 - val_mse: 0.5970\n",
      "Epoch 117/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5488 - mse: 0.5488 - val_loss: 0.5924 - val_mse: 0.5924\n",
      "Epoch 118/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5427 - mse: 0.5427 - val_loss: 0.5887 - val_mse: 0.5887\n",
      "Epoch 119/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5371 - mse: 0.5371 - val_loss: 0.5883 - val_mse: 0.5883\n",
      "Epoch 120/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5317 - mse: 0.5317 - val_loss: 0.5919 - val_mse: 0.5919\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "r2: 0.36244315547324957 meansquarederror: 0.14193077953906344 meanabsoluteerror: 0.34172360126904705 maxerror: 0.5169935991132539\n",
      "Epoch 1/120\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 1.3675 - mse: 1.3675 - val_loss: 30.0302 - val_mse: 30.0302\n",
      "Epoch 2/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 24.9980 - mse: 24.9980 - val_loss: 0.1735 - val_mse: 0.1735\n",
      "Epoch 3/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3715 - mse: 1.3715 - val_loss: 11.8972 - val_mse: 11.8972\n",
      "Epoch 4/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 17.4834 - mse: 17.4834 - val_loss: 9.6809 - val_mse: 9.6809\n",
      "Epoch 5/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 14.8414 - mse: 14.8414 - val_loss: 1.1136 - val_mse: 1.1136\n",
      "Epoch 6/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.7512 - mse: 3.7512 - val_loss: 2.3766 - val_mse: 2.3766\n",
      "Epoch 7/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.0211 - mse: 2.0211 - val_loss: 10.3873 - val_mse: 10.3873\n",
      "Epoch 8/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.9755 - mse: 7.9755 - val_loss: 12.6758 - val_mse: 12.6758\n",
      "Epoch 9/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.8457 - mse: 9.8457 - val_loss: 7.7091 - val_mse: 7.7091\n",
      "Epoch 10/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.8254 - mse: 5.8254 - val_loss: 1.9369 - val_mse: 1.9369\n",
      "Epoch 11/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.7462 - mse: 1.7462 - val_loss: 0.1491 - val_mse: 0.1491\n",
      "Epoch 12/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.7235 - mse: 1.7235 - val_loss: 1.5402 - val_mse: 1.5402\n",
      "Epoch 13/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.3615 - mse: 4.3615 - val_loss: 2.5289 - val_mse: 2.5289\n",
      "Epoch 14/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.7710 - mse: 5.7710 - val_loss: 1.6490 - val_mse: 1.6490\n",
      "Epoch 15/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.5090 - mse: 4.5090 - val_loss: 0.3215 - val_mse: 0.3215\n",
      "Epoch 16/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.2281 - mse: 2.2281 - val_loss: 0.4563 - val_mse: 0.4563\n",
      "Epoch 17/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.1666 - mse: 1.1666 - val_loss: 2.2846 - val_mse: 2.2846\n",
      "Epoch 18/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.9119 - mse: 1.9119 - val_loss: 4.2325 - val_mse: 4.2325\n",
      "Epoch 19/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.1830 - mse: 3.1830 - val_loss: 4.6667 - val_mse: 4.6667\n",
      "Epoch 20/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.4866 - mse: 3.4866 - val_loss: 3.4140 - val_mse: 3.4140\n",
      "Epoch 21/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.6125 - mse: 2.6125 - val_loss: 1.5913 - val_mse: 1.5913\n",
      "Epoch 22/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.5106 - mse: 1.5106 - val_loss: 0.3942 - val_mse: 0.3942\n",
      "Epoch 23/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1448 - mse: 1.1448 - val_loss: 0.1515 - val_mse: 0.1515\n",
      "Epoch 24/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.6131 - mse: 1.6131 - val_loss: 0.3545 - val_mse: 0.3545\n",
      "Epoch 25/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.2354 - mse: 2.2354 - val_loss: 0.4053 - val_mse: 0.4053\n",
      "Epoch 26/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.3396 - mse: 2.3396 - val_loss: 0.2200 - val_mse: 0.2200\n",
      "Epoch 27/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8680 - mse: 1.8680 - val_loss: 0.1706 - val_mse: 0.1706\n",
      "Epoch 28/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2975 - mse: 1.2975 - val_loss: 0.5861 - val_mse: 0.5861\n",
      "Epoch 29/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1095 - mse: 1.1095 - val_loss: 1.3571 - val_mse: 1.3571\n",
      "Epoch 30/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3556 - mse: 1.3556 - val_loss: 2.0040 - val_mse: 2.0040\n",
      "Epoch 31/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.6846 - mse: 1.6846 - val_loss: 2.1047 - val_mse: 2.1047\n",
      "Epoch 32/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.7363 - mse: 1.7363 - val_loss: 1.6407 - val_mse: 1.6407\n",
      "Epoch 33/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4768 - mse: 1.4768 - val_loss: 0.9546 - val_mse: 0.9546\n",
      "Epoch 34/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1684 - mse: 1.1684 - val_loss: 0.4261 - val_mse: 0.4261\n",
      "Epoch 35/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0732 - mse: 1.0732 - val_loss: 0.1950 - val_mse: 0.1950\n",
      "Epoch 36/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.2108 - mse: 1.2108 - val_loss: 0.1552 - val_mse: 0.1552\n",
      "Epoch 37/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.3832 - mse: 1.3832 - val_loss: 0.1562 - val_mse: 0.1562\n",
      "Epoch 38/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.3975 - mse: 1.3975 - val_loss: 0.1760 - val_mse: 0.1760\n",
      "Epoch 39/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2450 - mse: 1.2450 - val_loss: 0.3055 - val_mse: 0.3055\n",
      "Epoch 40/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0767 - mse: 1.0767 - val_loss: 0.5978 - val_mse: 0.5978\n",
      "Epoch 41/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0343 - mse: 1.0343 - val_loss: 0.9600 - val_mse: 0.9600\n",
      "Epoch 42/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1166 - mse: 1.1166 - val_loss: 1.2014 - val_mse: 1.2014\n",
      "Epoch 43/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.2030 - mse: 1.2030 - val_loss: 1.1892 - val_mse: 1.1892\n",
      "Epoch 44/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1904 - mse: 1.1904 - val_loss: 0.9517 - val_mse: 0.9517\n",
      "Epoch 45/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0914 - mse: 1.0914 - val_loss: 0.6393 - val_mse: 0.6393\n",
      "Epoch 46/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.0024 - mse: 1.0024 - val_loss: 0.3957 - val_mse: 0.3957\n",
      "Epoch 47/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9943 - mse: 0.9943 - val_loss: 0.2696 - val_mse: 0.2696\n",
      "Epoch 48/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0456 - mse: 1.0456 - val_loss: 0.2319 - val_mse: 0.2319\n",
      "Epoch 49/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0793 - mse: 1.0793 - val_loss: 0.2505 - val_mse: 0.2505\n",
      "Epoch 50/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0498 - mse: 1.0498 - val_loss: 0.3308 - val_mse: 0.3308\n",
      "Epoch 51/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9841 - mse: 0.9841 - val_loss: 0.4846 - val_mse: 0.4846\n",
      "Epoch 52/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9425 - mse: 0.9425 - val_loss: 0.6781 - val_mse: 0.6781\n",
      "Epoch 53/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9505 - mse: 0.9505 - val_loss: 0.8290 - val_mse: 0.8290\n",
      "Epoch 54/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9778 - mse: 0.9778 - val_loss: 0.8624 - val_mse: 0.8624\n",
      "Epoch 55/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9787 - mse: 0.9787 - val_loss: 0.7696 - val_mse: 0.7696\n",
      "Epoch 56/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9437 - mse: 0.9437 - val_loss: 0.6106 - val_mse: 0.6106\n",
      "Epoch 57/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9037 - mse: 0.9037 - val_loss: 0.4621 - val_mse: 0.4621\n",
      "Epoch 58/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8902 - mse: 0.8902 - val_loss: 0.3685 - val_mse: 0.3685\n",
      "Epoch 59/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9005 - mse: 0.9005 - val_loss: 0.3346 - val_mse: 0.3346\n",
      "Epoch 60/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9061 - mse: 0.9061 - val_loss: 0.3522 - val_mse: 0.3522\n",
      "Epoch 61/120\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8888 - mse: 0.8888 - val_loss: 0.4178 - val_mse: 0.4178\n",
      "Epoch 62/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8590 - mse: 0.8590 - val_loss: 0.5215 - val_mse: 0.5215\n",
      "Epoch 63/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8399 - mse: 0.8399 - val_loss: 0.6312 - val_mse: 0.6312\n",
      "Epoch 64/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8385 - mse: 0.8385 - val_loss: 0.7002 - val_mse: 0.7002\n",
      "Epoch 65/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8405 - mse: 0.8405 - val_loss: 0.6974 - val_mse: 0.6974\n",
      "Epoch 66/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8298 - mse: 0.8298 - val_loss: 0.6309 - val_mse: 0.6309\n",
      "Epoch 67/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8081 - mse: 0.8081 - val_loss: 0.5390 - val_mse: 0.5390\n",
      "Epoch 68/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7900 - mse: 0.7900 - val_loss: 0.4615 - val_mse: 0.4615\n",
      "Epoch 69/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7833 - mse: 0.7833 - val_loss: 0.4197 - val_mse: 0.4197\n",
      "Epoch 70/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7809 - mse: 0.7809 - val_loss: 0.4175 - val_mse: 0.4175\n",
      "Epoch 71/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7717 - mse: 0.7717 - val_loss: 0.4515 - val_mse: 0.4515\n",
      "Epoch 72/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7548 - mse: 0.7548 - val_loss: 0.5125 - val_mse: 0.5125\n",
      "Epoch 73/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7392 - mse: 0.7392 - val_loss: 0.5805 - val_mse: 0.5805\n",
      "Epoch 74/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7307 - mse: 0.7307 - val_loss: 0.6278 - val_mse: 0.6278\n",
      "Epoch 75/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7255 - mse: 0.7255 - val_loss: 0.6340 - val_mse: 0.6340\n",
      "Epoch 76/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7161 - mse: 0.7161 - val_loss: 0.6002 - val_mse: 0.6002\n",
      "Epoch 77/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7020 - mse: 0.7020 - val_loss: 0.5471 - val_mse: 0.5471\n",
      "Epoch 78/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6888 - mse: 0.6888 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 79/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6803 - mse: 0.6803 - val_loss: 0.4748 - val_mse: 0.4748\n",
      "Epoch 80/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6736 - mse: 0.6736 - val_loss: 0.4768 - val_mse: 0.4768\n",
      "Epoch 81/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6640 - mse: 0.6640 - val_loss: 0.5032 - val_mse: 0.5032\n",
      "Epoch 82/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6518 - mse: 0.6518 - val_loss: 0.5446 - val_mse: 0.5446\n",
      "Epoch 83/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6408 - mse: 0.6408 - val_loss: 0.5851 - val_mse: 0.5851\n",
      "Epoch 84/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6330 - mse: 0.6330 - val_loss: 0.6074 - val_mse: 0.6074\n",
      "Epoch 85/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6257 - mse: 0.6257 - val_loss: 0.6032 - val_mse: 0.6032\n",
      "Epoch 86/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6164 - mse: 0.6164 - val_loss: 0.5780 - val_mse: 0.5780\n",
      "Epoch 87/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6061 - mse: 0.6061 - val_loss: 0.5469 - val_mse: 0.5469\n",
      "Epoch 88/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5972 - mse: 0.5972 - val_loss: 0.5246 - val_mse: 0.5246\n",
      "Epoch 89/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5903 - mse: 0.5903 - val_loss: 0.5192 - val_mse: 0.5192\n",
      "Epoch 90/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5831 - mse: 0.5831 - val_loss: 0.5316 - val_mse: 0.5316\n",
      "Epoch 91/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5747 - mse: 0.5747 - val_loss: 0.5565 - val_mse: 0.5565\n",
      "Epoch 92/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5664 - mse: 0.5664 - val_loss: 0.5841 - val_mse: 0.5841\n",
      "Epoch 93/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5596 - mse: 0.5596 - val_loss: 0.6027 - val_mse: 0.6027\n",
      "Epoch 94/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5536 - mse: 0.5536 - val_loss: 0.6052 - val_mse: 0.6052\n",
      "Epoch 95/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5471 - mse: 0.5471 - val_loss: 0.5934 - val_mse: 0.5934\n",
      "Epoch 96/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5402 - mse: 0.5402 - val_loss: 0.5759 - val_mse: 0.5759\n",
      "Epoch 97/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5339 - mse: 0.5339 - val_loss: 0.5628 - val_mse: 0.5628\n",
      "Epoch 98/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5288 - mse: 0.5288 - val_loss: 0.5604 - val_mse: 0.5604\n",
      "Epoch 99/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5238 - mse: 0.5238 - val_loss: 0.5697 - val_mse: 0.5697\n",
      "Epoch 100/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5185 - mse: 0.5185 - val_loss: 0.5871 - val_mse: 0.5871\n",
      "Epoch 101/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5134 - mse: 0.5134 - val_loss: 0.6054 - val_mse: 0.6054\n",
      "Epoch 102/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5091 - mse: 0.5091 - val_loss: 0.6174 - val_mse: 0.6174\n",
      "Epoch 103/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5053 - mse: 0.5053 - val_loss: 0.6191 - val_mse: 0.6191\n",
      "Epoch 104/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5014 - mse: 0.5014 - val_loss: 0.6125 - val_mse: 0.6125\n",
      "Epoch 105/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4976 - mse: 0.4976 - val_loss: 0.6036 - val_mse: 0.6036\n",
      "Epoch 106/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4943 - mse: 0.4943 - val_loss: 0.5986 - val_mse: 0.5986\n",
      "Epoch 107/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4915 - mse: 0.4915 - val_loss: 0.6010 - val_mse: 0.6010\n",
      "Epoch 108/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4888 - mse: 0.4888 - val_loss: 0.6105 - val_mse: 0.6105\n",
      "Epoch 109/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4861 - mse: 0.4861 - val_loss: 0.6236 - val_mse: 0.6236\n",
      "Epoch 110/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4838 - mse: 0.4838 - val_loss: 0.6352 - val_mse: 0.6352\n",
      "Epoch 111/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4818 - mse: 0.4818 - val_loss: 0.6413 - val_mse: 0.6413\n",
      "Epoch 112/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4801 - mse: 0.4801 - val_loss: 0.6411 - val_mse: 0.6411\n",
      "Epoch 113/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4784 - mse: 0.4784 - val_loss: 0.6372 - val_mse: 0.6372\n",
      "Epoch 114/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4768 - mse: 0.4768 - val_loss: 0.6339 - val_mse: 0.6339\n",
      "Epoch 115/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4756 - mse: 0.4756 - val_loss: 0.6345 - val_mse: 0.6345\n",
      "Epoch 116/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4746 - mse: 0.4746 - val_loss: 0.6399 - val_mse: 0.6399\n",
      "Epoch 117/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4735 - mse: 0.4735 - val_loss: 0.6486 - val_mse: 0.6486\n",
      "Epoch 118/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4726 - mse: 0.4726 - val_loss: 0.6575 - val_mse: 0.6575\n",
      "Epoch 119/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4719 - mse: 0.4719 - val_loss: 0.6634 - val_mse: 0.6634\n",
      "Epoch 120/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4714 - mse: 0.4714 - val_loss: 0.6651 - val_mse: 0.6651\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "r2: 0.5061715681521795 meansquarederror: 0.10993443940318899 meanabsoluteerror: 0.2919868538462063 maxerror: 0.4548621614567141\n",
      "Epoch 1/120\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 1.5297 - mse: 1.5297 - val_loss: 38.5099 - val_mse: 38.5099\n",
      "Epoch 2/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 47.6074 - mse: 47.6074 - val_loss: 1.5963 - val_mse: 1.5963\n",
      "Epoch 3/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.6621 - mse: 4.6621 - val_loss: 15.4898 - val_mse: 15.4898\n",
      "Epoch 4/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 12.3928 - mse: 12.3928 - val_loss: 31.6861 - val_mse: 31.6861\n",
      "Epoch 5/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 26.5207 - mse: 26.5207 - val_loss: 21.6429 - val_mse: 21.6429\n",
      "Epoch 6/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 17.6362 - mse: 17.6362 - val_loss: 5.9086 - val_mse: 5.9086\n",
      "Epoch 7/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5956 - mse: 4.5956 - val_loss: 0.1203 - val_mse: 0.1203\n",
      "Epoch 8/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.8020 - mse: 1.8020 - val_loss: 4.0083 - val_mse: 4.0083\n",
      "Epoch 9/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.9267 - mse: 7.9267 - val_loss: 7.8148 - val_mse: 7.8148\n",
      "Epoch 10/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 12.6665 - mse: 12.6665 - val_loss: 6.4856 - val_mse: 6.4856\n",
      "Epoch 11/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 11.0343 - mse: 11.0343 - val_loss: 2.4069 - val_mse: 2.4069\n",
      "Epoch 12/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.7615 - mse: 5.7615 - val_loss: 0.1290 - val_mse: 0.1290\n",
      "Epoch 13/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.8144 - mse: 1.8144 - val_loss: 1.7980 - val_mse: 1.7980\n",
      "Epoch 14/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.7854 - mse: 1.7854 - val_loss: 5.7251 - val_mse: 5.7251\n",
      "Epoch 15/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.4015 - mse: 4.4015 - val_loss: 8.5109 - val_mse: 8.5109\n",
      "Epoch 16/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.5312 - mse: 6.5312 - val_loss: 8.2389 - val_mse: 8.2389\n",
      "Epoch 17/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.3116 - mse: 6.3116 - val_loss: 5.5257 - val_mse: 5.5257\n",
      "Epoch 18/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.2373 - mse: 4.2373 - val_loss: 2.3661 - val_mse: 2.3661\n",
      "Epoch 19/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.0814 - mse: 2.0814 - val_loss: 0.4544 - val_mse: 0.4544\n",
      "Epoch 20/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.2785 - mse: 1.2785 - val_loss: 0.1788 - val_mse: 0.1788\n",
      "Epoch 21/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.9734 - mse: 1.9734 - val_loss: 0.7486 - val_mse: 0.7486\n",
      "Epoch 22/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.1945 - mse: 3.1945 - val_loss: 1.1268 - val_mse: 1.1268\n",
      "Epoch 23/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.8165 - mse: 3.8165 - val_loss: 0.8820 - val_mse: 0.8820\n",
      "Epoch 24/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4116 - mse: 3.4116 - val_loss: 0.3404 - val_mse: 0.3404\n",
      "Epoch 25/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.3833 - mse: 2.3833 - val_loss: 0.1369 - val_mse: 0.1369\n",
      "Epoch 26/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4935 - mse: 1.4935 - val_loss: 0.6391 - val_mse: 0.6391\n",
      "Epoch 27/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2604 - mse: 1.2604 - val_loss: 1.6647 - val_mse: 1.6647\n",
      "Epoch 28/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.6490 - mse: 1.6490 - val_loss: 2.6441 - val_mse: 2.6441\n",
      "Epoch 29/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.2041 - mse: 2.2041 - val_loss: 3.0430 - val_mse: 3.0430\n",
      "Epoch 30/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.4516 - mse: 2.4516 - val_loss: 2.7008 - val_mse: 2.7008\n",
      "Epoch 31/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.2304 - mse: 2.2304 - val_loss: 1.8681 - val_mse: 1.8681\n",
      "Epoch 32/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.7381 - mse: 1.7381 - val_loss: 0.9836 - val_mse: 0.9836\n",
      "Epoch 33/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3245 - mse: 1.3245 - val_loss: 0.3863 - val_mse: 0.3863\n",
      "Epoch 34/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2240 - mse: 1.2240 - val_loss: 0.1528 - val_mse: 0.1528\n",
      "Epoch 35/120\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.4145 - mse: 1.4145 - val_loss: 0.1405 - val_mse: 0.1405\n",
      "Epoch 36/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.6783 - mse: 1.6783 - val_loss: 0.1621 - val_mse: 0.1621\n",
      "Epoch 37/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.7888 - mse: 1.7888 - val_loss: 0.1425 - val_mse: 0.1425\n",
      "Epoch 38/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.6709 - mse: 1.6709 - val_loss: 0.1471 - val_mse: 0.1471\n",
      "Epoch 39/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.4258 - mse: 1.4258 - val_loss: 0.2890 - val_mse: 0.2890\n",
      "Epoch 40/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.2279 - mse: 1.2279 - val_loss: 0.6062 - val_mse: 0.6062\n",
      "Epoch 41/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.1886 - mse: 1.1886 - val_loss: 1.0085 - val_mse: 1.0085\n",
      "Epoch 42/120\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2886 - mse: 1.2886 - val_loss: 1.3278 - val_mse: 1.3278\n",
      "Epoch 43/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.4139 - mse: 1.4139 - val_loss: 1.4258 - val_mse: 1.4258\n",
      "Epoch 44/120\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.4538 - mse: 1.4538 - val_loss: 1.2759 - val_mse: 1.2759\n",
      "Epoch 45/120\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.3799 - mse: 1.3799 - val_loss: 0.9667 - val_mse: 0.9667\n",
      "Epoch 46/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.2520 - mse: 1.2520 - val_loss: 0.6354 - val_mse: 0.6354\n",
      "Epoch 47/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1599 - mse: 1.1599 - val_loss: 0.3862 - val_mse: 0.3862\n",
      "Epoch 48/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.1524 - mse: 1.1524 - val_loss: 0.2490 - val_mse: 0.2490\n",
      "Epoch 49/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.2085 - mse: 1.2085 - val_loss: 0.1963 - val_mse: 0.1963\n",
      "Epoch 50/120\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2637 - mse: 1.2637 - val_loss: 0.1921 - val_mse: 0.1921\n",
      "Epoch 51/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.2659 - mse: 1.2659 - val_loss: 0.2276 - val_mse: 0.2276\n",
      "Epoch 52/120\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2125 - mse: 1.2125 - val_loss: 0.3176 - val_mse: 0.3176\n",
      "Epoch 53/120\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1441 - mse: 1.1441 - val_loss: 0.4693 - val_mse: 0.4693\n",
      "Epoch 54/120\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1062 - mse: 1.1062 - val_loss: 0.6554 - val_mse: 0.6554\n",
      "Epoch 55/120\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1135 - mse: 1.1135 - val_loss: 0.8172 - val_mse: 0.8172\n",
      "Epoch 56/120\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1434 - mse: 1.1434 - val_loss: 0.8953 - val_mse: 0.8953\n",
      "Epoch 57/120\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1597 - mse: 1.1597 - val_loss: 0.8649 - val_mse: 0.8649\n",
      "Epoch 58/120\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1433 - mse: 1.1433 - val_loss: 0.7477 - val_mse: 0.7477\n",
      "Epoch 59/120\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.1046 - mse: 1.1046 - val_loss: 0.5951 - val_mse: 0.5951\n",
      "Epoch 60/120\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0700 - mse: 1.0700 - val_loss: 0.4579 - val_mse: 0.4579\n",
      "Epoch 61/120\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0587 - mse: 1.0587 - val_loss: 0.3641 - val_mse: 0.3641\n",
      "Epoch 62/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0675 - mse: 1.0675 - val_loss: 0.3182 - val_mse: 0.3182\n",
      "Epoch 63/120\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.0776 - mse: 1.0776 - val_loss: 0.3142 - val_mse: 0.3142\n",
      "Epoch 64/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0723 - mse: 1.0723 - val_loss: 0.3478 - val_mse: 0.3478\n",
      "Epoch 65/120\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0506 - mse: 1.0506 - val_loss: 0.4163 - val_mse: 0.4163\n",
      "Epoch 66/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0255 - mse: 1.0255 - val_loss: 0.5100 - val_mse: 0.5100\n",
      "Epoch 67/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0107 - mse: 1.0107 - val_loss: 0.6064 - val_mse: 0.6064\n",
      "Epoch 68/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0089 - mse: 1.0089 - val_loss: 0.6762 - val_mse: 0.6762\n",
      "Epoch 69/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0111 - mse: 1.0111 - val_loss: 0.6968 - val_mse: 0.6968\n",
      "Epoch 70/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0065 - mse: 1.0065 - val_loss: 0.6650 - val_mse: 0.6650\n",
      "Epoch 71/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9918 - mse: 0.9918 - val_loss: 0.5972 - val_mse: 0.5972\n",
      "Epoch 72/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.9734 - mse: 0.9734 - val_loss: 0.5194 - val_mse: 0.5194\n",
      "Epoch 73/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9596 - mse: 0.9596 - val_loss: 0.4543 - val_mse: 0.4543\n",
      "Epoch 74/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9533 - mse: 0.9533 - val_loss: 0.4144 - val_mse: 0.4144\n",
      "Epoch 75/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9502 - mse: 0.9502 - val_loss: 0.4032 - val_mse: 0.4032\n",
      "Epoch 76/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9436 - mse: 0.9436 - val_loss: 0.4194 - val_mse: 0.4194\n",
      "Epoch 77/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9312 - mse: 0.9312 - val_loss: 0.4586 - val_mse: 0.4586\n",
      "Epoch 78/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9163 - mse: 0.9163 - val_loss: 0.5122 - val_mse: 0.5122\n",
      "Epoch 79/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9041 - mse: 0.9041 - val_loss: 0.5663 - val_mse: 0.5663\n",
      "Epoch 80/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8961 - mse: 0.8961 - val_loss: 0.6049 - val_mse: 0.6049\n",
      "Epoch 81/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8897 - mse: 0.8897 - val_loss: 0.6165 - val_mse: 0.6165\n",
      "Epoch 82/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8811 - mse: 0.8811 - val_loss: 0.5997 - val_mse: 0.5997\n",
      "Epoch 83/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8692 - mse: 0.8692 - val_loss: 0.5634 - val_mse: 0.5634\n",
      "Epoch 84/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8563 - mse: 0.8563 - val_loss: 0.5215 - val_mse: 0.5215\n",
      "Epoch 85/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8451 - mse: 0.8451 - val_loss: 0.4871 - val_mse: 0.4871\n",
      "Epoch 86/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8363 - mse: 0.8363 - val_loss: 0.4682 - val_mse: 0.4682\n",
      "Epoch 87/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8280 - mse: 0.8280 - val_loss: 0.4676 - val_mse: 0.4676\n",
      "Epoch 88/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8180 - mse: 0.8180 - val_loss: 0.4840 - val_mse: 0.4840\n",
      "Epoch 89/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8064 - mse: 0.8064 - val_loss: 0.5127 - val_mse: 0.5127\n",
      "Epoch 90/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7946 - mse: 0.7946 - val_loss: 0.5457 - val_mse: 0.5457\n",
      "Epoch 91/120\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7842 - mse: 0.7842 - val_loss: 0.5733 - val_mse: 0.5733\n",
      "Epoch 92/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7749 - mse: 0.7749 - val_loss: 0.5874 - val_mse: 0.5874\n",
      "Epoch 93/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7655 - mse: 0.7655 - val_loss: 0.5848 - val_mse: 0.5848\n",
      "Epoch 94/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7550 - mse: 0.7550 - val_loss: 0.5685 - val_mse: 0.5685\n",
      "Epoch 95/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7438 - mse: 0.7438 - val_loss: 0.5460 - val_mse: 0.5460\n",
      "Epoch 96/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7331 - mse: 0.7331 - val_loss: 0.5256 - val_mse: 0.5256\n",
      "Epoch 97/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7233 - mse: 0.7233 - val_loss: 0.5137 - val_mse: 0.5137\n",
      "Epoch 98/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7139 - mse: 0.7139 - val_loss: 0.5131 - val_mse: 0.5131\n",
      "Epoch 99/120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7042 - mse: 0.7042 - val_loss: 0.5235 - val_mse: 0.5235\n",
      "Epoch 100/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6939 - mse: 0.6939 - val_loss: 0.5415 - val_mse: 0.5415\n",
      "Epoch 101/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6836 - mse: 0.6836 - val_loss: 0.5620 - val_mse: 0.5620\n",
      "Epoch 102/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6740 - mse: 0.6740 - val_loss: 0.5786 - val_mse: 0.5786\n",
      "Epoch 103/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6649 - mse: 0.6649 - val_loss: 0.5867 - val_mse: 0.5867\n",
      "Epoch 104/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6558 - mse: 0.6558 - val_loss: 0.5851 - val_mse: 0.5851\n",
      "Epoch 105/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6465 - mse: 0.6465 - val_loss: 0.5760 - val_mse: 0.5760\n",
      "Epoch 106/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6372 - mse: 0.6372 - val_loss: 0.5642 - val_mse: 0.5642\n",
      "Epoch 107/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6283 - mse: 0.6283 - val_loss: 0.5548 - val_mse: 0.5548\n",
      "Epoch 108/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6198 - mse: 0.6198 - val_loss: 0.5515 - val_mse: 0.5515\n",
      "Epoch 109/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6116 - mse: 0.6116 - val_loss: 0.5553 - val_mse: 0.5553\n",
      "Epoch 110/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6034 - mse: 0.6034 - val_loss: 0.5653 - val_mse: 0.5653\n",
      "Epoch 111/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5953 - mse: 0.5953 - val_loss: 0.5786 - val_mse: 0.5786\n",
      "Epoch 112/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5875 - mse: 0.5875 - val_loss: 0.5912 - val_mse: 0.5912\n",
      "Epoch 113/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5801 - mse: 0.5801 - val_loss: 0.5998 - val_mse: 0.5998\n",
      "Epoch 114/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5730 - mse: 0.5730 - val_loss: 0.6025 - val_mse: 0.6025\n",
      "Epoch 115/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5661 - mse: 0.5661 - val_loss: 0.6000 - val_mse: 0.6000\n",
      "Epoch 116/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5593 - mse: 0.5593 - val_loss: 0.5949 - val_mse: 0.5949\n",
      "Epoch 117/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5528 - mse: 0.5528 - val_loss: 0.5904 - val_mse: 0.5904\n",
      "Epoch 118/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5467 - mse: 0.5467 - val_loss: 0.5892 - val_mse: 0.5892\n",
      "Epoch 119/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5409 - mse: 0.5409 - val_loss: 0.5924 - val_mse: 0.5924\n",
      "Epoch 120/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5354 - mse: 0.5354 - val_loss: 0.5995 - val_mse: 0.5995\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "r2: 0.3701548753592784 meansquarederror: 0.14021402216376866 meanabsoluteerror: 0.3406446799780772 maxerror: 0.5085570616172785\n",
      "Epoch 1/120\n",
      "1/1 [==============================] - 1s 640ms/step - loss: 1.8719 - mse: 1.8719 - val_loss: 34.4301 - val_mse: 34.4301\n",
      "Epoch 2/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 43.3268 - mse: 43.3268 - val_loss: 1.5416 - val_mse: 1.5416\n",
      "Epoch 3/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.6222 - mse: 4.6222 - val_loss: 14.0444 - val_mse: 14.0444\n",
      "Epoch 4/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 11.0855 - mse: 11.0855 - val_loss: 28.6283 - val_mse: 28.6283\n",
      "Epoch 5/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 23.6888 - mse: 23.6888 - val_loss: 18.6473 - val_mse: 18.6473\n",
      "Epoch 6/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 14.9557 - mse: 14.9557 - val_loss: 4.4076 - val_mse: 4.4076\n",
      "Epoch 7/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4526 - mse: 3.4526 - val_loss: 0.2197 - val_mse: 0.2197\n",
      "Epoch 8/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.1990 - mse: 2.1990 - val_loss: 4.2160 - val_mse: 4.2160\n",
      "Epoch 9/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.2553 - mse: 8.2553 - val_loss: 6.9806 - val_mse: 6.9806\n",
      "Epoch 10/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 11.7275 - mse: 11.7275 - val_loss: 4.9911 - val_mse: 4.9911\n",
      "Epoch 11/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.2307 - mse: 9.2307 - val_loss: 1.3420 - val_mse: 1.3420\n",
      "Epoch 12/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.2442 - mse: 4.2442 - val_loss: 0.2092 - val_mse: 0.2092\n",
      "Epoch 13/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.3925 - mse: 1.3925 - val_loss: 2.7628 - val_mse: 2.7628\n",
      "Epoch 14/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.3178 - mse: 2.3178 - val_loss: 6.5401 - val_mse: 6.5401\n",
      "Epoch 15/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.9679 - mse: 4.9679 - val_loss: 8.2834 - val_mse: 8.2834\n",
      "Epoch 16/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.3048 - mse: 6.3048 - val_loss: 6.9360 - val_mse: 6.9360\n",
      "Epoch 17/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.2590 - mse: 5.2590 - val_loss: 3.8743 - val_mse: 3.8743\n",
      "Epoch 18/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.0261 - mse: 3.0261 - val_loss: 1.2134 - val_mse: 1.2134\n",
      "Epoch 19/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.4580 - mse: 1.4580 - val_loss: 0.1471 - val_mse: 0.1471\n",
      "Epoch 20/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.4698 - mse: 1.4698 - val_loss: 0.4069 - val_mse: 0.4069\n",
      "Epoch 21/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.5589 - mse: 2.5589 - val_loss: 0.9338 - val_mse: 0.9338\n",
      "Epoch 22/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.5224 - mse: 3.5224 - val_loss: 0.9511 - val_mse: 0.9511\n",
      "Epoch 23/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.5448 - mse: 3.5448 - val_loss: 0.4883 - val_mse: 0.4883\n",
      "Epoch 24/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.7073 - mse: 2.7073 - val_loss: 0.1321 - val_mse: 0.1321\n",
      "Epoch 25/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.7128 - mse: 1.7128 - val_loss: 0.4114 - val_mse: 0.4114\n",
      "Epoch 26/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2444 - mse: 1.2444 - val_loss: 1.3359 - val_mse: 1.3359\n",
      "Epoch 27/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.4748 - mse: 1.4748 - val_loss: 2.3967 - val_mse: 2.3967\n",
      "Epoch 28/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.0334 - mse: 2.0334 - val_loss: 2.9718 - val_mse: 2.9718\n",
      "Epoch 29/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.3836 - mse: 2.3836 - val_loss: 2.7733 - val_mse: 2.7733\n",
      "Epoch 30/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.2541 - mse: 2.2541 - val_loss: 1.9887 - val_mse: 1.9887\n",
      "Epoch 31/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.7858 - mse: 1.7858 - val_loss: 1.0762 - val_mse: 1.0762\n",
      "Epoch 32/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3445 - mse: 1.3445 - val_loss: 0.4291 - val_mse: 0.4291\n",
      "Epoch 33/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2099 - mse: 1.2099 - val_loss: 0.1624 - val_mse: 0.1624\n",
      "Epoch 34/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3873 - mse: 1.3873 - val_loss: 0.1385 - val_mse: 0.1385\n",
      "Epoch 35/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.6552 - mse: 1.6552 - val_loss: 0.1588 - val_mse: 0.1588\n",
      "Epoch 36/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.7702 - mse: 1.7702 - val_loss: 0.1407 - val_mse: 0.1407\n",
      "Epoch 37/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.6493 - mse: 1.6493 - val_loss: 0.1537 - val_mse: 0.1537\n",
      "Epoch 38/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.4002 - mse: 1.4002 - val_loss: 0.3161 - val_mse: 0.3161\n",
      "Epoch 39/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2080 - mse: 1.2080 - val_loss: 0.6600 - val_mse: 0.6600\n",
      "Epoch 40/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.1849 - mse: 1.1849 - val_loss: 1.0763 - val_mse: 1.0763\n",
      "Epoch 41/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.2985 - mse: 1.2985 - val_loss: 1.3792 - val_mse: 1.3792\n",
      "Epoch 42/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.4201 - mse: 1.4201 - val_loss: 1.4312 - val_mse: 1.4312\n",
      "Epoch 43/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.4386 - mse: 1.4386 - val_loss: 1.2283 - val_mse: 1.2283\n",
      "Epoch 44/120\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.3424 - mse: 1.3424 - val_loss: 0.8874 - val_mse: 0.8874\n",
      "Epoch 45/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.2111 - mse: 1.2111 - val_loss: 0.5582 - val_mse: 0.5582\n",
      "Epoch 46/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.1384 - mse: 1.1384 - val_loss: 0.3345 - val_mse: 0.3345\n",
      "Epoch 47/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1571 - mse: 1.1571 - val_loss: 0.2256 - val_mse: 0.2256\n",
      "Epoch 48/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.2236 - mse: 1.2236 - val_loss: 0.1922 - val_mse: 0.1922\n",
      "Epoch 49/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2652 - mse: 1.2652 - val_loss: 0.2034 - val_mse: 0.2034\n",
      "Epoch 50/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2419 - mse: 1.2419 - val_loss: 0.2623 - val_mse: 0.2623\n",
      "Epoch 51/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1726 - mse: 1.1726 - val_loss: 0.3869 - val_mse: 0.3869\n",
      "Epoch 52/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.1104 - mse: 1.1104 - val_loss: 0.5705 - val_mse: 0.5705\n",
      "Epoch 53/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0940 - mse: 1.0940 - val_loss: 0.7635 - val_mse: 0.7635\n",
      "Epoch 54/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1189 - mse: 1.1189 - val_loss: 0.8944 - val_mse: 0.8944\n",
      "Epoch 55/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.1475 - mse: 1.1475 - val_loss: 0.9129 - val_mse: 0.9129\n",
      "Epoch 56/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1460 - mse: 1.1460 - val_loss: 0.8205 - val_mse: 0.8205\n",
      "Epoch 57/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1115 - mse: 1.1115 - val_loss: 0.6652 - val_mse: 0.6652\n",
      "Epoch 58/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0695 - mse: 1.0695 - val_loss: 0.5085 - val_mse: 0.5085\n",
      "Epoch 59/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0478 - mse: 1.0478 - val_loss: 0.3923 - val_mse: 0.3923\n",
      "Epoch 60/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0524 - mse: 1.0524 - val_loss: 0.3291 - val_mse: 0.3291\n",
      "Epoch 61/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0657 - mse: 1.0657 - val_loss: 0.3136 - val_mse: 0.3136\n",
      "Epoch 62/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0657 - mse: 1.0657 - val_loss: 0.3398 - val_mse: 0.3398\n",
      "Epoch 63/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0457 - mse: 1.0457 - val_loss: 0.4053 - val_mse: 0.4053\n",
      "Epoch 64/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0179 - mse: 1.0179 - val_loss: 0.5020 - val_mse: 0.5020\n",
      "Epoch 65/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9993 - mse: 0.9993 - val_loss: 0.6076 - val_mse: 0.6076\n",
      "Epoch 66/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9959 - mse: 0.9959 - val_loss: 0.6886 - val_mse: 0.6886\n",
      "Epoch 67/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9991 - mse: 0.9991 - val_loss: 0.7171 - val_mse: 0.7171\n",
      "Epoch 68/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9956 - mse: 0.9956 - val_loss: 0.6864 - val_mse: 0.6864\n",
      "Epoch 69/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9806 - mse: 0.9806 - val_loss: 0.6139 - val_mse: 0.6139\n",
      "Epoch 70/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9605 - mse: 0.9605 - val_loss: 0.5294 - val_mse: 0.5294\n",
      "Epoch 71/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9456 - mse: 0.9456 - val_loss: 0.4591 - val_mse: 0.4591\n",
      "Epoch 72/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9394 - mse: 0.9394 - val_loss: 0.4172 - val_mse: 0.4172\n",
      "Epoch 73/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9366 - mse: 0.9366 - val_loss: 0.4072 - val_mse: 0.4072\n",
      "Epoch 74/120\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.9294 - mse: 0.9294 - val_loss: 0.4272 - val_mse: 0.4272\n",
      "Epoch 75/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9157 - mse: 0.9157 - val_loss: 0.4723 - val_mse: 0.4723\n",
      "Epoch 76/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8998 - mse: 0.8998 - val_loss: 0.5320 - val_mse: 0.5320\n",
      "Epoch 77/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8875 - mse: 0.8875 - val_loss: 0.5896 - val_mse: 0.5896\n",
      "Epoch 78/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8799 - mse: 0.8799 - val_loss: 0.6266 - val_mse: 0.6266\n",
      "Epoch 79/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8734 - mse: 0.8734 - val_loss: 0.6316 - val_mse: 0.6316\n",
      "Epoch 80/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8637 - mse: 0.8637 - val_loss: 0.6060 - val_mse: 0.6060\n",
      "Epoch 81/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8504 - mse: 0.8504 - val_loss: 0.5623 - val_mse: 0.5623\n",
      "Epoch 82/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8369 - mse: 0.8369 - val_loss: 0.5173 - val_mse: 0.5173\n",
      "Epoch 83/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8261 - mse: 0.8261 - val_loss: 0.4847 - val_mse: 0.4847\n",
      "Epoch 84/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8177 - mse: 0.8177 - val_loss: 0.4713 - val_mse: 0.4713\n",
      "Epoch 85/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8088 - mse: 0.8088 - val_loss: 0.4786 - val_mse: 0.4786\n",
      "Epoch 86/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7976 - mse: 0.7976 - val_loss: 0.5034 - val_mse: 0.5034\n",
      "Epoch 87/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7850 - mse: 0.7850 - val_loss: 0.5386 - val_mse: 0.5386\n",
      "Epoch 88/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7732 - mse: 0.7732 - val_loss: 0.5736 - val_mse: 0.5736\n",
      "Epoch 89/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7633 - mse: 0.7633 - val_loss: 0.5973 - val_mse: 0.5973\n",
      "Epoch 90/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7540 - mse: 0.7540 - val_loss: 0.6026 - val_mse: 0.6026\n",
      "Epoch 91/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7438 - mse: 0.7438 - val_loss: 0.5897 - val_mse: 0.5897\n",
      "Epoch 92/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7323 - mse: 0.7323 - val_loss: 0.5659 - val_mse: 0.5659\n",
      "Epoch 93/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7209 - mse: 0.7209 - val_loss: 0.5410 - val_mse: 0.5410\n",
      "Epoch 94/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7105 - mse: 0.7105 - val_loss: 0.5238 - val_mse: 0.5238\n",
      "Epoch 95/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7010 - mse: 0.7010 - val_loss: 0.5190 - val_mse: 0.5190\n",
      "Epoch 96/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6914 - mse: 0.6914 - val_loss: 0.5273 - val_mse: 0.5273\n",
      "Epoch 97/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6809 - mse: 0.6809 - val_loss: 0.5458 - val_mse: 0.5458\n",
      "Epoch 98/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6703 - mse: 0.6703 - val_loss: 0.5686 - val_mse: 0.5686\n",
      "Epoch 99/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6604 - mse: 0.6604 - val_loss: 0.5884 - val_mse: 0.5884\n",
      "Epoch 100/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6512 - mse: 0.6512 - val_loss: 0.5990 - val_mse: 0.5990\n",
      "Epoch 101/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6421 - mse: 0.6421 - val_loss: 0.5981 - val_mse: 0.5981\n",
      "Epoch 102/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6328 - mse: 0.6328 - val_loss: 0.5881 - val_mse: 0.5881\n",
      "Epoch 103/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6233 - mse: 0.6233 - val_loss: 0.5745 - val_mse: 0.5745\n",
      "Epoch 104/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6143 - mse: 0.6143 - val_loss: 0.5634 - val_mse: 0.5634\n",
      "Epoch 105/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6059 - mse: 0.6059 - val_loss: 0.5592 - val_mse: 0.5592\n",
      "Epoch 106/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5978 - mse: 0.5978 - val_loss: 0.5634 - val_mse: 0.5634\n",
      "Epoch 107/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5897 - mse: 0.5897 - val_loss: 0.5748 - val_mse: 0.5748\n",
      "Epoch 108/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5816 - mse: 0.5816 - val_loss: 0.5897 - val_mse: 0.5897\n",
      "Epoch 109/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5739 - mse: 0.5739 - val_loss: 0.6034 - val_mse: 0.6034\n",
      "Epoch 110/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5667 - mse: 0.5667 - val_loss: 0.6119 - val_mse: 0.6119\n",
      "Epoch 111/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5599 - mse: 0.5599 - val_loss: 0.6134 - val_mse: 0.6134\n",
      "Epoch 112/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5531 - mse: 0.5531 - val_loss: 0.6092 - val_mse: 0.6092\n",
      "Epoch 113/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5465 - mse: 0.5465 - val_loss: 0.6028 - val_mse: 0.6028\n",
      "Epoch 114/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5403 - mse: 0.5403 - val_loss: 0.5980 - val_mse: 0.5980\n",
      "Epoch 115/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5346 - mse: 0.5346 - val_loss: 0.5976 - val_mse: 0.5976\n",
      "Epoch 116/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5291 - mse: 0.5291 - val_loss: 0.6025 - val_mse: 0.6025\n",
      "Epoch 117/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5239 - mse: 0.5239 - val_loss: 0.6115 - val_mse: 0.6115\n",
      "Epoch 118/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5189 - mse: 0.5189 - val_loss: 0.6220 - val_mse: 0.6220\n",
      "Epoch 119/120\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5142 - mse: 0.5142 - val_loss: 0.6311 - val_mse: 0.6311\n",
      "Epoch 120/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5099 - mse: 0.5099 - val_loss: 0.6365 - val_mse: 0.6365\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "r2: 0.443948243923763 meansquarederror: 0.12378638843183831 meanabsoluteerror: 0.3195955747767967 maxerror: 0.4800888942688961\n",
      "Epoch 1/120\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 2.0227 - mse: 2.0227 - val_loss: 47.0055 - val_mse: 47.0055\n",
      "Epoch 2/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 40.2866 - mse: 40.2866 - val_loss: 5.8342 - val_mse: 5.8342\n",
      "Epoch 3/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.5080 - mse: 4.5080 - val_loss: 5.6815 - val_mse: 5.6815\n",
      "Epoch 4/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 10.1818 - mse: 10.1818 - val_loss: 15.5212 - val_mse: 15.5212\n",
      "Epoch 5/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 21.9113 - mse: 21.9113 - val_loss: 8.5941 - val_mse: 8.5941\n",
      "Epoch 6/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 13.7340 - mse: 13.7340 - val_loss: 0.6483 - val_mse: 0.6483\n",
      "Epoch 7/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.1284 - mse: 3.1284 - val_loss: 2.6483 - val_mse: 2.6483\n",
      "Epoch 8/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.2741 - mse: 2.2741 - val_loss: 10.4132 - val_mse: 10.4132\n",
      "Epoch 9/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.0277 - mse: 8.0277 - val_loss: 14.0548 - val_mse: 14.0548\n",
      "Epoch 10/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 11.0056 - mse: 11.0056 - val_loss: 10.8574 - val_mse: 10.8574\n",
      "Epoch 11/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.3707 - mse: 8.3707 - val_loss: 4.7974 - val_mse: 4.7974\n",
      "Epoch 12/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.6928 - mse: 3.6928 - val_loss: 0.7172 - val_mse: 0.7172\n",
      "Epoch 13/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.3226 - mse: 1.3226 - val_loss: 0.3631 - val_mse: 0.3631\n",
      "Epoch 14/120\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.5117 - mse: 2.5117 - val_loss: 1.8747 - val_mse: 1.8747\n",
      "Epoch 15/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.0177 - mse: 5.0177 - val_loss: 2.5679 - val_mse: 2.5679\n",
      "Epoch 16/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.9910 - mse: 5.9910 - val_loss: 1.6790 - val_mse: 1.6790\n",
      "Epoch 17/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.7168 - mse: 4.7168 - val_loss: 0.4063 - val_mse: 0.4063\n",
      "Epoch 18/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.5790 - mse: 2.5790 - val_loss: 0.2510 - val_mse: 0.2510\n",
      "Epoch 19/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.3326 - mse: 1.3326 - val_loss: 1.5890 - val_mse: 1.5890\n",
      "Epoch 20/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.6243 - mse: 1.6243 - val_loss: 3.4787 - val_mse: 3.4787\n",
      "Epoch 21/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.7441 - mse: 2.7441 - val_loss: 4.5953 - val_mse: 4.5953\n",
      "Epoch 22/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.5064 - mse: 3.5064 - val_loss: 4.2933 - val_mse: 4.2933\n",
      "Epoch 23/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.2907 - mse: 3.2907 - val_loss: 2.9202 - val_mse: 2.9202\n",
      "Epoch 24/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.3706 - mse: 2.3706 - val_loss: 1.3688 - val_mse: 1.3688\n",
      "Epoch 25/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.4990 - mse: 1.4990 - val_loss: 0.3829 - val_mse: 0.3829\n",
      "Epoch 26/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2502 - mse: 1.2502 - val_loss: 0.1265 - val_mse: 0.1265\n",
      "Epoch 27/120\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.6252 - mse: 1.6252 - val_loss: 0.2543 - val_mse: 0.2543\n",
      "Epoch 28/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.1558 - mse: 2.1558 - val_loss: 0.3358 - val_mse: 0.3358\n",
      "Epoch 29/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.3509 - mse: 2.3509 - val_loss: 0.2310 - val_mse: 0.2310\n",
      "Epoch 30/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.0771 - mse: 2.0771 - val_loss: 0.1289 - val_mse: 0.1289\n",
      "Epoch 31/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.5869 - mse: 1.5869 - val_loss: 0.2984 - val_mse: 0.2984\n",
      "Epoch 32/120\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.2508 - mse: 1.2508 - val_loss: 0.8101 - val_mse: 0.8101\n",
      "Epoch 33/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.2558 - mse: 1.2558 - val_loss: 1.4559 - val_mse: 1.4559\n",
      "Epoch 34/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.4995 - mse: 1.4995 - val_loss: 1.9016 - val_mse: 1.9016\n",
      "Epoch 35/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.7218 - mse: 1.7218 - val_loss: 1.9264 - val_mse: 1.9264\n",
      "Epoch 36/120\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.7307 - mse: 1.7307 - val_loss: 1.5551 - val_mse: 1.5551\n",
      "Epoch 37/120\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.5329 - mse: 1.5329 - val_loss: 1.0078 - val_mse: 1.0078\n",
      "Epoch 38/120\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2926 - mse: 1.2926 - val_loss: 0.5327 - val_mse: 0.5327\n",
      "Epoch 39/120\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1791 - mse: 1.1791 - val_loss: 0.2578 - val_mse: 0.2578\n",
      "Epoch 40/120\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.2367 - mse: 1.2367 - val_loss: 0.1588 - val_mse: 0.1588\n",
      "Epoch 41/120\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.3713 - mse: 1.3713 - val_loss: 0.1419 - val_mse: 0.1419\n",
      "Epoch 42/120\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4462 - mse: 1.4462 - val_loss: 0.1502 - val_mse: 0.1502\n",
      "Epoch 43/120\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3967 - mse: 1.3967 - val_loss: 0.2048 - val_mse: 0.2048\n",
      "Epoch 44/120\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2686 - mse: 1.2686 - val_loss: 0.3565 - val_mse: 0.3565\n",
      "Epoch 45/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1630 - mse: 1.1630 - val_loss: 0.6092 - val_mse: 0.6092\n",
      "Epoch 46/120\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1462 - mse: 1.1462 - val_loss: 0.8877 - val_mse: 0.8877\n",
      "Epoch 47/120\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2028 - mse: 1.2028 - val_loss: 1.0764 - val_mse: 1.0764\n",
      "Epoch 48/120\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.2617 - mse: 1.2617 - val_loss: 1.0959 - val_mse: 1.0959\n",
      "Epoch 49/120\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.2629 - mse: 1.2629 - val_loss: 0.9511 - val_mse: 0.9511\n",
      "Epoch 50/120\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.2042 - mse: 1.2042 - val_loss: 0.7205 - val_mse: 0.7205\n",
      "Epoch 51/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1334 - mse: 1.1334 - val_loss: 0.4991 - val_mse: 0.4991\n",
      "Epoch 52/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1006 - mse: 1.1006 - val_loss: 0.3457 - val_mse: 0.3457\n",
      "Epoch 53/120\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1164 - mse: 1.1164 - val_loss: 0.2683 - val_mse: 0.2683\n",
      "Epoch 54/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1489 - mse: 1.1489 - val_loss: 0.2492 - val_mse: 0.2492\n",
      "Epoch 55/120\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1577 - mse: 1.1577 - val_loss: 0.2765 - val_mse: 0.2765\n",
      "Epoch 56/120\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1297 - mse: 1.1297 - val_loss: 0.3526 - val_mse: 0.3526\n",
      "Epoch 57/120\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0860 - mse: 1.0860 - val_loss: 0.4758 - val_mse: 0.4758\n",
      "Epoch 58/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0579 - mse: 1.0579 - val_loss: 0.6209 - val_mse: 0.6209\n",
      "Epoch 59/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0580 - mse: 1.0580 - val_loss: 0.7402 - val_mse: 0.7402\n",
      "Epoch 60/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0720 - mse: 1.0720 - val_loss: 0.7889 - val_mse: 0.7889\n",
      "Epoch 61/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.0758 - mse: 1.0758 - val_loss: 0.7524 - val_mse: 0.7524\n",
      "Epoch 62/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.0586 - mse: 1.0586 - val_loss: 0.6533 - val_mse: 0.6533\n",
      "Epoch 63/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0303 - mse: 1.0303 - val_loss: 0.5348 - val_mse: 0.5348\n",
      "Epoch 64/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.0093 - mse: 1.0093 - val_loss: 0.4355 - val_mse: 0.4355\n",
      "Epoch 65/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0044 - mse: 1.0044 - val_loss: 0.3744 - val_mse: 0.3744\n",
      "Epoch 66/120\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0078 - mse: 1.0078 - val_loss: 0.3543 - val_mse: 0.3543\n",
      "Epoch 67/120\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0055 - mse: 1.0055 - val_loss: 0.3720 - val_mse: 0.3720\n",
      "Epoch 68/120\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9911 - mse: 0.9911 - val_loss: 0.4231 - val_mse: 0.4231\n",
      "Epoch 69/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.9706 - mse: 0.9706 - val_loss: 0.4984 - val_mse: 0.4984\n",
      "Epoch 70/120\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9550 - mse: 0.9550 - val_loss: 0.5784 - val_mse: 0.5784\n",
      "Epoch 71/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9485 - mse: 0.9485 - val_loss: 0.6372 - val_mse: 0.6372\n",
      "Epoch 72/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9459 - mse: 0.9459 - val_loss: 0.6545 - val_mse: 0.6545\n",
      "Epoch 73/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9388 - mse: 0.9388 - val_loss: 0.6271 - val_mse: 0.6271\n",
      "Epoch 74/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9247 - mse: 0.9247 - val_loss: 0.5699 - val_mse: 0.5699\n",
      "Epoch 75/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9084 - mse: 0.9084 - val_loss: 0.5062 - val_mse: 0.5062\n",
      "Epoch 76/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8961 - mse: 0.8961 - val_loss: 0.4559 - val_mse: 0.4559\n",
      "Epoch 77/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8888 - mse: 0.8888 - val_loss: 0.4295 - val_mse: 0.4295\n",
      "Epoch 78/120\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8822 - mse: 0.8822 - val_loss: 0.4298 - val_mse: 0.4298\n",
      "Epoch 79/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8719 - mse: 0.8719 - val_loss: 0.4543 - val_mse: 0.4543\n",
      "Epoch 80/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8581 - mse: 0.8581 - val_loss: 0.4963 - val_mse: 0.4963\n",
      "Epoch 81/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8445 - mse: 0.8445 - val_loss: 0.5438 - val_mse: 0.5438\n",
      "Epoch 82/120\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8339 - mse: 0.8339 - val_loss: 0.5815 - val_mse: 0.5815\n",
      "Epoch 83/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8255 - mse: 0.8255 - val_loss: 0.5968 - val_mse: 0.5968\n",
      "Epoch 84/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8162 - mse: 0.8162 - val_loss: 0.5861 - val_mse: 0.5861\n",
      "Epoch 85/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8043 - mse: 0.8043 - val_loss: 0.5562 - val_mse: 0.5562\n",
      "Epoch 86/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7913 - mse: 0.7913 - val_loss: 0.5203 - val_mse: 0.5203\n",
      "Epoch 87/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7796 - mse: 0.7796 - val_loss: 0.4910 - val_mse: 0.4910\n",
      "Epoch 88/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7698 - mse: 0.7698 - val_loss: 0.4764 - val_mse: 0.4764\n",
      "Epoch 89/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7603 - mse: 0.7603 - val_loss: 0.4790 - val_mse: 0.4790\n",
      "Epoch 90/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7494 - mse: 0.7494 - val_loss: 0.4970 - val_mse: 0.4970\n",
      "Epoch 91/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7374 - mse: 0.7374 - val_loss: 0.5244 - val_mse: 0.5244\n",
      "Epoch 92/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7259 - mse: 0.7259 - val_loss: 0.5522 - val_mse: 0.5522\n",
      "Epoch 93/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7156 - mse: 0.7156 - val_loss: 0.5712 - val_mse: 0.5712\n",
      "Epoch 94/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7060 - mse: 0.7060 - val_loss: 0.5753 - val_mse: 0.5753\n",
      "Epoch 95/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6957 - mse: 0.6957 - val_loss: 0.5648 - val_mse: 0.5648\n",
      "Epoch 96/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6848 - mse: 0.6848 - val_loss: 0.5460 - val_mse: 0.5460\n",
      "Epoch 97/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6740 - mse: 0.6740 - val_loss: 0.5270 - val_mse: 0.5270\n",
      "Epoch 98/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6641 - mse: 0.6641 - val_loss: 0.5151 - val_mse: 0.5151\n",
      "Epoch 99/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6547 - mse: 0.6547 - val_loss: 0.5138 - val_mse: 0.5138\n",
      "Epoch 100/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6453 - mse: 0.6453 - val_loss: 0.5230 - val_mse: 0.5230\n",
      "Epoch 101/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6354 - mse: 0.6354 - val_loss: 0.5395 - val_mse: 0.5395\n",
      "Epoch 102/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6258 - mse: 0.6258 - val_loss: 0.5577 - val_mse: 0.5577\n",
      "Epoch 103/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6168 - mse: 0.6168 - val_loss: 0.5713 - val_mse: 0.5713\n",
      "Epoch 104/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6083 - mse: 0.6083 - val_loss: 0.5763 - val_mse: 0.5763\n",
      "Epoch 105/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5999 - mse: 0.5999 - val_loss: 0.5723 - val_mse: 0.5723\n",
      "Epoch 106/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5913 - mse: 0.5913 - val_loss: 0.5628 - val_mse: 0.5628\n",
      "Epoch 107/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5831 - mse: 0.5831 - val_loss: 0.5531 - val_mse: 0.5531\n",
      "Epoch 108/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5754 - mse: 0.5754 - val_loss: 0.5476 - val_mse: 0.5476\n",
      "Epoch 109/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5681 - mse: 0.5681 - val_loss: 0.5490 - val_mse: 0.5490\n",
      "Epoch 110/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5610 - mse: 0.5610 - val_loss: 0.5568 - val_mse: 0.5568\n",
      "Epoch 111/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5540 - mse: 0.5540 - val_loss: 0.5687 - val_mse: 0.5687\n",
      "Epoch 112/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5474 - mse: 0.5474 - val_loss: 0.5807 - val_mse: 0.5807\n",
      "Epoch 113/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5412 - mse: 0.5412 - val_loss: 0.5892 - val_mse: 0.5892\n",
      "Epoch 114/120\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5354 - mse: 0.5354 - val_loss: 0.5922 - val_mse: 0.5922\n",
      "Epoch 115/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5298 - mse: 0.5298 - val_loss: 0.5902 - val_mse: 0.5902\n",
      "Epoch 116/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5244 - mse: 0.5244 - val_loss: 0.5859 - val_mse: 0.5859\n",
      "Epoch 117/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5194 - mse: 0.5194 - val_loss: 0.5827 - val_mse: 0.5827\n",
      "Epoch 118/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5148 - mse: 0.5148 - val_loss: 0.5830 - val_mse: 0.5830\n",
      "Epoch 119/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5105 - mse: 0.5105 - val_loss: 0.5877 - val_mse: 0.5877\n",
      "Epoch 120/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5065 - mse: 0.5065 - val_loss: 0.5957 - val_mse: 0.5957\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "r2: 0.39222702329805914 meansquarederror: 0.13530039416346376 meanabsoluteerror: 0.33136489001212593 maxerror: 0.5144356440929756\n",
      "Epoch 1/120\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 1.4528 - mse: 1.4528 - val_loss: 38.3687 - val_mse: 38.3687\n",
      "Epoch 2/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 47.5181 - mse: 47.5181 - val_loss: 1.5086 - val_mse: 1.5086\n",
      "Epoch 3/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.5577 - mse: 4.5577 - val_loss: 15.3801 - val_mse: 15.3801\n",
      "Epoch 4/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 12.2210 - mse: 12.2210 - val_loss: 31.8403 - val_mse: 31.8403\n",
      "Epoch 5/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 26.5362 - mse: 26.5362 - val_loss: 22.6148 - val_mse: 22.6148\n",
      "Epoch 6/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 18.3837 - mse: 18.3837 - val_loss: 6.8602 - val_mse: 6.8602\n",
      "Epoch 7/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.2707 - mse: 5.2707 - val_loss: 0.1301 - val_mse: 0.1301\n",
      "Epoch 8/120\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5558 - mse: 1.5558 - val_loss: 3.3968 - val_mse: 3.3968\n",
      "Epoch 9/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.1609 - mse: 7.1609 - val_loss: 7.5282 - val_mse: 7.5282\n",
      "Epoch 10/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 12.3666 - mse: 12.3666 - val_loss: 6.8107 - val_mse: 6.8107\n",
      "Epoch 11/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 11.4800 - mse: 11.4800 - val_loss: 2.9140 - val_mse: 2.9140\n",
      "Epoch 12/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.4905 - mse: 6.4905 - val_loss: 0.2231 - val_mse: 0.2231\n",
      "Epoch 13/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.1803 - mse: 2.1803 - val_loss: 1.2776 - val_mse: 1.2776\n",
      "Epoch 14/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.5185 - mse: 1.5185 - val_loss: 4.9770 - val_mse: 4.9770\n",
      "Epoch 15/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.8203 - mse: 3.8203 - val_loss: 8.1303 - val_mse: 8.1303\n",
      "Epoch 16/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.1869 - mse: 6.1869 - val_loss: 8.4993 - val_mse: 8.4993\n",
      "Epoch 17/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.4701 - mse: 6.4701 - val_loss: 6.2248 - val_mse: 6.2248\n",
      "Epoch 18/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.7211 - mse: 4.7211 - val_loss: 3.0543 - val_mse: 3.0543\n",
      "Epoch 19/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.4874 - mse: 2.4874 - val_loss: 0.7840 - val_mse: 0.7840\n",
      "Epoch 20/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3171 - mse: 1.3171 - val_loss: 0.1218 - val_mse: 0.1218\n",
      "Epoch 21/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.6731 - mse: 1.6731 - val_loss: 0.5424 - val_mse: 0.5424\n",
      "Epoch 22/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.8368 - mse: 2.8368 - val_loss: 1.0308 - val_mse: 1.0308\n",
      "Epoch 23/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.6841 - mse: 3.6841 - val_loss: 0.9701 - val_mse: 0.9701\n",
      "Epoch 24/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.5788 - mse: 3.5788 - val_loss: 0.4803 - val_mse: 0.4803\n",
      "Epoch 25/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.6971 - mse: 2.6971 - val_loss: 0.1302 - val_mse: 0.1302\n",
      "Epoch 26/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.7170 - mse: 1.7170 - val_loss: 0.3946 - val_mse: 0.3946\n",
      "Epoch 27/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2534 - mse: 1.2534 - val_loss: 1.2759 - val_mse: 1.2759\n",
      "Epoch 28/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.4555 - mse: 1.4555 - val_loss: 2.3193 - val_mse: 2.3193\n",
      "Epoch 29/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.9939 - mse: 1.9939 - val_loss: 2.9560 - val_mse: 2.9560\n",
      "Epoch 30/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.3790 - mse: 2.3790 - val_loss: 2.8819 - val_mse: 2.8819\n",
      "Epoch 31/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.3280 - mse: 2.3280 - val_loss: 2.2049 - val_mse: 2.2049\n",
      "Epoch 32/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.9147 - mse: 1.9147 - val_loss: 1.3101 - val_mse: 1.3101\n",
      "Epoch 33/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.4482 - mse: 1.4482 - val_loss: 0.5874 - val_mse: 0.5874\n",
      "Epoch 34/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.2192 - mse: 1.2192 - val_loss: 0.2162 - val_mse: 0.2162\n",
      "Epoch 35/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.3067 - mse: 1.3067 - val_loss: 0.1311 - val_mse: 0.1311\n",
      "Epoch 36/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.5613 - mse: 1.5613 - val_loss: 0.1509 - val_mse: 0.1509\n",
      "Epoch 37/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.7489 - mse: 1.7489 - val_loss: 0.1487 - val_mse: 0.1487\n",
      "Epoch 38/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.7270 - mse: 1.7270 - val_loss: 0.1339 - val_mse: 0.1339\n",
      "Epoch 39/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.5258 - mse: 1.5258 - val_loss: 0.2074 - val_mse: 0.2074\n",
      "Epoch 40/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2957 - mse: 1.2957 - val_loss: 0.4474 - val_mse: 0.4474\n",
      "Epoch 41/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1823 - mse: 1.1823 - val_loss: 0.8221 - val_mse: 0.8221\n",
      "Epoch 42/120\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.2257 - mse: 1.2257 - val_loss: 1.1937 - val_mse: 1.1937\n",
      "Epoch 43/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.3499 - mse: 1.3499 - val_loss: 1.4033 - val_mse: 1.4033\n",
      "Epoch 44/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.4364 - mse: 1.4364 - val_loss: 1.3691 - val_mse: 1.3691\n",
      "Epoch 45/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.4153 - mse: 1.4153 - val_loss: 1.1275 - val_mse: 1.1275\n",
      "Epoch 46/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.3070 - mse: 1.3070 - val_loss: 0.7979 - val_mse: 0.7979\n",
      "Epoch 47/120\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1918 - mse: 1.1918 - val_loss: 0.5044 - val_mse: 0.5044\n",
      "Epoch 48/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.1422 - mse: 1.1422 - val_loss: 0.3131 - val_mse: 0.3131\n",
      "Epoch 49/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.1711 - mse: 1.1711 - val_loss: 0.2216 - val_mse: 0.2216\n",
      "Epoch 50/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2321 - mse: 1.2321 - val_loss: 0.1948 - val_mse: 0.1948\n",
      "Epoch 51/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2638 - mse: 1.2638 - val_loss: 0.2090 - val_mse: 0.2090\n",
      "Epoch 52/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2376 - mse: 1.2376 - val_loss: 0.2686 - val_mse: 0.2686\n",
      "Epoch 53/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1734 - mse: 1.1734 - val_loss: 0.3877 - val_mse: 0.3877\n",
      "Epoch 54/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1170 - mse: 1.1170 - val_loss: 0.5585 - val_mse: 0.5585\n",
      "Epoch 55/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1009 - mse: 1.1009 - val_loss: 0.7382 - val_mse: 0.7382\n",
      "Epoch 56/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.1214 - mse: 1.1214 - val_loss: 0.8655 - val_mse: 0.8655\n",
      "Epoch 57/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1476 - mse: 1.1476 - val_loss: 0.8952 - val_mse: 0.8952\n",
      "Epoch 58/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.1496 - mse: 1.1496 - val_loss: 0.8236 - val_mse: 0.8236\n",
      "Epoch 59/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.1217 - mse: 1.1217 - val_loss: 0.6874 - val_mse: 0.6874\n",
      "Epoch 60/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.0829 - mse: 1.0829 - val_loss: 0.5392 - val_mse: 0.5392\n",
      "Epoch 61/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0579 - mse: 1.0579 - val_loss: 0.4203 - val_mse: 0.4203\n",
      "Epoch 62/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0564 - mse: 1.0564 - val_loss: 0.3476 - val_mse: 0.3476\n",
      "Epoch 63/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0673 - mse: 1.0673 - val_loss: 0.3199 - val_mse: 0.3199\n",
      "Epoch 64/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0717 - mse: 1.0717 - val_loss: 0.3314 - val_mse: 0.3314\n",
      "Epoch 65/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0590 - mse: 1.0590 - val_loss: 0.3792 - val_mse: 0.3792\n",
      "Epoch 66/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0348 - mse: 1.0348 - val_loss: 0.4586 - val_mse: 0.4586\n",
      "Epoch 67/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0132 - mse: 1.0132 - val_loss: 0.5550 - val_mse: 0.5550\n",
      "Epoch 68/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.0039 - mse: 1.0039 - val_loss: 0.6427 - val_mse: 0.6427\n",
      "Epoch 69/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.0045 - mse: 1.0045 - val_loss: 0.6943 - val_mse: 0.6943\n",
      "Epoch 70/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0046 - mse: 1.0046 - val_loss: 0.6944 - val_mse: 0.6944\n",
      "Epoch 71/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9960 - mse: 0.9960 - val_loss: 0.6476 - val_mse: 0.6476\n",
      "Epoch 72/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9792 - mse: 0.9792 - val_loss: 0.5748 - val_mse: 0.5748\n",
      "Epoch 73/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9621 - mse: 0.9621 - val_loss: 0.5010 - val_mse: 0.5010\n",
      "Epoch 74/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.9511 - mse: 0.9511 - val_loss: 0.4450 - val_mse: 0.4450\n",
      "Epoch 75/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9465 - mse: 0.9465 - val_loss: 0.4156 - val_mse: 0.4156\n",
      "Epoch 76/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9424 - mse: 0.9424 - val_loss: 0.4143 - val_mse: 0.4143\n",
      "Epoch 77/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9336 - mse: 0.9336 - val_loss: 0.4388 - val_mse: 0.4388\n",
      "Epoch 78/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9200 - mse: 0.9200 - val_loss: 0.4834 - val_mse: 0.4834\n",
      "Epoch 79/120\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9057 - mse: 0.9057 - val_loss: 0.5379 - val_mse: 0.5379\n",
      "Epoch 80/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8949 - mse: 0.8949 - val_loss: 0.5874 - val_mse: 0.5874\n",
      "Epoch 81/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8877 - mse: 0.8877 - val_loss: 0.6173 - val_mse: 0.6173\n",
      "Epoch 82/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8808 - mse: 0.8808 - val_loss: 0.6194 - val_mse: 0.6194\n",
      "Epoch 83/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8710 - mse: 0.8710 - val_loss: 0.5958 - val_mse: 0.5958\n",
      "Epoch 84/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8585 - mse: 0.8585 - val_loss: 0.5572 - val_mse: 0.5572\n",
      "Epoch 85/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8460 - mse: 0.8460 - val_loss: 0.5174 - val_mse: 0.5174\n",
      "Epoch 86/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8356 - mse: 0.8356 - val_loss: 0.4877 - val_mse: 0.4877\n",
      "Epoch 87/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8271 - mse: 0.8271 - val_loss: 0.4744 - val_mse: 0.4744\n",
      "Epoch 88/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8183 - mse: 0.8183 - val_loss: 0.4790 - val_mse: 0.4790\n",
      "Epoch 89/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8078 - mse: 0.8078 - val_loss: 0.4992 - val_mse: 0.4992\n",
      "Epoch 90/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7959 - mse: 0.7959 - val_loss: 0.5294 - val_mse: 0.5294\n",
      "Epoch 91/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7845 - mse: 0.7845 - val_loss: 0.5611 - val_mse: 0.5611\n",
      "Epoch 92/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7745 - mse: 0.7745 - val_loss: 0.5851 - val_mse: 0.5851\n",
      "Epoch 93/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7653 - mse: 0.7653 - val_loss: 0.5945 - val_mse: 0.5945\n",
      "Epoch 94/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7556 - mse: 0.7556 - val_loss: 0.5880 - val_mse: 0.5880\n",
      "Epoch 95/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7449 - mse: 0.7449 - val_loss: 0.5698 - val_mse: 0.5698\n",
      "Epoch 96/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7338 - mse: 0.7338 - val_loss: 0.5477 - val_mse: 0.5477\n",
      "Epoch 97/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7233 - mse: 0.7233 - val_loss: 0.5295 - val_mse: 0.5295\n",
      "Epoch 98/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7137 - mse: 0.7137 - val_loss: 0.5204 - val_mse: 0.5204\n",
      "Epoch 99/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7043 - mse: 0.7043 - val_loss: 0.5226 - val_mse: 0.5226\n",
      "Epoch 100/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6945 - mse: 0.6945 - val_loss: 0.5349 - val_mse: 0.5349\n",
      "Epoch 101/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6842 - mse: 0.6842 - val_loss: 0.5536 - val_mse: 0.5536\n",
      "Epoch 102/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6742 - mse: 0.6742 - val_loss: 0.5731 - val_mse: 0.5731\n",
      "Epoch 103/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6647 - mse: 0.6647 - val_loss: 0.5877 - val_mse: 0.5877\n",
      "Epoch 104/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6558 - mse: 0.6558 - val_loss: 0.5936 - val_mse: 0.5936\n",
      "Epoch 105/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6467 - mse: 0.6467 - val_loss: 0.5902 - val_mse: 0.5902\n",
      "Epoch 106/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6375 - mse: 0.6375 - val_loss: 0.5804 - val_mse: 0.5804\n",
      "Epoch 107/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6284 - mse: 0.6284 - val_loss: 0.5692 - val_mse: 0.5692\n",
      "Epoch 108/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6197 - mse: 0.6197 - val_loss: 0.5611 - val_mse: 0.5611\n",
      "Epoch 109/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6114 - mse: 0.6114 - val_loss: 0.5592 - val_mse: 0.5592\n",
      "Epoch 110/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6034 - mse: 0.6034 - val_loss: 0.5643 - val_mse: 0.5643\n",
      "Epoch 111/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5953 - mse: 0.5953 - val_loss: 0.5749 - val_mse: 0.5749\n",
      "Epoch 112/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5874 - mse: 0.5874 - val_loss: 0.5879 - val_mse: 0.5879\n",
      "Epoch 113/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5798 - mse: 0.5798 - val_loss: 0.5997 - val_mse: 0.5997\n",
      "Epoch 114/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5726 - mse: 0.5726 - val_loss: 0.6070 - val_mse: 0.6070\n",
      "Epoch 115/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5658 - mse: 0.5658 - val_loss: 0.6087 - val_mse: 0.6087\n",
      "Epoch 116/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5590 - mse: 0.5590 - val_loss: 0.6058 - val_mse: 0.6058\n",
      "Epoch 117/120\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5525 - mse: 0.5525 - val_loss: 0.6008 - val_mse: 0.6008\n",
      "Epoch 118/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5462 - mse: 0.5462 - val_loss: 0.5969 - val_mse: 0.5969\n",
      "Epoch 119/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5404 - mse: 0.5404 - val_loss: 0.5964 - val_mse: 0.5964\n",
      "Epoch 120/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5349 - mse: 0.5349 - val_loss: 0.6001 - val_mse: 0.6001\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "r2: 0.36806006386819634 meansquarederror: 0.14068036211520837 meanabsoluteerror: 0.3402426788245955 maxerror: 0.5085225322775093\n",
      "Epoch 1/120\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 1.4682 - mse: 1.4682 - val_loss: 38.1725 - val_mse: 38.1725\n",
      "Epoch 2/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 47.3833 - mse: 47.3833 - val_loss: 1.5164 - val_mse: 1.5164\n",
      "Epoch 3/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.5757 - mse: 4.5757 - val_loss: 15.4956 - val_mse: 15.4956\n",
      "Epoch 4/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 12.2591 - mse: 12.2591 - val_loss: 31.7962 - val_mse: 31.7962\n",
      "Epoch 5/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 26.4185 - mse: 26.4185 - val_loss: 22.1498 - val_mse: 22.1498\n",
      "Epoch 6/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 17.9142 - mse: 17.9142 - val_loss: 6.4043 - val_mse: 6.4043\n",
      "Epoch 7/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.8868 - mse: 4.8868 - val_loss: 0.1150 - val_mse: 0.1150\n",
      "Epoch 8/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.6510 - mse: 1.6510 - val_loss: 3.6395 - val_mse: 3.6395\n",
      "Epoch 9/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.4938 - mse: 7.4938 - val_loss: 7.5817 - val_mse: 7.5817\n",
      "Epoch 10/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 12.4519 - mse: 12.4519 - val_loss: 6.5760 - val_mse: 6.5760\n",
      "Epoch 11/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 11.2086 - mse: 11.2086 - val_loss: 2.6254 - val_mse: 2.6254\n",
      "Epoch 12/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.1034 - mse: 6.1034 - val_loss: 0.1636 - val_mse: 0.1636\n",
      "Epoch 13/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.9798 - mse: 1.9798 - val_loss: 1.5233 - val_mse: 1.5233\n",
      "Epoch 14/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.6118 - mse: 1.6118 - val_loss: 5.3327 - val_mse: 5.3327\n",
      "Epoch 15/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.0475 - mse: 4.0475 - val_loss: 8.3243 - val_mse: 8.3243\n",
      "Epoch 16/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.3028 - mse: 6.3028 - val_loss: 8.4172 - val_mse: 8.4172\n",
      "Epoch 17/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.3706 - mse: 6.3706 - val_loss: 5.9581 - val_mse: 5.9581\n",
      "Epoch 18/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.4920 - mse: 4.4920 - val_loss: 2.7880 - val_mse: 2.7880\n",
      "Epoch 19/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.2972 - mse: 2.2972 - val_loss: 0.6524 - val_mse: 0.6524\n",
      "Epoch 20/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2769 - mse: 1.2769 - val_loss: 0.1318 - val_mse: 0.1318\n",
      "Epoch 21/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.7659 - mse: 1.7659 - val_loss: 0.6029 - val_mse: 0.6029\n",
      "Epoch 22/120\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.9516 - mse: 2.9516 - val_loss: 1.0464 - val_mse: 1.0464\n",
      "Epoch 23/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.7129 - mse: 3.7129 - val_loss: 0.9169 - val_mse: 0.9169\n",
      "Epoch 24/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.4939 - mse: 3.4939 - val_loss: 0.4123 - val_mse: 0.4123\n",
      "Epoch 25/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.5572 - mse: 2.5572 - val_loss: 0.1248 - val_mse: 0.1248\n",
      "Epoch 26/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.6120 - mse: 1.6120 - val_loss: 0.4861 - val_mse: 0.4861\n",
      "Epoch 27/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2356 - mse: 1.2356 - val_loss: 1.4278 - val_mse: 1.4278\n",
      "Epoch 28/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.5076 - mse: 1.5076 - val_loss: 2.4534 - val_mse: 2.4534\n",
      "Epoch 29/120\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.0530 - mse: 2.0530 - val_loss: 3.0089 - val_mse: 3.0089\n",
      "Epoch 30/120\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.3906 - mse: 2.3906 - val_loss: 2.8427 - val_mse: 2.8427\n",
      "Epoch 31/120\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 2.2819 - mse: 2.2819 - val_loss: 2.1113 - val_mse: 2.1113\n",
      "Epoch 32/120\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.8427 - mse: 1.8427 - val_loss: 1.2158 - val_mse: 1.2158\n",
      "Epoch 33/120\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.3935 - mse: 1.3935 - val_loss: 0.5282 - val_mse: 0.5282\n",
      "Epoch 34/120\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2057 - mse: 1.2057 - val_loss: 0.1963 - val_mse: 0.1963\n",
      "Epoch 35/120\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.3262 - mse: 1.3262 - val_loss: 0.1315 - val_mse: 0.1315\n",
      "Epoch 36/120\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.5851 - mse: 1.5851 - val_loss: 0.1514 - val_mse: 0.1514\n",
      "Epoch 37/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.7506 - mse: 1.7506 - val_loss: 0.1444 - val_mse: 0.1444\n",
      "Epoch 38/120\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.7001 - mse: 1.7001 - val_loss: 0.1369 - val_mse: 0.1369\n",
      "Epoch 39/120\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4852 - mse: 1.4852 - val_loss: 0.2333 - val_mse: 0.2333\n",
      "Epoch 40/120\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.2639 - mse: 1.2639 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 41/120\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1721 - mse: 1.1721 - val_loss: 0.8866 - val_mse: 0.8866\n",
      "Epoch 42/120\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2326 - mse: 1.2326 - val_loss: 1.2471 - val_mse: 1.2471\n",
      "Epoch 43/120\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3583 - mse: 1.3583 - val_loss: 1.4279 - val_mse: 1.4279\n",
      "Epoch 44/120\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.4327 - mse: 1.4327 - val_loss: 1.3623 - val_mse: 1.3623\n",
      "Epoch 45/120\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.3975 - mse: 1.3975 - val_loss: 1.1010 - val_mse: 1.1010\n",
      "Epoch 46/120\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2837 - mse: 1.2837 - val_loss: 0.7680 - val_mse: 0.7680\n",
      "Epoch 47/120\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1740 - mse: 1.1740 - val_loss: 0.4828 - val_mse: 0.4828\n",
      "Epoch 48/120\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1351 - mse: 1.1351 - val_loss: 0.3027 - val_mse: 0.3027\n",
      "Epoch 49/120\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1713 - mse: 1.1713 - val_loss: 0.2195 - val_mse: 0.2195\n",
      "Epoch 50/120\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2317 - mse: 1.2317 - val_loss: 0.1978 - val_mse: 0.1978\n",
      "Epoch 51/120\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.2568 - mse: 1.2568 - val_loss: 0.2175 - val_mse: 0.2175\n",
      "Epoch 52/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.2239 - mse: 1.2239 - val_loss: 0.2855 - val_mse: 0.2855\n",
      "Epoch 53/120\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1584 - mse: 1.1584 - val_loss: 0.4143 - val_mse: 0.4143\n",
      "Epoch 54/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.1060 - mse: 1.1060 - val_loss: 0.5913 - val_mse: 0.5913\n",
      "Epoch 55/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0954 - mse: 1.0954 - val_loss: 0.7696 - val_mse: 0.7696\n",
      "Epoch 56/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1185 - mse: 1.1185 - val_loss: 0.8878 - val_mse: 0.8878\n",
      "Epoch 57/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1430 - mse: 1.1430 - val_loss: 0.9049 - val_mse: 0.9049\n",
      "Epoch 58/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1411 - mse: 1.1411 - val_loss: 0.8227 - val_mse: 0.8227\n",
      "Epoch 59/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1107 - mse: 1.1107 - val_loss: 0.6813 - val_mse: 0.6813\n",
      "Epoch 60/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0726 - mse: 1.0726 - val_loss: 0.5335 - val_mse: 0.5335\n",
      "Epoch 61/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0504 - mse: 1.0504 - val_loss: 0.4180 - val_mse: 0.4180\n",
      "Epoch 62/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0511 - mse: 1.0511 - val_loss: 0.3496 - val_mse: 0.3496\n",
      "Epoch 63/120\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.0623 - mse: 1.0623 - val_loss: 0.3262 - val_mse: 0.3262\n",
      "Epoch 64/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.0649 - mse: 1.0649 - val_loss: 0.3424 - val_mse: 0.3424\n",
      "Epoch 65/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0505 - mse: 1.0505 - val_loss: 0.3952 - val_mse: 0.3952\n",
      "Epoch 66/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0259 - mse: 1.0259 - val_loss: 0.4789 - val_mse: 0.4789\n",
      "Epoch 67/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0055 - mse: 1.0055 - val_loss: 0.5772 - val_mse: 0.5772\n",
      "Epoch 68/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9977 - mse: 0.9977 - val_loss: 0.6633 - val_mse: 0.6633\n",
      "Epoch 69/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9988 - mse: 0.9988 - val_loss: 0.7102 - val_mse: 0.7102\n",
      "Epoch 70/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9983 - mse: 0.9983 - val_loss: 0.7047 - val_mse: 0.7047\n",
      "Epoch 71/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9885 - mse: 0.9885 - val_loss: 0.6534 - val_mse: 0.6534\n",
      "Epoch 72/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9714 - mse: 0.9714 - val_loss: 0.5785 - val_mse: 0.5785\n",
      "Epoch 73/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9548 - mse: 0.9548 - val_loss: 0.5049 - val_mse: 0.5049\n",
      "Epoch 74/120\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9447 - mse: 0.9447 - val_loss: 0.4507 - val_mse: 0.4507\n",
      "Epoch 75/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9405 - mse: 0.9405 - val_loss: 0.4239 - val_mse: 0.4239\n",
      "Epoch 76/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9361 - mse: 0.9361 - val_loss: 0.4256 - val_mse: 0.4256\n",
      "Epoch 77/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9268 - mse: 0.9268 - val_loss: 0.4532 - val_mse: 0.4532\n",
      "Epoch 78/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9129 - mse: 0.9129 - val_loss: 0.5005 - val_mse: 0.5005\n",
      "Epoch 79/120\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8990 - mse: 0.8990 - val_loss: 0.5563 - val_mse: 0.5563\n",
      "Epoch 80/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8887 - mse: 0.8887 - val_loss: 0.6054 - val_mse: 0.6054\n",
      "Epoch 81/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8818 - mse: 0.8818 - val_loss: 0.6332 - val_mse: 0.6332\n",
      "Epoch 82/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8747 - mse: 0.8747 - val_loss: 0.6324 - val_mse: 0.6324\n",
      "Epoch 83/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8646 - mse: 0.8646 - val_loss: 0.6063 - val_mse: 0.6063\n",
      "Epoch 84/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8521 - mse: 0.8521 - val_loss: 0.5664 - val_mse: 0.5664\n",
      "Epoch 85/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8398 - mse: 0.8398 - val_loss: 0.5265 - val_mse: 0.5265\n",
      "Epoch 86/120\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8298 - mse: 0.8298 - val_loss: 0.4979 - val_mse: 0.4979\n",
      "Epoch 87/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8214 - mse: 0.8214 - val_loss: 0.4863 - val_mse: 0.4863\n",
      "Epoch 88/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8126 - mse: 0.8126 - val_loss: 0.4930 - val_mse: 0.4930\n",
      "Epoch 89/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8020 - mse: 0.8020 - val_loss: 0.5151 - val_mse: 0.5151\n",
      "Epoch 90/120\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7902 - mse: 0.7902 - val_loss: 0.5468 - val_mse: 0.5468\n",
      "Epoch 91/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7790 - mse: 0.7790 - val_loss: 0.5789 - val_mse: 0.5789\n",
      "Epoch 92/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7693 - mse: 0.7693 - val_loss: 0.6022 - val_mse: 0.6022\n",
      "Epoch 93/120\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7602 - mse: 0.7602 - val_loss: 0.6102 - val_mse: 0.6102\n",
      "Epoch 94/120\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.7505 - mse: 0.7505 - val_loss: 0.6021 - val_mse: 0.6021\n",
      "Epoch 95/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7398 - mse: 0.7398 - val_loss: 0.5828 - val_mse: 0.5828\n",
      "Epoch 96/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7289 - mse: 0.7289 - val_loss: 0.5603 - val_mse: 0.5603\n",
      "Epoch 97/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7187 - mse: 0.7187 - val_loss: 0.5425 - val_mse: 0.5425\n",
      "Epoch 98/120\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7093 - mse: 0.7093 - val_loss: 0.5345 - val_mse: 0.5345\n",
      "Epoch 99/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7000 - mse: 0.7000 - val_loss: 0.5381 - val_mse: 0.5381\n",
      "Epoch 100/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6902 - mse: 0.6902 - val_loss: 0.5517 - val_mse: 0.5517\n",
      "Epoch 101/120\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6801 - mse: 0.6801 - val_loss: 0.5714 - val_mse: 0.5714\n",
      "Epoch 102/120\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6703 - mse: 0.6703 - val_loss: 0.5913 - val_mse: 0.5913\n",
      "Epoch 103/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6611 - mse: 0.6611 - val_loss: 0.6055 - val_mse: 0.6055\n",
      "Epoch 104/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6523 - mse: 0.6523 - val_loss: 0.6105 - val_mse: 0.6105\n",
      "Epoch 105/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6434 - mse: 0.6434 - val_loss: 0.6062 - val_mse: 0.6062\n",
      "Epoch 106/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6343 - mse: 0.6343 - val_loss: 0.5958 - val_mse: 0.5958\n",
      "Epoch 107/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6253 - mse: 0.6253 - val_loss: 0.5844 - val_mse: 0.5844\n",
      "Epoch 108/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6169 - mse: 0.6169 - val_loss: 0.5767 - val_mse: 0.5767\n",
      "Epoch 109/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6088 - mse: 0.6088 - val_loss: 0.5755 - val_mse: 0.5755\n",
      "Epoch 110/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6009 - mse: 0.6009 - val_loss: 0.5815 - val_mse: 0.5815\n",
      "Epoch 111/120\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5930 - mse: 0.5930 - val_loss: 0.5930 - val_mse: 0.5930\n",
      "Epoch 112/120\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5853 - mse: 0.5853 - val_loss: 0.6065 - val_mse: 0.6065\n",
      "Epoch 113/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5779 - mse: 0.5779 - val_loss: 0.6182 - val_mse: 0.6182\n",
      "Epoch 114/120\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5710 - mse: 0.5710 - val_loss: 0.6252 - val_mse: 0.6252\n",
      "Epoch 115/120\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5643 - mse: 0.5643 - val_loss: 0.6263 - val_mse: 0.6263\n",
      "Epoch 116/120\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5577 - mse: 0.5577 - val_loss: 0.6228 - val_mse: 0.6228\n",
      "Epoch 117/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5513 - mse: 0.5513 - val_loss: 0.6176 - val_mse: 0.6176\n",
      "Epoch 118/120\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5452 - mse: 0.5452 - val_loss: 0.6138 - val_mse: 0.6138\n",
      "Epoch 119/120\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5396 - mse: 0.5396 - val_loss: 0.6136 - val_mse: 0.6136\n",
      "Epoch 120/120\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5342 - mse: 0.5342 - val_loss: 0.6180 - val_mse: 0.6180\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "r2: 0.39064411985979797 meansquarederror: 0.13565277485054464 meanabsoluteerror: 0.3331093451313141 maxerror: 0.5014048523479384\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# from tensorflow.python.keras.layers import Dense\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n",
    "predictions_rt = []\n",
    "\n",
    "\n",
    "for i in range(0,30):\n",
    "    variables,results = split_x_and_y(database.iloc[[0,1,2,3,4,5,6,7,8]],['A','E','N'],'Rt')\n",
    "    test_x,test_y = split_x_and_y(database.iloc[[9,10,11]],['A','E','N'],'Rt')\n",
    "\n",
    "    model = keras.Sequential([\n",
    "    layers.Dense(256*5, activation='sigmoid', input_shape=[len(variables.keys())]),\n",
    "    # layers.Dropout(0.1),\n",
    "    layers.Dense(256*5, activation='sigmoid'),\n",
    "    layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    # optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "    model.compile(optimizer='adam',loss='mean_squared_error',metrics=['mse'])\n",
    "\n",
    "    history = model.fit(variables.values,results.values,epochs=120,validation_split=0.2)\n",
    "\n",
    "    guess = model.predict(test_x.values)\n",
    "    desnormalizar = test_x.copy()\n",
    "    desnormalizar['Rt'] = guess\n",
    "    desnormalizado_teste = standardscaler.inverse_transform(desnormalizar)\n",
    "    desnormalizado_teste\n",
    "\n",
    "    desnormalizar = test_x.copy()\n",
    "    desnormalizar['Rt'] = test_y\n",
    "    desnormalizado_resultado = standardscaler.inverse_transform(desnormalizar)\n",
    "    desnormalizado_resultado\n",
    "\n",
    "    r2,meansquarederror,meanabsoluteerror,maxerror = scores(desnormalizado_resultado[:,-1],desnormalizado_teste[:,-1])\n",
    "\n",
    "    predictions_rt.append(list(desnormalizado_teste[:,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_boxplots = pd.DataFrame(predictions_rt,columns=['C1','C2','C3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(data=df_boxplots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Rt')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(data=df_boxplots,y='C1')\n",
    "plt.xlabel('C1')\n",
    "plt.ylabel('Rt')\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(data=df_boxplots,y='C2')\n",
    "plt.xlabel('C2')\n",
    "plt.ylabel('Rt')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(data=df_boxplots,y='C3')\n",
    "plt.xlabel('C3')\n",
    "plt.ylabel('Rt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "edbada794071f9c875b2bc5e0e869a1d746a19a0ba8801f10239845106c51c5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
